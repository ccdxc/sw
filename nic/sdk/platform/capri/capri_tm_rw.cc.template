//-----------------------------------------------------------------------------
// {C} Copyright 2017 Pensando Systems Inc. All rights reserved
//-----------------------------------------------------------------------------
/*
 * capri_tm_rw.cc
 * Vasanth Kumar (Pensando Systems)
 */


#include <stdio.h>
#include <string>
#include <errno.h>
#include <stdlib.h>
#include <assert.h>
#include <map>
#include <cmath>

#include "include/sdk/base.hpp"
#include "include/sdk/mem.hpp"
#include "include/sdk/lock.hpp"
#include "platform/capri/capri_p4.hpp"
#include "platform/capri/capri_tm_rw.hpp"
#include "platform/capri/capri_state.hpp"
#include "platform/utils/mpartition.hpp"
#include "lib/bitmap/bitmap.hpp"

#include "third-party/asic/capri/model/utils/cap_blk_reg_model.h"
#include "third-party/asic/capri/model/cap_top/cap_top_csr.h"
#include "third-party/asic/capri/model/cap_pb/cap_pbc_csr.h"
#include "third-party/asic/capri/verif/apis/cap_pb_api.h"
#include "third-party/asic/capri/model/cap_pb/cap_pbc_decoders.h"

namespace sdk {
namespace platform {
namespace capri {

static cpp_int_helper cpp_helper;
static pthread_mutex_t tm_mutex;

typedef struct capri_tm_cfg_profile_s {
    uint32_t num_qs[NUM_TM_PORT_TYPES];
    uint32_t jumbo_mtu[NUM_TM_PORT_TYPES];
    uint32_t num_active_uplink_ports;
    uint64_t hbm_fifo_base;
    uint32_t hbm_fifo_size;
    bool     sw_init_enabled;
    bool     sw_cfg_write_enabled;
    tm_q_t   *p4_high_perf_qs;
    uint32_t num_p4_high_perf_qs;
} capri_tm_cfg_profile_t;

typedef struct capri_tm_port_asic_profile_s {
    uint32_t reserved_mtus;
    uint32_t headroom_cells;
    uint32_t recirc_q;
    bool     uses_credits;
} capri_tm_asic_port_profile_t;

typedef struct capri_tm_asic_profile_s {
    uint32_t                     cell_alloc_units;
    uint32_t                     hbm_fifo_alloc_units;
    uint32_t                     hbm_fifo_control_scale_factor;
    capri_tm_asic_port_profile_t port[NUM_TM_PORT_TYPES];
    uint32_t                     hbm_fifo_reserved_bytes_per_context[NUM_TM_HBM_FIFO_TYPES];
    uint32_t                     cpu_copy_tail_drop_threshold;
    uint32_t                     span_tail_drop_threshold;
} capri_tm_asic_profile_t;

typedef struct capri_tm_buf_hbm_cfg_s {
    bool valid;
    uint64_t payload_offset;
    uint64_t control_offset;
    uint32_t payload_chunks;
    uint32_t control_chunks;
} capri_tm_buf_hbm_cfg_t;

typedef struct capri_tm_buf_cfgs_s {
    uint32_t               chunks_per_q[NUM_TM_PORT_TYPES];
    capri_tm_buf_hbm_cfg_t hbm_fifo[NUM_TM_HBM_FIFO_TYPES][CAPRI_TM_MAX_HBM_CONTEXTS];
} capri_tm_buf_cfg_t;

typedef struct capri_tm_hbm_context_stats_s {
    uint64_t good_pkts_in;
    uint64_t good_pkts_out;
    uint64_t errored_pkts_in;
    uint32_t max_oflow_fifo_depth;
} capri_tm_hbm_context_stats_t;

typedef struct capri_tm_shadow_stats_s {
    sdk_spinlock_t slock; // Lock for accessing the stats
    capri_tm_hbm_context_stats_t cur_vals[NUM_TM_HBM_FIFO_TYPES][CAPRI_TM_MAX_HBM_CONTEXTS];
    capri_tm_hbm_context_stats_t prev_vals[NUM_TM_HBM_FIFO_TYPES][CAPRI_TM_MAX_HBM_CONTEXTS];
} capri_tm_shadow_stats_t;

typedef struct capri_tm_ctx_s {
    capri_tm_shadow_stats_t stats;
    capri_tm_asic_profile_t asic_profile;
    capri_tm_cfg_profile_t  cfg_profile;
    capri_tm_buf_cfg_t      buf_cfg;
    std::atomic<bool>       init_complete;
} capri_tm_ctx_t;

capri_tm_ctx_t g_tm_ctx_;
capri_tm_ctx_t *g_tm_ctx;

static void
set_tm_ctx (capri_tm_cfg_profile_t *tm_cfg_profile,
            capri_tm_asic_profile_t *asic_profile)
{
    if (!g_tm_ctx) {
        g_tm_ctx_.cfg_profile = *tm_cfg_profile;
        g_tm_ctx_.asic_profile = *asic_profile;
        SDK_SPINLOCK_INIT(&g_tm_ctx_.stats.slock, PTHREAD_PROCESS_PRIVATE);
        g_tm_ctx = &g_tm_ctx_;
    }
}

static capri_tm_ctx_t *
tm_ctx (void)
{
    return g_tm_ctx;
}

static capri_tm_asic_profile_t *
tm_asic_profile (void)
{
    return &tm_ctx()->asic_profile;
}

static capri_tm_cfg_profile_t *
tm_cfg_profile (void)
{
    return &tm_ctx()->cfg_profile;
}

static inline bool
tm_sw_init_enabled (void)
{
    return tm_cfg_profile()->sw_init_enabled;
}

static inline bool
tm_sw_cfg_write_enabled (void)
{
    return tm_cfg_profile()->sw_cfg_write_enabled;
}

static void
populate_asic_profile (capri_tm_asic_profile_t *asic_profile)
{
    // These are values based on performance numbers seen during rtl simulation
    // When reserved_mtus is zero, it indicates that allocate whatever is left
    memset(asic_profile, 0, sizeof(*asic_profile));
    asic_profile->cell_alloc_units = 4;
    asic_profile->hbm_fifo_alloc_units = CAPRI_TM_HBM_FIFO_ALLOC_SIZE;
    asic_profile->hbm_fifo_control_scale_factor = 50;
    asic_profile->cpu_copy_tail_drop_threshold = 900;
    asic_profile->span_tail_drop_threshold = 100;

    asic_profile->port[TM_PORT_TYPE_UPLINK].reserved_mtus = 0;
    asic_profile->port[TM_PORT_TYPE_UPLINK].headroom_cells = 100;

    asic_profile->port[TM_PORT_TYPE_P4IG].reserved_mtus = 3;
    asic_profile->port[TM_PORT_TYPE_P4IG].headroom_cells = 0;
    asic_profile->port[TM_PORT_TYPE_P4IG].uses_credits = true;
    asic_profile->port[TM_PORT_TYPE_P4IG].recirc_q = CAPRI_TM_P4_RECIRC_QUEUE;

    asic_profile->port[TM_PORT_TYPE_P4EG].reserved_mtus = 3;
    asic_profile->port[TM_PORT_TYPE_P4EG].headroom_cells = 0;
    asic_profile->port[TM_PORT_TYPE_P4EG].uses_credits = true;
    asic_profile->port[TM_PORT_TYPE_P4EG].recirc_q = CAPRI_TM_P4_RECIRC_QUEUE;

    asic_profile->port[TM_PORT_TYPE_DMA].reserved_mtus = 0;
    asic_profile->port[TM_PORT_TYPE_DMA].headroom_cells = 100;

    asic_profile->hbm_fifo_reserved_bytes_per_context[TM_HBM_FIFO_TYPE_UPLINK] = 3*1024*1024; // 3MB
    asic_profile->hbm_fifo_reserved_bytes_per_context[TM_HBM_FIFO_TYPE_TXDMA] = 9*1024*1024;; // 9MB
}

static inline uint32_t
bytes_to_cells (uint32_t bytes)
{
    return (bytes + CAPRI_TM_CELL_SIZE - 1)/CAPRI_TM_CELL_SIZE;
}

static inline uint32_t
cells_to_bytes (uint32_t cells)
{
    return cells * CAPRI_TM_CELL_SIZE;
}

static inline uint32_t
cells_to_chunks (uint32_t cells)
{
    return (cells + tm_asic_profile()->cell_alloc_units - 1)/
        tm_asic_profile()->cell_alloc_units;
}

static inline uint32_t
chunks_to_cells (uint32_t chunks)
{
    return chunks * tm_asic_profile()->cell_alloc_units;
}

static inline uint32_t
hbm_bytes_to_chunks (uint32_t bytes)
{
    return (bytes + tm_asic_profile()->hbm_fifo_alloc_units - 1)/
        tm_asic_profile()->hbm_fifo_alloc_units;
}

static inline uint32_t
hbm_chunks_to_bytes (uint32_t chunks)
{
    return chunks * tm_asic_profile()->hbm_fifo_alloc_units;
}

static inline uint32_t
capri_tm_get_max_cell_chunks_for_island (uint32_t island)
{
    uint32_t cells = 0;
    SDK_ASSERT(island < CAPRI_TM_NUM_BUFFER_ISLANDS);
    if (tm_cfg_profile()->num_active_uplink_ports > 2) {
        island = CAPRI_TM_NUM_BUFFER_ISLANDS - island - 1;
    }
    if (island == 0) {
        cells = CAPRI_TM_BUFFER_ISLAND_0_CELL_COUNT;
    } else if (island == 1) {
        cells = CAPRI_TM_BUFFER_ISLAND_1_CELL_COUNT;
    }
    return cells_to_chunks(cells);
}

static inline bool
capri_tm_hbm_overflow_enabled (void)
{
    return tm_cfg_profile()->hbm_fifo_size == 0 ? false : true;
}

static inline tm_port_type_e
capri_tm_get_port_type (tm_port_t port)
{
    switch(port) {
        case CAPRI_TM_PORT_UPLINK_0:
        case CAPRI_TM_PORT_UPLINK_1:
        case CAPRI_TM_PORT_UPLINK_2:
        case CAPRI_TM_PORT_UPLINK_3:
        case CAPRI_TM_PORT_UPLINK_4:
        case CAPRI_TM_PORT_UPLINK_5:
        case CAPRI_TM_PORT_UPLINK_6:
        case CAPRI_TM_PORT_UPLINK_7:
        case CAPRI_TM_PORT_NCSI:
            return TM_PORT_TYPE_UPLINK;
        case CAPRI_TM_PORT_DMA:
            return TM_PORT_TYPE_DMA;
        case CAPRI_TM_PORT_EGRESS:
            return TM_PORT_TYPE_P4EG;
        case CAPRI_TM_PORT_INGRESS:
            return TM_PORT_TYPE_P4IG;
    }
    return NUM_TM_PORT_TYPES;
}

static inline bool
is_active_uplink_port (tm_port_t port)
{
    if (port < tm_cfg_profile()->num_active_uplink_ports) {
        return true;
    }
    return false;
}

static inline bool
is_active_port (tm_port_t port)
{
    tm_port_type_e port_type;

    port_type = capri_tm_get_port_type(port);
    if (port_type == TM_PORT_TYPE_UPLINK) {
        return (is_active_uplink_port(port) ||
                (port == CAPRI_TM_PORT_NCSI));
    }
    return true;
}

static inline uint32_t
capri_tm_max_hbm_contexts_for_fifo (uint32_t fifo_type)
{
    switch (fifo_type) {
        case TM_HBM_FIFO_TYPE_UPLINK:
            return CAPRI_TM_MAX_HBM_ETH_CONTEXTS;
        case TM_HBM_FIFO_TYPE_TXDMA:
            return CAPRI_TM_MAX_HBM_DMA_CONTEXTS;
        case NUM_TM_HBM_FIFO_TYPES:
            return 0;
    }
    return 0;
}

static inline bool
port_supports_hbm_contexts (tm_port_t port)
{
    return is_active_uplink_port(port) || (port == CAPRI_TM_PORT_DMA);
}

static inline uint32_t
capri_tm_get_num_iqs_for_port_type (tm_port_type_e port_type)
{
    switch(port_type) {
        case TM_PORT_TYPE_UPLINK:
            return 8;
        case TM_PORT_TYPE_P4IG:
        case TM_PORT_TYPE_P4EG:
            return 32;
        case TM_PORT_TYPE_DMA:
            return 16;
        case NUM_TM_PORT_TYPES:
            return 0;
    }
    return 0;
}

uint32_t
capri_tm_get_num_iqs_for_port (tm_port_t port)
{
    return capri_tm_get_num_iqs_for_port_type(capri_tm_get_port_type(port));
}

static inline uint32_t
capri_tm_get_num_oqs_for_port_type (tm_port_type_e port_type)
{
    switch(port_type) {
        case TM_PORT_TYPE_UPLINK:
            return 16;
        case TM_PORT_TYPE_P4IG:
        case TM_PORT_TYPE_P4EG:
        case TM_PORT_TYPE_DMA:
            return 32;
        case NUM_TM_PORT_TYPES:
            return 0;
    }
    return 0;
}

uint32_t
capri_tm_get_num_oqs_for_port (tm_port_t port)
{
    return capri_tm_get_num_oqs_for_port_type(capri_tm_get_port_type(port));
}

static inline uint32_t
capri_tm_get_island_for_port_type (tm_port_type_e port_type)
{
    switch(port_type) {
        case TM_PORT_TYPE_UPLINK:
        case TM_PORT_TYPE_P4EG:
            return 1;
        case TM_PORT_TYPE_P4IG:
        case TM_PORT_TYPE_DMA:
            return 0;
        case NUM_TM_PORT_TYPES:
            return 0;
    }

    return 0;
}

static inline tm_hbm_fifo_type_e
capri_tm_get_fifo_type_for_port (tm_port_t port)
{
    switch(capri_tm_get_port_type(port)) {
        case TM_PORT_TYPE_UPLINK:
            return TM_HBM_FIFO_TYPE_UPLINK;
        case TM_PORT_TYPE_DMA:
            return TM_HBM_FIFO_TYPE_TXDMA;
        case TM_PORT_TYPE_P4EG:
        case TM_PORT_TYPE_P4IG:
        case NUM_TM_PORT_TYPES:
            return NUM_TM_HBM_FIFO_TYPES;
    }
    return NUM_TM_HBM_FIFO_TYPES;
}

static inline bool
tm_is_high_perf_q (tm_q_t q)
{
    for (unsigned int i = 0; i < tm_cfg_profile()->num_p4_high_perf_qs; i++) {
        if (q == tm_cfg_profile()->p4_high_perf_qs[i]) {
            return true;
        }
    }
    return false;
}

//:: from collections import OrderedDict
//:: import math
//:: TM_PORTS = 12
//:: QS = 32
//:: L1_NODES = 16
//:: L2_NODES = 4
//:: e = [
//::    "CAPRI_TM_PORT_UPLINK_0",
//::    "CAPRI_TM_PORT_UPLINK_1",
//::    "CAPRI_TM_PORT_UPLINK_2",
//::    "CAPRI_TM_PORT_UPLINK_3",
//::    "CAPRI_TM_PORT_UPLINK_4",
//::    "CAPRI_TM_PORT_UPLINK_5",
//::    "CAPRI_TM_PORT_UPLINK_6",
//::    "CAPRI_TM_PORT_UPLINK_7",
//::    "CAPRI_TM_PORT_NCSI",
//::    "CAPRI_TM_PORT_DMA",
//::    "CAPRI_TM_PORT_EGRESS",
//::    "CAPRI_TM_PORT_INGRESS"]
//::
//:: port_info = OrderedDict()
//::
//:: for p in range(TM_PORTS):
//::     pinfo = {}
//::     pinfo["enum"] = e[p]
//::     pinfo["qs"] = QS
//::     pinfo["l1"] = L1_NODES
//::     pinfo["l2"] = L2_NODES
//::     pinfo["l3"] = 0
//::     pinfo["has_hbm"] = False
//::     pinfo["supports_credits"] = False
//::     if p < 9:
//::        pinfo["type"] = "uplink"
//::        pinfo["pgs"] = 8
//::        if e[p] != "CAPRI_TM_PORT_NCSI":
//::            pinfo["has_hbm"] = True
//::        #endif
//::     elif p < 10:
//::        pinfo["type"] = "dma"
//::        pinfo["pgs"] = 16
//::        pinfo["l3"] = 1
//::        pinfo["has_hbm"] = True
//::     else:
//::        pinfo["type"] = "p4"
//::        pinfo["pgs"] = 32
//::        pinfo["l3"] = 1
//::        pinfo["supports_credits"] = True
//::     #endif
//::     port_info[p] = pinfo
//:: #endfor
//::
//:: hbm_fifo_info = {
//::                'TM_HBM_FIFO_TYPE_UPLINK': {'reg_name' : 'eth', 'count' : 32 },
//::                'TM_HBM_FIFO_TYPE_TXDMA': {'reg_name' : 'tx', 'count' : 16}
//::                 }
//::
//:: import yaml
//:: def get_reg_instances(regs, types):
//:: import re
//:: instances = []
//:: for reg in sorted(regs.keys()):
//::    regn = reg.split('.')[-1]
//::    if types is None or len(set(regn.split('_')) & types):
//::        instances.append(reg)
//::    #endif
//:: #endfor
//:: return instances
//:: #enddef
//::
//:: def parse_block(data, block, type, path_to_here, regs):
//::     global parse_block
//::     path = path_to_here[:]
//::     block_type = data[block]['type']
//::     if block_type == type:
//::        regs[path] = data[block]['fields'].keys()
//::        # sta_rpl_err doesn't seem to have type() method even though it's in
//::        # yaml
//::        if path == "pbc_csr.sta_rpl_err":
//::            regs[path].remove("type")
//::        #endif
//::        return
//::     #endif
//::     if block_type != 'block':
//::         return
//::     #endif
//::     for field, field_d in data[block]['fields'].items():
//::        lpath = path + '.' + field
//::        is_array = False
//::        if field_d['array'] != 1:
//::            is_array = True
//::        #endif
//::        apath = lpath[:]
//::        for i in range(field_d['array']):
//::            if is_array:
//::                apath = lpath + '[%d]' % i
//::            #endif
//::            parse_block(data, field_d['decoder'], type, apath, regs)
//::        #endfor
//::     #endfor
//:: #enddef
//::
//:: def normalize(data):
//::    d = {}
//::    for block_name, block_data in data.items():
//::        d[block_name] = {x.keys()[0]:x.values()[0] for x in block_data}
//::        d[block_name]['fields'] = {x.keys()[0]:x.values()[0] for x in d[block_name]['fields']}
//::        for field_name, field_d in d[block_name]['fields'].items():
//::            d[block_name]['fields'][field_name] = {x.keys()[0]:x.values()[0] for x in field_d}
//::        #endfor
//::    #endfor
//::    return d
//:: #enddef
//::
//:: with open(_context['args']) as data_file:
//::    data = yaml.load(data_file)
//:: #endwith
//:: regs = OrderedDict()
//:: memories = OrderedDict()
//::
//:: data = normalize(data)
//:: parse_block(data, 'cap_pbc_csr', 'register', 'pbc_csr', regs)
//:: parse_block(data, 'cap_pbc_csr', 'memory', 'cap0.pb', memories)
//::
//:: def trace_register(inst_name, var_name="data"):
//::    global regs
//::    s = ''
//::    fields = ['all']
//::    if inst_name in regs:
//::        fields += regs[inst_name]
//::    #endif
//::    for field in fields:
//::        s += var_name + ''' <<"'''
//::        s += inst_name + '''.''' + field
//::        s += ''': 0x" << '''
//::        s += inst_name + '''.''' + field + '''() << endl;\n'''
//::    #endfor
//::    return s
//:: #enddef
//::
//::
//:: fns = OrderedDict()
//:: fns["debug"] = set(['cnt', 'sta', 'sat'])
//:: fns["config"] = set(['cfg'])
//::
//:: for fn,types in fns.items():

void
capri_tm_dump_${fn}_regs (void)
{
#if 0
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    stringstream data;
    data << hex << endl;
//:: instances = get_reg_instances(regs, types)
//:: for inst_name in instances:
    ${inst_name}.read();
    ${trace_register(inst_name)}
//:: #endfor
    SDK_TRACE_DEBUG("%s", data.str().c_str());
#endif
}
//:: #endfor
//::

bool
capri_tm_port_is_uplink_port (uint32_t port)
{
    return ((port >= CAPRI_TM_UPLINK_PORT_BEGIN) && (port <= CAPRI_TM_UPLINK_PORT_END));
}

bool
capri_tm_port_is_dma_port (uint32_t port)
{
    return ((port >= CAPRI_TM_DMA_PORT_BEGIN) && (port <= CAPRI_TM_DMA_PORT_END));
}

static bool
capri_tm_is_valid_port (uint32_t port)
{
    return ((port >= CAPRI_TM_PORT_UPLINK_0) && (port <= CAPRI_TM_PORT_INGRESS));
}

sdk_ret_t
capri_tm_uplink_set_cam_type (tm_port_t port, uint32_t  entry, uint32_t  etype)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;

    uint32_t cam_compare = 1;   // 2 - compare DA, 1 - compare ethertype, 0 - reset

    if(!etype)
        cam_compare = 0;

    if (!capri_tm_port_is_uplink_port(port)) {
        SDK_TRACE_VERBOSE("%u is not a valid TM uplink port",
                          port);
        return sdk::SDK_RET_INVALID_ARG;
    }

    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
        case ${pinfo["enum"]}:
            {
                pbc_csr.hbm.hbm_port_${p}.cfg_hbm_parser_cam_type.read();
                pbc_csr.hbm.hbm_port_${p}.cfg_hbm_parser_cam_enable.read();

                if ( (entry >= 0) || (entry < 4) ) {
//:: for ent in range(4):
                    if(${ent} == entry) {
                        pbc_csr.hbm.hbm_port_${p}.cfg_hbm_parser_cam_type.entry_${ent}(etype);
                        pbc_csr.hbm.hbm_port_${p}.cfg_hbm_parser_cam_enable.entry_${ent}(cam_compare);
                    }
//:: #endfor
                } else {
                    SDK_TRACE_ERR("%u is not a valid entry", entry);
                    return sdk::SDK_RET_INVALID_ARG;
                }

                if (tm_sw_cfg_write_enabled()) {
                    pbc_csr.hbm.hbm_port_${p}.cfg_hbm_parser_cam_type.write();
                    pbc_csr.hbm.hbm_port_${p}.cfg_hbm_parser_cam_enable.write();
                }
                break;
            }
//::    #endif
//:: #endfor
        default:
            return sdk::SDK_RET_INVALID_ARG;
    }

    return sdk::SDK_RET_OK;
}

sdk_ret_t
capri_tm_uplink_set_cam_da (tm_port_t port, uint32_t  entry, uint64_t  dmac)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;

    uint32_t cam_compare = 2;   // 2 - compare DA, 1 - compare ethertype, 0 - reset

    if(!dmac)
        cam_compare = 0;

    if (!capri_tm_port_is_uplink_port(port)) {
        SDK_TRACE_ERR("%u is not a valid TM uplink port",
                      port);
        return sdk::SDK_RET_INVALID_ARG;
    }

    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
        case ${pinfo["enum"]}:
            {
                pbc_csr.hbm.hbm_port_${p}.cfg_hbm_parser_cam_da.read();
                pbc_csr.hbm.hbm_port_${p}.cfg_hbm_parser_cam_enable.read();

                if ( (entry >= 0) || (entry < 4) ) {
//:: for ent in range(4):
                    if(${ent} == entry) {
                        pbc_csr.hbm.hbm_port_${p}.cfg_hbm_parser_cam_da.entry_${ent}(dmac);
                        pbc_csr.hbm.hbm_port_${p}.cfg_hbm_parser_cam_enable.entry_${ent}(cam_compare);
                    }
//:: #endfor
                } else {
                    SDK_TRACE_ERR("%u is not a valid entry", entry);
                    return sdk::SDK_RET_INVALID_ARG;
                }

                if (tm_sw_cfg_write_enabled()) {
                    pbc_csr.hbm.hbm_port_${p}.cfg_hbm_parser_cam_da.write();
                    pbc_csr.hbm.hbm_port_${p}.cfg_hbm_parser_cam_enable.write();
                }
                break;
            }
//::    #endif
//:: #endfor
        default:
            return sdk::SDK_RET_INVALID_ARG;
    }

    return sdk::SDK_RET_OK;
}

sdk_ret_t
capri_tm_uplink_set_cam_cos (tm_port_t port, uint32_t  entry, uint32_t  cos)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;

    if (!capri_tm_port_is_uplink_port(port)) {
        SDK_TRACE_ERR("%u is not a valid TM uplink port",
                      port);
        return sdk::SDK_RET_INVALID_ARG;
    }

    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
        case ${pinfo["enum"]}:
            {
                pbc_csr.hbm.hbm_port_${p}.cfg_hbm_parser_cam_cos.read();

                if ( (entry >= 0) || (entry < 4) ) {
//:: for ent in range(4):
                    if(${ent} == entry) {
                        pbc_csr.hbm.hbm_port_${p}.cfg_hbm_parser_cam_cos.entry_${ent}(cos);
                    }
//:: #endfor
                } else {
                    SDK_TRACE_ERR("%u is not a valid entry", entry);
                    return sdk::SDK_RET_INVALID_ARG;
                }

                if (tm_sw_cfg_write_enabled()) {
                    pbc_csr.hbm.hbm_port_${p}.cfg_hbm_parser_cam_cos.write();
                }
                break;
            }
//::    #endif
//:: #endfor
        default:
            return sdk::SDK_RET_INVALID_ARG;
    }

    return sdk::SDK_RET_OK;
}

sdk_ret_t
capri_tm_set_uplink_iq_to_p4_oq_map (tm_port_t  port, tm_q_t iq, tm_q_t p4_q)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;

    cpp_int oq_map_val;

    if (!capri_tm_port_is_uplink_port(port)) {
        SDK_TRACE_ERR("%u is not a valid TM uplink port",
                      port);
        return sdk::SDK_RET_INVALID_ARG;
    }

    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
        case ${pinfo["enum"]}:
            {
                pbc_csr.cfg_parser${p}.read();
                oq_map_val = pbc_csr.cfg_parser${p}.oq_map();

                cpp_helper.set_slc(oq_map_val, p4_q,
                                   iq * 5,
                                   ((iq + 1) * 5) - 1);

                pbc_csr.cfg_parser${p}.oq_map(oq_map_val);

                if (tm_sw_cfg_write_enabled()) {
                    pbc_csr.cfg_parser${p}.write();
                }
                break;
            }
//::    #endif
//:: #endfor
        default:
            return sdk::SDK_RET_INVALID_ARG;
    }

    return sdk::SDK_RET_OK;
}

sdk_ret_t
capri_tm_uplink_iq_no_drop_update (tm_port_t port, tm_q_t iq, bool no_drop)
{
    if (!capri_tm_port_is_uplink_port(port)) {
        SDK_TRACE_ERR("%u is not a valid TM uplink port", port);
        return sdk::SDK_RET_INVALID_ARG;
    }

    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    cap_pbchbm_csr_t &hbm_csr = pbc_csr.hbm;
    cpp_int no_drop_val;

    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
        case ${pinfo["enum"]}:
            {
                if (port_supports_hbm_contexts(port)) {
                    // per port no_drop config in hbm
                    hbm_csr.hbm_port_${p}.cfg_hbm_context.read();
                    no_drop_val =
                            hbm_csr.hbm_port_${p}.cfg_hbm_context.no_drop();
                    if (no_drop == true) {
                        no_drop_val |= (1 << iq);
                    } else {
                        no_drop_val &= ~(1 << iq);
                    }
                    hbm_csr.hbm_port_${p}.cfg_hbm_context.no_drop(no_drop_val);
                    if (tm_sw_cfg_write_enabled()) {
                        hbm_csr.hbm_port_${p}.cfg_hbm_context.write();
                    }
                }
                break;
            }
//::    #endif
//:: #endfor
        default:
            return sdk::SDK_RET_ERR;
    }
    return sdk::SDK_RET_OK;
}

sdk_ret_t
capri_tm_uplink_q_params_update (tm_port_t port, tm_uplink_q_params_t *q_params)
{
    tm_q_t iq = q_params->iq;

    /* Do some sanity checks for port and iq */
    if (!capri_tm_port_is_uplink_port(port)) {
        SDK_TRACE_ERR("%u is not a valid TM uplink port",
                      port);
        return sdk::SDK_RET_INVALID_ARG;
    }

    tm_port_type_e port_type = capri_tm_get_port_type(port);
    if (q_params->mtu > tm_cfg_profile()->jumbo_mtu[port_type]) {
        SDK_TRACE_ERR("Invalid mtu %u larger than the jumbo %u",
                      q_params->mtu, tm_cfg_profile()->jumbo_mtu[port_type]);
        return sdk::SDK_RET_INVALID_ARG;
    }

    if ((q_params->p4_q < (signed)CAPRI_TM_P4_UPLINK_IQ_OFFSET) ||
        (q_params->p4_q >= (signed)capri_tm_get_num_iqs_for_port_type(TM_PORT_TYPE_P4IG))) {
        SDK_TRACE_ERR("Invalid P4 Oq %u for uplink port %u",
                      q_params->p4_q, port);
        return sdk::SDK_RET_INVALID_ARG;
    }

    stringstream data;
    data << hex << endl;
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    cap_pbchbm_csr_t &hbm_csr = pbc_csr.hbm;
    cpp_int xoff_val;
    cpp_int xon_val;
    cpp_int oq_map_val;
    cpp_int port_payload_occupancy_val;
    uint32_t xoff_threshold;
    uint32_t xon_threshold;
    uint32_t hbm_context;
    uint32_t num_hbm_contexts_per_port;
    cap_pbc_oq_map_t oq_map_decoder;

    oq_map_decoder.init();
    num_hbm_contexts_per_port = tm_cfg_profile()->num_qs[TM_PORT_TYPE_UPLINK];
    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
        case ${pinfo["enum"]}:
            {
                // P4 oq derivation register
                pbc_csr.cfg_parser${p}.read();
                oq_map_val = pbc_csr.cfg_parser${p}.oq_map();

                cpp_helper.set_slc(oq_map_val, q_params->p4_q,
                                    iq * 5,
                                    ((iq + 1) * 5) - 1);

                pbc_csr.cfg_parser${p}.oq_map(oq_map_val);

                oq_map_decoder.all(pbc_csr.cfg_parser${p}.oq_map());
                oq_map_decoder.set_name("cap0.pb.pbc.cfg_parser${p}.decoder");
                if (tm_sw_cfg_write_enabled()) {
                    oq_map_decoder.show();

                    ${trace_register("pbc_csr.cfg_parser" + str(p))}
                    pbc_csr.cfg_parser${p}.write();
                }

                // MTU
                pbc_csr.port_${p}.cfg_account_mtu_table.read();
                switch (iq) {
//::        for pg in range(port_info[p]["pgs"]):
                    case ${pg}:
                        {
                            /* Update the MTU in the MTU register */
                            pbc_csr.port_${p}.cfg_account_mtu_table.pg${pg}(
                                bytes_to_cells(q_params->mtu));
                            break;
                        }
//::        #endfor
                    default:
                        return sdk::SDK_RET_ERR;
                }

                if (tm_sw_cfg_write_enabled()) {
                    ${trace_register("pbc_csr.port_" + str(p) + ".cfg_account_mtu_table")}
                    pbc_csr.port_${p}.cfg_account_mtu_table.write();
                }

                if (port_supports_hbm_contexts(port)) {
#if 0
                    // Deprecated:
                    // user specified xoff threshold is the offset from payload
                    // occupancy. Read the payload occupancy and recalculate
                    // xoff threshold to be programmed

                    hbm_csr.hbm_port_${p}.cfg_hbm_eth_payload_occupancy.read();
                    port_payload_occupancy_val =
                                    hbm_csr.hbm_port_${p}.
                                    cfg_hbm_eth_payload_occupancy.threshold();
                    payload_occupancy = cpp_helper.get_slc(
                        port_payload_occupancy_val,
                        iq*19, ((iq + 1) * 19) - 1).convert_to<uint32_t>();
                    payload_occupancy_bytes = payload_occupancy << 10;
                    xoff_threshold = q_params->xoff_threshold;
                    if (xoff_threshold &&
                                   (payload_occupancy_bytes > xoff_threshold)) {
                        xoff_threshold =
                                   payload_occupancy_bytes - xoff_threshold;
                    } else {
                        xoff_threshold = 0;
                    }
                    xoff_threshold >>= 9;
#endif
                    // xoff and xon thresholds are in 512B units in register.
                    // So right shift by 9 (using ceil value for xon and floor
                    // for xoff)

                    xoff_threshold =
                                (q_params->xoff_threshold + (1<<9) - 1) >> 9;
                    xon_threshold =
                                (q_params->xon_threshold + (1<<9) - 1) >> 9;

                    hbm_csr.cfg_hbm_threshold.read();
                    xoff_val = hbm_csr.cfg_hbm_threshold.xoff();
                    xon_val = hbm_csr.cfg_hbm_threshold.xon();
                    hbm_context =
                           iq + (num_hbm_contexts_per_port * ${pinfo["enum"]});

                    // 20 bits per hbm_context
                    cpp_helper.set_slc(xoff_val, xoff_threshold,
                                       hbm_context * 20,
                                       ((hbm_context + 1) * 20) - 1);
                    // 20 bits per hbm_context
                    cpp_helper.set_slc(xon_val, xon_threshold,
                                       hbm_context * 20,
                                       ((hbm_context + 1) * 20) - 1);
                    hbm_csr.cfg_hbm_threshold.xoff(xoff_val);
                    hbm_csr.cfg_hbm_threshold.xon(xon_val);

                    // Write all the registers
                    if (tm_sw_cfg_write_enabled()) {
                        ${trace_register("pbc_csr.hbm.cfg_hbm_threshold")}
                        hbm_csr.cfg_hbm_threshold.write();
                    }
                }
                break;
            }
//::    #endif
//:: #endfor
        default:
            return sdk::SDK_RET_ERR;
    }
    return sdk::SDK_RET_OK;
}

sdk_ret_t
capri_tm_uplink_input_map_update (tm_port_t port, uint32_t dot1q_pcp, tm_q_t iq)
{
    if (!capri_tm_port_is_uplink_port(port)) {
        SDK_TRACE_ERR("%u is not a valid TM uplink port", port);
        return sdk::SDK_RET_INVALID_ARG;
    }
    stringstream data;
    data << hex << endl;
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    cap_pbchbm_csr_t &hbm_csr = pbc_csr.hbm;
    cpp_int tc_map_reg_val;
    uint32_t tc;
    uint32_t nbits;

    tc = dot1q_pcp;

    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
        case ${pinfo["enum"]}:
            {
                nbits = ${int(math.log(pinfo["pgs"], 2))};
                hbm_csr.hbm_port_${p}.cfg_hbm_tc_to_q.read();
                tc_map_reg_val = hbm_csr.hbm_port_${p}.cfg_hbm_tc_to_q.table();

                cpp_helper.set_slc(tc_map_reg_val, iq,
                                    tc * nbits,
                                    ((tc+1) * nbits) - 1);

                /* Update and write the tc to PG mapping */
                hbm_csr.hbm_port_${p}.cfg_hbm_tc_to_q.table(tc_map_reg_val);
                if (tm_sw_cfg_write_enabled()) {
                    ${trace_register("pbc_csr.hbm.hbm_port_" + str(p) + ".cfg_hbm_tc_to_q")}
                    hbm_csr.hbm_port_${p}.cfg_hbm_tc_to_q.write();
                }
                break;
            }
//::    #endif
//:: #endfor
        default:
            return sdk::SDK_RET_INVALID_ARG;
    }
    SDK_TRACE_DEBUG("%s", data.str().c_str());
    return sdk::SDK_RET_OK;
}

sdk_ret_t
capri_tm_uplink_input_dscp_map_update (tm_port_t port, uint32_t tc,
                                       bool *ip_dscp)
{
    if (!capri_tm_port_is_uplink_port(port)) {
        SDK_TRACE_ERR("%u is not a valid TM uplink port",
                      port);
        return sdk::SDK_RET_INVALID_ARG;
    }
    stringstream data;
    data << hex << endl;
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    cap_pbchbm_csr_t &hbm_csr = pbc_csr.hbm;
    cpp_int dscp_map_val;
    int use_ip = 0;

    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
        case ${pinfo["enum"]}:
            {
                hbm_csr.hbm_port_${p}.cfg_hbm_parser.read();
                dscp_map_val = hbm_csr.hbm_port_${p}.cfg_hbm_parser.dscp_map();

                for (unsigned i = 0; i < TM_MAX_DSCP_VALS; i++) {
                    if (ip_dscp[i]) {
                        cpp_helper.set_slc(dscp_map_val,
                                           tc,
                                           i * 3,
                                           ((i+1) * 3) - 1);
                    }
                }

                use_ip = (dscp_map_val ? 1 : 0);

                hbm_csr.hbm_port_${p}.cfg_hbm_parser.use_dot1q(1);
                hbm_csr.hbm_port_${p}.cfg_hbm_parser.use_ip(use_ip);
                hbm_csr.hbm_port_${p}.cfg_hbm_parser.dscp_map(dscp_map_val);
                if (tm_sw_cfg_write_enabled()) {
                    ${trace_register("pbc_csr.hbm.hbm_port_" + str(p) + ".cfg_hbm_parser")}
                    hbm_csr.hbm_port_${p}.cfg_hbm_parser.write();
                }
                break;
            }
//::    #endif
//:: #endfor
        default:
            return sdk::SDK_RET_INVALID_ARG;
    }
    SDK_TRACE_DEBUG("%s", data.str().c_str());
    return sdk::SDK_RET_OK;
}

/**
 * @brief  get the PFC-COS mask for incoming pause frames
 */
sdk_ret_t
capri_tm_get_uplink_mac_xoff (tm_port_t port, uint32_t *xoff_cos_bitmap)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;

    if (!capri_tm_port_is_uplink_port(port)) {
        SDK_TRACE_ERR("%u is not a valid TM uplink port",
                      port);
        return sdk::SDK_RET_INVALID_ARG;
    }

    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
        case ${pinfo["enum"]}:
            {
                pbc_csr.port_${p}.cfg_mac_xoff.read();
                *xoff_cos_bitmap = pbc_csr.port_${p}.cfg_mac_xoff.enable().
                                                    convert_to<uint32_t>();
                break;
            }
//::    #endif
//:: #endfor
        default:
            return sdk::SDK_RET_INVALID_ARG;
    }
    return sdk::SDK_RET_OK;
}

/**
 * @brief  Enable/Disable reacting to incoming pause frames
 * @param[in] port           PB port
 * @param[in] reset_all_xoff reset for all cos values
 * @param[in] set_all_xoff   set for all cos values
 * @param[in] reset_pfc_xoff reset for pfc xoff cos
 * @param[in] set_pfc_xoff   set for pfc xoff cos
 * @param[in] xoff_cos       pfc xoff cos. Applicable only if
 *                           reset_pfc_xoff/set_pfc_xoff is true
 */
sdk_ret_t
capri_tm_set_uplink_mac_xoff (tm_port_t port,
                              bool reset_all_xoff,
                              bool set_all_xoff,
                              bool reset_pfc_xoff,
                              bool set_pfc_xoff,
                              uint32_t xoff_cos_bitmap)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    uint32_t xoff_enable_val;

    if (!capri_tm_port_is_uplink_port(port)) {
        SDK_TRACE_ERR("%u is not a valid TM uplink port",
                      port);
        return sdk::SDK_RET_INVALID_ARG;
    }

    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
        case ${pinfo["enum"]}:
            {
                pbc_csr.port_${p}.cfg_mac_xoff.read();
                xoff_enable_val = pbc_csr.port_${p}.cfg_mac_xoff.enable().
                                                    convert_to<uint32_t>();
                if (reset_all_xoff == true) {
                    xoff_enable_val = 0x0;
                } else if (set_all_xoff == true) {
                    xoff_enable_val = 0xff;
                }
                if (reset_pfc_xoff == true) {
                    //xoff_enable_val &= ~(1 << xoff_cos);
                    xoff_enable_val &= ~xoff_cos_bitmap;
                } else if (set_pfc_xoff == true) {
                    //xoff_enable_val |= (1 << xoff_cos);
                    xoff_enable_val |= xoff_cos_bitmap;
                }
                pbc_csr.port_${p}.cfg_mac_xoff.enable(xoff_enable_val);
                if (tm_sw_cfg_write_enabled()) {
                    pbc_csr.port_${p}.cfg_mac_xoff.write();
                }
                break;
            }
//::    #endif
//:: #endfor
        default:
            return sdk::SDK_RET_INVALID_ARG;
    }
    return sdk::SDK_RET_OK;
}

/**
 * @brief get OQ to xoff_cos map
 */
sdk_ret_t
capri_tm_get_uplink_oq_xoff_map (tm_port_t port, tm_q_t oq, uint32_t *xoff_cos)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    cpp_int xoff2oq_map_val;
    cap_pbc_eth_oq_xoff_map_t xoff2oq_map_decoder;

    if (!capri_tm_port_is_uplink_port(port)) {
        SDK_TRACE_ERR("%u is not a valid TM uplink port",
                      port);
        return sdk::SDK_RET_INVALID_ARG;
    }
    xoff2oq_map_decoder.init();
    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
        case ${pinfo["enum"]}:
            {
                pbc_csr.port_${p}.cfg_oq_xoff2oq.read();
                *xoff_cos = cpp_helper.get_slc(pbc_csr.port_${p}.cfg_oq_xoff2oq.map(),
                                               oq*3,
                                               (((oq+1)*3)-1)).convert_to<uint32_t>();
                break;
            }
//::    #endif
//:: #endfor
        default:
            return sdk::SDK_RET_INVALID_ARG;
    }
    return sdk::SDK_RET_OK;
}

/**
 * @brief map OQ to xoff_cos
 * @param[in] port      PB port
 * @param[in] oq        PB output queue to xoff
 * @param[in] xoff_cos  cos value of the incoming PFC
 */
sdk_ret_t
capri_tm_uplink_oq_update (tm_port_t port, tm_q_t oq, uint32_t xoff_cos)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    cpp_int xoff2oq_map_val;
    cap_pbc_eth_oq_xoff_map_t xoff2oq_map_decoder;

    if (!capri_tm_port_is_uplink_port(port)) {
        SDK_TRACE_ERR("%u is not a valid TM uplink port",
                      port);
        return sdk::SDK_RET_INVALID_ARG;
    }
    xoff2oq_map_decoder.init();
    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
        case ${pinfo["enum"]}:
            {
                pbc_csr.port_${p}.cfg_oq_xoff2oq.read();
                xoff2oq_map_val = pbc_csr.port_${p}.cfg_oq_xoff2oq.map();
                cpp_helper.set_slc(xoff2oq_map_val, xoff_cos, oq*3, ((oq+1)*3)-1);
                pbc_csr.port_${p}.cfg_oq_xoff2oq.map(xoff2oq_map_val);
                xoff2oq_map_decoder.all(pbc_csr.port_${p}.cfg_oq_xoff2oq.map());
                xoff2oq_map_decoder.set_name("cap0.pb.pbc.port_${p}.cfg_oq_xoff2oq.decoder");
                if (tm_sw_cfg_write_enabled()) {
                    pbc_csr.port_${p}.cfg_oq_xoff2oq.write();
                }
                break;
            }
//::    #endif
//:: #endfor
        default:
            return sdk::SDK_RET_INVALID_ARG;
    }
    return sdk::SDK_RET_OK;
}

//:: for level in range(3):
//::    parent_level = level+1
sdk_ret_t
capri_tm_scheduler_map_update_l${level} (uint32_t port,
                                         uint32_t node,
                                         tm_queue_node_params_t *node_params)
{
    stringstream data;
    data << hex << endl;
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    (void)pbc_csr;
    cpp_int node_val;
    cpp_int strict_val;

    uint32_t max_nodes = CAPRI_TM_COUNT_L${level}_NODES;

    if (node >= max_nodes) {
        SDK_TRACE_ERR("node %u exceeds the number of valid level "
                      "${level} nodes in port %u",
                      node, port);
        return sdk::SDK_RET_INVALID_ARG;
    }

    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["l"+str(parent_level)]:
        case ${pinfo["enum"]}:
            {
                pbc_csr.port_${p}.cfg_oq_arb_l${parent_level}_selection.read();
                pbc_csr.port_${p}.cfg_oq_arb_l${parent_level}_strict.read();

                strict_val = pbc_csr.port_${p}.cfg_oq_arb_l${parent_level}_strict.priority();
                cpp_helper.set_slc(strict_val,
                                    node_params->sched_type == TM_SCHED_TYPE_STRICT ? 1 : 0,
                                    node,
                                    node);

                // Reset the current node's association in all the parent level
                // nodes
//::        for parent_node in range(pinfo["l"+str(parent_level)]):
                // ${parent_node}
                node_val = pbc_csr.port_${p}.cfg_oq_arb_l${parent_level}_selection.node_${parent_node}();
                // Associate/disassociate the current node with the parent node
                cpp_helper.set_slc(node_val,
                                    node_params->parent_node == ${parent_node} ? 1 : 0,
                                    node,
                                    node);
                pbc_csr.port_${p}.cfg_oq_arb_l${parent_level}_selection.node_${parent_node}(node_val);
//::        #endfor
                pbc_csr.port_${p}.cfg_oq_arb_l${parent_level}_strict.priority(strict_val);

                /* Write the registers */
                if (tm_sw_cfg_write_enabled()) {
                    ${trace_register("pbc_csr.port_" + str(p) + ".cfg_oq_arb_l" + str(parent_level) + "_selection")}
                    ${trace_register("pbc_csr.port_" + str(p) + ".cfg_oq_arb_l" + str(parent_level) + "_strict")}

                    pbc_csr.port_${p}.cfg_oq_arb_l${parent_level}_selection.write();
                    pbc_csr.port_${p}.cfg_oq_arb_l${parent_level}_strict.write();
                }
                break;
            }
//::    #endif
//:: #endfor
        default:
            return sdk::SDK_RET_ERR;
    }

    pbc_csr.cfg_sched.read();
    pbc_csr.cfg_sched.dhs_selection( ${level}*2 );
    if (tm_sw_cfg_write_enabled()) {
        ${trace_register("pbc_csr.cfg_sched")}
        pbc_csr.cfg_sched.write();
    }

    pbc_csr.cfg_dhs_mem.address(port*max_nodes + node);
    if (tm_sw_cfg_write_enabled()) {
        ${trace_register("pbc_csr.cfg_dhs_mem")}
        pbc_csr.cfg_dhs_mem.write();
    }

    uint64_t scheduler_rate;
    if (node_params->sched_type == TM_SCHED_TYPE_STRICT) {
        scheduler_rate = (uint64_t)CAPRI_TM_SCHEDULER_RATE_REFRESH_INTERVAL_US*node_params->strict.rate;
        scheduler_rate /= 1000000;
        if (scheduler_rate >= (1ull << 32)) {
            // This should never happen it's in 80 Tbps range
            SDK_ASSERT(0);
        }
    }

    uint32_t quota = (node_params->sched_type == TM_SCHED_TYPE_STRICT ?
                      scheduler_rate : node_params->dwrr.weight);

    pbc_csr.dhs_sched.entry[0].command(1);   //1: overwrite quota and credits
    pbc_csr.dhs_sched.entry[0].current_credit(quota);
    pbc_csr.dhs_sched.entry[0].quota(quota);
    if (tm_sw_cfg_write_enabled()) {
        ${trace_register("pbc_csr.dhs_sched.entry[0]")}
        pbc_csr.dhs_sched.entry[0].write();
    }
    SDK_TRACE_DEBUG("%s", data.str().c_str());
    SDK_TRACE_DEBUG("Updated the output queue scheduler on port %u "
                    "level %u, node %u",
                    port, ${level}, node);

    return sdk::SDK_RET_OK;
}

//:: #endfor

sdk_ret_t
capri_tm_scheduler_map_update (uint32_t port,
                               tm_queue_node_type_e node_type,
                               uint32_t node,
                               tm_queue_node_params_t *node_params)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;

    if (!capri_tm_is_valid_port(port)) {
        SDK_TRACE_ERR("%u is not a valid TM port",
                      port);
        return sdk::SDK_RET_INVALID_ARG;
    }

    switch (node_type) {
        case TM_QUEUE_NODE_TYPE_LEVEL_1:
            ret = capri_tm_scheduler_map_update_l0(port, node, node_params);
            break;

        case TM_QUEUE_NODE_TYPE_LEVEL_2:
            ret = capri_tm_scheduler_map_update_l1(port, node, node_params);
            break;

        default:
        case TM_QUEUE_NODE_TYPE_LEVEL_3:
            ret = capri_tm_scheduler_map_update_l2(port, node, node_params);
            break;
    }
    return ret;
}

/* Program the lif value on an uplink port */
sdk_ret_t
capri_tm_uplink_lif_set (uint32_t port,
                         uint32_t lif)
{
    if (!capri_tm_port_is_uplink_port(port)) {
        SDK_TRACE_ERR("%u is not a valid TM uplink port",
                      port);
        return sdk::SDK_RET_INVALID_ARG;
    }

    stringstream data;
    data << hex << endl;
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;

    pbc_csr.cfg_src_port_to_lif_map.read();
    /* Update the value in the csr */
    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] != "uplink":
//::        continue
//::    #endif
        case ${pinfo["enum"]}:
            {
                pbc_csr.cfg_src_port_to_lif_map.entry_${p}(lif);
                break;
            }
//:: #endfor
        default:
            return sdk::SDK_RET_ERR;
    }

    /* Write the csr */
    ${trace_register("pbc_csr.cfg_src_port_to_lif_map")}
    pbc_csr.cfg_src_port_to_lif_map.write();
    SDK_TRACE_DEBUG("%s", data.str().c_str());

    SDK_TRACE_DEBUG("Set the lif %u on port %u",
                    lif, port);

    return sdk::SDK_RET_OK;
}

uint32_t
capri_tm_get_hbm_occupancy(tm_hbm_fifo_type_e fifo_type, uint32_t context)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    cap_pbchbm_csr_t &hbm_csr = pbc_csr.hbm;
    uint32_t occupancy = UINT32_MAX;

    if (context >= capri_tm_max_hbm_contexts_for_fifo(fifo_type)) {
        SDK_TRACE_ERR("Invalid context %u for fifo %u", context, fifo_type);
        return sdk::SDK_RET_INVALID_ARG;
    }

    stringstream data;
    data << hex << endl;
    switch(fifo_type) {
//:: for fifo_type, finfo in hbm_fifo_info.items():
        case ${fifo_type}:
            switch (context) {
//::    for context in range(finfo['count']):
                case ${context}:
                    {
                        hbm_csr.sta_hbm_${finfo["reg_name"]}_context_${context}.read();
                        ${trace_register("pbc_csr.hbm.sta_hbm_" + finfo["reg_name"] + "_context_" + str(context))}
                        occupancy =
                            hbm_csr.sta_hbm_${finfo["reg_name"]}_context_${context}.depth().convert_to<uint32_t>();
                    }
                    break;
//::    #endfor
            }
            break;
//:: #endfor
        default:
            return occupancy;
    }
    //SDK_TRACE_DEBUG("%s", data.str().c_str());

    return occupancy;
}

static void
capri_tm_get_buffer_occupancy (tm_port_t port, tm_q_t iq,
                               uint32_t *cell_occupancy,
                               uint32_t *peak_occupancy)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;

    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
        case ${pinfo["enum"]}:
            {
                // ${pinfo["enum"]}
                pbc_csr.port_${p}.sta_account.read();
                switch (iq) {
//::        for pg in range(pinfo["pgs"]):
                    case ${pg}:
                        {
                            *cell_occupancy = pbc_csr.port_${p}.sta_account.occupancy_${pg}().convert_to<uint32_t>();
                            *peak_occupancy = pbc_csr.port_${p}.sta_account.sp_held_${pg}().convert_to<uint32_t>();
                            break;
                        }
//::        #endfor
                    default:
                        return;
                }
                break;
            }
//:: #endfor
        default:
            break;
    }
}

static sdk_ret_t
capri_tm_sop_eop_check (tm_port_t port)
{
    uint32_t tries         = 0;
    uint32_t max_tries     = 1000;
    uint32_t sop_count_in  = 0;
    uint32_t eop_count_in  = 0;
    uint32_t sop_count_out = 0;
    uint32_t eop_count_out = 0;
    cap_top_csr_t &cap0    = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;

    while (tries < max_tries) {
        pbc_csr.cnt_flits[port].read();
        sop_count_in = pbc_csr.cnt_flits[port].sop_in().convert_to<uint32_t>();
        eop_count_in = pbc_csr.cnt_flits[port].eop_in().convert_to<uint32_t>();
        sop_count_out = pbc_csr.cnt_flits[port].sop_out().convert_to<uint32_t>();
        eop_count_out = pbc_csr.cnt_flits[port].eop_out().convert_to<uint32_t>();
        if ((sop_count_in == eop_count_in) &&
            (sop_count_out == eop_count_out)) {
            SDK_TRACE_VERBOSE("Port %u sop eop match after %u tries. "
                              "sop_in %u, eop_in %u, sop_out %u, eop_out %u",
                              port, tries,
                              sop_count_in, eop_count_in,
                              sop_count_out, eop_count_out);
            break;
        }
        usleep(1000);
        tries++;
    }
    if (tries == max_tries) {
        SDK_TRACE_ERR("Port %u sop eop doesn't match after %u tries. "
                      "sop_in %u, eop_in %u, sop_out %u, eop_out %u",
                      port, tries,
                      sop_count_in, eop_count_in,
                      sop_count_out, eop_count_out);
        return sdk::SDK_RET_RETRY;
    }
    return sdk::SDK_RET_OK;
}

static sdk_ret_t
capri_tm_drain_hbm_contexts (tm_port_t port)
{
    bool all_zeroes = false;
    uint32_t tries = 0;
    uint32_t max_tries = 1000;
    uint32_t occupancy;
    uint32_t num_hbm_contexts_per_port;
    uint32_t context;
    uint32_t i;

    num_hbm_contexts_per_port = tm_cfg_profile()->num_qs[TM_PORT_TYPE_UPLINK];
    while (port_supports_hbm_contexts(port) &&
           !all_zeroes && (tries < max_tries)) {
        all_zeroes = true;
        for (i = 0; i < num_hbm_contexts_per_port; i++) {
            context = (port * num_hbm_contexts_per_port) + i;
            occupancy = capri_tm_get_hbm_occupancy(TM_HBM_FIFO_TYPE_UPLINK, context);
            if (occupancy) {
                all_zeroes = false;
            } else {
                SDK_TRACE_VERBOSE("port %u, hbm context %u 0", port, context);
            }
        }
        // TODO: Do we need a sleep here ?
        usleep(1000);
        tries++;
    }

    if (!all_zeroes && port_supports_hbm_contexts(port)) {
        SDK_TRACE_ERR("Port %u hbm queues not drained completely after %u tries",
                      port, tries);
        return sdk::SDK_RET_RETRY;
    }

    return sdk::SDK_RET_OK;
}

static sdk_ret_t
capri_tm_drain_occupancy (tm_port_t port)
{
    sdk_ret_t ret = SDK_RET_OK;
    uint32_t max_tries = 1000;
    uint32_t tries = 0;
    bool all_zeroes = false;
    uint32_t cur_occupancy = 0;
    uint32_t peak_occupancy = 0;
    uint32_t num_iqs = capri_tm_get_num_iqs_for_port(port);

    while ((all_zeroes == false) && (tries < max_tries)) {
        all_zeroes = true;
        for (uint32_t iq = 0; iq < num_iqs; iq++) {
            capri_tm_get_buffer_occupancy(port, iq, &cur_occupancy, &peak_occupancy);
            if (cur_occupancy != 0) {
                all_zeroes = false;
            } else {
                SDK_TRACE_VERBOSE("port %u, iq %u 0", port, iq);
            }
        }
        tries++;
        usleep(1000);
    }
    if (all_zeroes == false) {
        return SDK_RET_RETRY;
    }
    return ret;
}

static sdk_ret_t
capri_tm_drain_oq (tm_port_t port)
{
    sdk_ret_t ret = SDK_RET_OK;
    uint32_t max_tries = 1000;
    uint32_t tries = 0;
    bool all_zeroes = false;
    uint32_t queue_depth = 0;
    uint32_t num_oqs = capri_tm_get_num_oqs_for_port(port);
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;

    while ((all_zeroes == false) && (tries < max_tries)) {
        all_zeroes = true;
        pbc_csr.sta_oq[port].read();
        for (uint32_t oq = 0; oq < num_oqs; oq++) {
            // 16 bits per oq
            queue_depth = cpp_helper.get_slc(pbc_csr.sta_oq[port].depth_value(),
                                             oq*16,
                                             (((oq+1)*16)-1)).convert_to<uint32_t>();
            if (queue_depth != 0) {
                all_zeroes = false;
            } else {
                SDK_TRACE_VERBOSE("port %u, oq %u 0", port, oq);
            }
        }
        tries++;
        usleep(1000);
    }
    if (all_zeroes == false) {
        return SDK_RET_RETRY;
    }
    return ret;
}

sdk_ret_t
capri_tm_drain_uplink_port (tm_port_t port)
{
    sdk_ret_t ret = SDK_RET_OK;

    ret = capri_tm_drain_hbm_contexts(port);
    if (ret != SDK_RET_OK) {
        SDK_TRACE_ERR("Port %u drain. hbm contexts not drained", port);
        return ret;
    }

    // wait for the sop and eop counters to match
    ret = capri_tm_sop_eop_check(port);
    if (ret != sdk::SDK_RET_OK) {
        SDK_TRACE_ERR("Port %u drain. sop eop does not match", port);
        return ret;
    }

    // wait for occupancy to be 0
    ret = capri_tm_drain_occupancy(port);
    if (ret != SDK_RET_OK) {
        SDK_TRACE_ERR("Port %u drain, occ not drained", port);
        return ret;
    }

    // wait for oq depth to be 0
    ret = capri_tm_drain_oq(port);
    if (ret != SDK_RET_OK) {
        SDK_TRACE_ERR("Port %u drain, oq not drained", port);
        return ret;
    }

    return ret;
}

sdk_ret_t
capri_tm_flush_uplink_port (tm_port_t port, bool enable)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;

    if (!capri_tm_port_is_uplink_port(port)) {
        SDK_TRACE_ERR("%u is not a valid TM uplink port",
                      port);
        return sdk::SDK_RET_INVALID_ARG;
    }

    // Mutex lock is to avoid sequencing b/w linkmgr-ctrl thread and periodic
    // thread for now during link-down event.
    // Ideally PB registers must be programmed by HAL cfg threads.
    // For GS, since QOS changes are not supported, the only PB registers
    // which are programmed after initial bootup are the ones below.
    // This is invoked only during upgrade and link-down events.
    pthread_mutex_lock(&tm_mutex);

    stringstream data;
    data << hex << endl;
    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
        case ${pinfo["enum"]}:
            {
                pbc_csr.port_${p}.cfg_oq.read();

                // flush the oq for this port
                pbc_csr.port_${p}.cfg_oq.flush(enable ? 1 : 0);
                if (tm_sw_cfg_write_enabled()) {
                    pbc_csr.port_${p}.cfg_oq.write();
                    pbc_csr.port_${p}.cfg_oq.read();
                    ${trace_register("pbc_csr.port_" + str(p) + ".cfg_oq")}
                }
                break;
            }
//::    #endif
//:: #endfor
        default:
            pthread_mutex_unlock(&tm_mutex);
            return sdk::SDK_RET_ERR;
    }
    SDK_TRACE_VERBOSE("%s", data.str().c_str());

    pthread_mutex_unlock(&tm_mutex);

    SDK_TRACE_VERBOSE("%s uplink port %u flush, ret %u",
                      enable ? "Enable" : "Disable", port, ret);
    return ret;
}

sdk_ret_t
capri_tm_write_control_uplink_port (tm_port_t port, bool enable)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;

    if (!capri_tm_port_is_uplink_port(port)) {
        SDK_TRACE_ERR("%u is not a valid TM uplink port",
                      port);
        return sdk::SDK_RET_INVALID_ARG;
    }

    // Mutex lock is to avoid sequencing b/w linkmgr-ctrl thread and periodic
    // thread for now during link-down event.
    // Ideally PB registers must be programmed by HAL cfg threads.
    // For GS, since QOS changes are not supported, the only PB registers
    // which are programmed after initial bootup are the ones below.
    // This is invoked only during upgrade and link-down events.
    pthread_mutex_lock(&tm_mutex);

    stringstream data;
    data << hex << endl;
    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
        case ${pinfo["enum"]}:
            {
                pbc_csr.port_${p}.cfg_write_control.read();

                // dont accept any packet into port
                pbc_csr.port_${p}.cfg_write_control.enable(enable ? 1 : 0);

                // flush the oq for this port
                if (tm_sw_cfg_write_enabled()) {
                    pbc_csr.port_${p}.cfg_write_control.write();
                    pbc_csr.port_${p}.cfg_write_control.read();
                    ${trace_register("pbc_csr.port_" + str(p) + ".cfg_write_control")}
                }
                break;
            }
//::    #endif
//:: #endfor
        default:
            pthread_mutex_unlock(&tm_mutex);
            return sdk::SDK_RET_ERR;
    }
    SDK_TRACE_VERBOSE("%s", data.str().c_str());

    pthread_mutex_unlock(&tm_mutex);

    SDK_TRACE_VERBOSE("%s uplink port %u write control, ret %u",
                      enable ? "Enable" : "Disable", port, ret);
    return ret;
}

sdk_ret_t
capri_tm_enable_disable_uplink_port (tm_port_t port, bool enable)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;

    if (!capri_tm_port_is_uplink_port(port)) {
        SDK_TRACE_VERBOSE("%u is not a valid TM uplink port",
                          port);
        return sdk::SDK_RET_INVALID_ARG;
    }

    // Mutex lock is to avoid sequencing b/w linkmgr-ctrl thread and periodic
    // thread for now during link-down event.
    // Ideally PB registers must be programmed by HAL cfg threads.
    // For GS, since QOS changes are not supported, the only PB registers
    // which are programmed after initial bootup are the ones below.
    // This is invoked only during upgrade and link-down events.
    pthread_mutex_lock(&tm_mutex);

    if (enable) {
        /* Make sure the contexts are free */
        ret = capri_tm_drain_uplink_port(port);
        if (ret != sdk::SDK_RET_OK) {
            SDK_TRACE_ERR("Port %u is not fully drained. Retry later", port);
            pthread_mutex_unlock(&tm_mutex);
            return ret;
        }
    }

    stringstream data;
    data << hex << endl;
    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
        case ${pinfo["enum"]}:
            {
                pbc_csr.port_${p}.cfg_write_control.read();
                pbc_csr.port_${p}.cfg_oq.read();

                // dont accept any packet into port
                pbc_csr.port_${p}.cfg_write_control.enable(enable ? 1 : 0);

                // flush the oq for this port
                pbc_csr.port_${p}.cfg_oq.flush(enable ? 0 : 1);
                if (tm_sw_cfg_write_enabled()) {
                    pbc_csr.port_${p}.cfg_write_control.write();
                    pbc_csr.port_${p}.cfg_write_control.read();
                    ${trace_register("pbc_csr.port_" + str(p) + ".cfg_write_control")}

                    pbc_csr.port_${p}.cfg_oq.write();
                    pbc_csr.port_${p}.cfg_oq.read();
                    ${trace_register("pbc_csr.port_" + str(p) + ".cfg_oq")}
                }
                break;
            }
//::    #endif
//:: #endfor
        default:
            pthread_mutex_unlock(&tm_mutex);
            return sdk::SDK_RET_ERR;
    }
    SDK_TRACE_DEBUG("%s", data.str().c_str());

    /* If we're disabling the port, we need to wait until all HBM contexts are
     * free and sop/eop counts to match
     */
    if (!enable) {
        ret = capri_tm_drain_uplink_port(port);
        if (ret != sdk::SDK_RET_OK) {
            SDK_TRACE_ERR("Port %u drain, not fully drained", port);
        }
    }

    pthread_mutex_unlock(&tm_mutex);

    SDK_TRACE_DEBUG("%s uplink port %u, ret %u",
                    enable ? "Enable" : "Disable", port, ret);
    return ret;
}

sdk_ret_t
capri_tm_hw_config_load_poll (int phase)
{
    if (phase == 0) {
        cap_pb_init_done(0,0);
    }
    return sdk::SDK_RET_OK;
}

sdk_ret_t
capri_tm_asic_init (void)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;

    // Do a sw reset prior to reconfiguring the islands etc
    pbc_csr.cfg_pbc_control.sw_reset(1);
    pbc_csr.cfg_pbc_control.write();
    pbc_csr.hbm.cfg_hbm.control_sw_reset(1);
    pbc_csr.hbm.cfg_hbm.write();

    pbc_csr.cfg_pbc_control.read();
    pbc_csr.hbm.cfg_hbm.read();

    pbc_csr.cfg_pbc_control.sw_reset(0);
    pbc_csr.cfg_pbc_control.write();
    pbc_csr.hbm.cfg_hbm.control_sw_reset(0);
    pbc_csr.hbm.cfg_hbm.write();

    pbc_csr.cfg_pbc_control.read();
    pbc_csr.hbm.cfg_hbm.read();
    //    cap_pb_init_start(0,0);
    //    cap_pb_init_done(0,0);
    return sdk::SDK_RET_OK;
}

static sdk_ret_t
alloc_cells (tm_port_type_e port_type, uint32_t *pbc_cell_chunks,
             capri_tm_buf_cfg_t *buf_cfg)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;
    uint32_t reserved_mtus;
    uint32_t reserved_cells;
    uint32_t headroom_cells;
    uint32_t chunks_per_q;
    uint32_t island;
    uint32_t num_qs;
    uint32_t reserved_chunks;
    uint32_t high_perf_reserved_chunks;
    uint32_t headroom_chunks;
    uint32_t chunks_needed;
    uint32_t num_high_perf_qs = tm_cfg_profile()->num_p4_high_perf_qs;

    island = capri_tm_get_island_for_port_type(port_type);

    num_qs = tm_cfg_profile()->num_qs[port_type];
    if (port_type == TM_PORT_TYPE_UPLINK) {
        //num_qs =
        //  1 + (tm_cfg_profile()->num_qs[port_type] * tm_cfg_profile()->num_active_uplink_ports);
        num_qs =
            CAPRI_TM_NUM_BMC_QUEUES +
                (tm_cfg_profile()->num_qs[port_type] * tm_cfg_profile()->num_active_uplink_ports);
    }

    reserved_mtus = tm_asic_profile()->port[port_type].reserved_mtus;
    headroom_cells = tm_asic_profile()->port[port_type].headroom_cells;

    headroom_chunks = cells_to_chunks(headroom_cells);

    if (reserved_mtus) {
        // Allocate reserved_mtus and headroom_cells from the given island
        reserved_cells =
            bytes_to_cells(tm_cfg_profile()->jumbo_mtu[port_type]) * reserved_mtus;

        reserved_chunks = cells_to_chunks(reserved_cells);

        high_perf_reserved_chunks = reserved_chunks * 2;

        chunks_needed = (reserved_chunks + headroom_chunks) * (num_qs - num_high_perf_qs);
        chunks_needed = chunks_needed +
            (high_perf_reserved_chunks + headroom_chunks) * num_high_perf_qs;

        if (pbc_cell_chunks[island] < chunks_needed) {
            SDK_TRACE_ERR("Error allocating reserved pbc chunks "
                          "island %u port_type %u num_qs %u reserved_cells %u "
                          "headroom_cells %u available %u",
                          island, port_type, num_qs, reserved_cells,
                          headroom_cells, chunks_to_cells(pbc_cell_chunks[island]));
            return sdk::SDK_RET_NO_RESOURCE;
        }
        pbc_cell_chunks[island] -= chunks_needed;
        buf_cfg->chunks_per_q[port_type] = reserved_chunks;
    } else {
        // Allocate the remaining chunks in the island for every queue
        chunks_per_q = pbc_cell_chunks[island]/num_qs;
        if (chunks_per_q < headroom_chunks) {
            SDK_TRACE_ERR("Error allocating remaining pbc chunks "
                          "island %u port_type %u num_qs %u "
                          "headroom_cells %u available %u per_q available %u",
                          island, port_type, num_qs,
                          headroom_cells,
                          chunks_to_cells(pbc_cell_chunks[island]),
                          chunks_to_cells(chunks_per_q));
            return sdk::SDK_RET_NO_RESOURCE;
        }
        pbc_cell_chunks[island] -= chunks_per_q * num_qs;
        buf_cfg->chunks_per_q[port_type] = chunks_per_q - headroom_chunks;
    }
    if (chunks_to_cells(buf_cfg->chunks_per_q[port_type]) <
        bytes_to_cells(tm_cfg_profile()->jumbo_mtu[port_type])) {
        SDK_TRACE_ERR("Error reserved cells %u/bytes %u is less than the "
                      "jumbo mtu  %u",
                      chunks_to_cells(buf_cfg->chunks_per_q[port_type]),
                      cells_to_bytes(chunks_to_cells(buf_cfg->chunks_per_q[port_type])),
                      tm_cfg_profile()->jumbo_mtu[port_type]);
        return sdk::SDK_RET_NO_RESOURCE;
    }
    SDK_TRACE_DEBUG("allocated cells %u port_type %u headroom %u",
                    chunks_to_cells(buf_cfg->chunks_per_q[port_type]),
                    port_type,
                    chunks_to_cells(headroom_chunks));

    return ret;
}

static sdk_ret_t
capri_tm_alloc_pbc_buffers (capri_tm_buf_cfg_t *buf_cfg)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;
    uint32_t pbc_cell_chunks[CAPRI_TM_NUM_BUFFER_ISLANDS] = {0};

    for (unsigned i = 0; i < SDK_ARRAY_SIZE(pbc_cell_chunks); i++) {
        pbc_cell_chunks[i] = capri_tm_get_max_cell_chunks_for_island(i);
    }

    /* First allocate buffer cells for the P4 ports and
     * then distribute the remaining equally among the different classes
     */
    ret = alloc_cells(TM_PORT_TYPE_P4IG, pbc_cell_chunks, buf_cfg);
    if (ret != sdk::SDK_RET_OK) {
        return ret;
    }

    ret = alloc_cells(TM_PORT_TYPE_P4EG, pbc_cell_chunks, buf_cfg);
    if (ret != sdk::SDK_RET_OK) {
        return ret;
    }

    /* Now allocate the remaining uniformly */
    ret = alloc_cells(TM_PORT_TYPE_UPLINK, pbc_cell_chunks, buf_cfg);
    if (ret != sdk::SDK_RET_OK) {
        return ret;
    }

    ret = alloc_cells(TM_PORT_TYPE_DMA, pbc_cell_chunks, buf_cfg);
    if (ret != sdk::SDK_RET_OK) {
        return ret;
    }

    for (unsigned i = 0; i < SDK_ARRAY_SIZE(pbc_cell_chunks); i++) {
        SDK_TRACE_DEBUG("unallocated cells island %u cells %u",
                        i, chunks_to_cells(pbc_cell_chunks[i]));
    }

    return sdk::SDK_RET_OK;
}

static sdk_ret_t
capri_tm_alloc_hbm_buffers (capri_tm_buf_cfg_t *buf_cfg)
{
    uint32_t num_hbm_contexts[NUM_TM_HBM_FIFO_TYPES] = {0};
    uint64_t total_hbm_chunks;
    uint32_t fifo_type;

    // HBM allocation
    //
    // Out of the whole available HBM payload and control has to be carved.
    // Control needs to be 1/50th of payload
    num_hbm_contexts[TM_HBM_FIFO_TYPE_UPLINK] =
        tm_cfg_profile()->num_qs[TM_PORT_TYPE_UPLINK] * tm_cfg_profile()->num_active_uplink_ports;
    num_hbm_contexts[TM_HBM_FIFO_TYPE_TXDMA] = tm_cfg_profile()->num_qs[TM_PORT_TYPE_DMA];

    total_hbm_chunks = tm_cfg_profile()->hbm_fifo_size/CAPRI_TM_HBM_FIFO_ALLOC_SIZE;

    // This calculation involves taking the floor value for both
    // total_hbm_chunks and control_chunks
    uint64_t control_chunks;
    uint64_t payload_chunks;

    control_chunks = total_hbm_chunks/(1 + tm_asic_profile()->hbm_fifo_control_scale_factor);
    payload_chunks = control_chunks * tm_asic_profile()->hbm_fifo_control_scale_factor;
    SDK_ASSERT((payload_chunks + control_chunks) <= total_hbm_chunks);

    SDK_TRACE_DEBUG("Available hbm chunks total %u payload %u control %u",
                    total_hbm_chunks, payload_chunks, control_chunks);

    uint64_t total_reserved_hbm_chunks = 0;
    uint64_t total_hbm_contexts = 0;
    uint64_t reserved_hbm_chunks_per_context[NUM_TM_HBM_FIFO_TYPES] = {0};
    for (fifo_type = 0; fifo_type < NUM_TM_HBM_FIFO_TYPES; fifo_type++) {
        reserved_hbm_chunks_per_context[fifo_type] =
            hbm_bytes_to_chunks(
                tm_asic_profile()->hbm_fifo_reserved_bytes_per_context[fifo_type]);

        if (num_hbm_contexts[fifo_type] > capri_tm_max_hbm_contexts_for_fifo(fifo_type)) {
            SDK_TRACE_ERR("num hbm contexts %u for fifo %u exceeds "
                          "max available %u",
                          num_hbm_contexts[fifo_type],
                          fifo_type,
                          capri_tm_max_hbm_contexts_for_fifo(fifo_type));
            return sdk::SDK_RET_INVALID_ARG;
        }
        uint64_t reserved_hbm_chunks =
            reserved_hbm_chunks_per_context[fifo_type] * num_hbm_contexts[fifo_type];

        total_reserved_hbm_chunks += reserved_hbm_chunks;
        total_hbm_contexts += num_hbm_contexts[fifo_type];
    }

    if (payload_chunks < total_reserved_hbm_chunks) {
        SDK_TRACE_ERR("Error allocating hbm fifo . Available chunks %u "
                      "total reserved required %u ",
                      payload_chunks, total_reserved_hbm_chunks);
        return sdk::SDK_RET_NO_RESOURCE;
    }
    uint64_t rem_payload_chunks = payload_chunks - total_reserved_hbm_chunks;

    // Allocate the rem_payload_chunks for the total number of queues
    //
    uint64_t payload_chunks_per_context = rem_payload_chunks/total_hbm_contexts;

    SDK_TRACE_DEBUG("HBM fifo allocation total payload %u, reserved %u "
                    "remaining %u total_contexts %u "
                    "payload chunks per context %u",
                    payload_chunks, total_reserved_hbm_chunks,
                    rem_payload_chunks, total_hbm_contexts, payload_chunks_per_context);

    uint64_t offset = 0;
    for (fifo_type = 0; fifo_type < NUM_TM_HBM_FIFO_TYPES; fifo_type++) {
        for (uint32_t context = 0; context < num_hbm_contexts[fifo_type]; context++) {
            uint64_t payload_chunks_needed =
                payload_chunks_per_context + reserved_hbm_chunks_per_context[fifo_type];
            uint64_t control_chunks_needed =
                (payload_chunks_needed + tm_asic_profile()->hbm_fifo_control_scale_factor - 1)/
                tm_asic_profile()->hbm_fifo_control_scale_factor;

            buf_cfg->hbm_fifo[fifo_type][context].valid = true;
            buf_cfg->hbm_fifo[fifo_type][context].payload_offset = offset;
            buf_cfg->hbm_fifo[fifo_type][context].payload_chunks = payload_chunks_needed;
            offset += payload_chunks_needed;
            buf_cfg->hbm_fifo[fifo_type][context].control_offset = offset;
            buf_cfg->hbm_fifo[fifo_type][context].control_chunks = control_chunks_needed;
            offset += control_chunks_needed;
        }
    }
    SDK_ASSERT(offset <= (control_chunks + payload_chunks));
    SDK_TRACE_DEBUG("unallocated hbm chunks %u total %u",
                    (control_chunks + payload_chunks) - offset,
                    total_hbm_chunks);
    return sdk::SDK_RET_OK;
}

static bool
iq_disabled (tm_port_t port, uint32_t iq)
{
    tm_port_type_e port_type;
    bool disabled = false;
    uint32_t max_iqs;
    uint32_t num_iqs;
    uint32_t disabled_iq_start, disabled_iq_end;

    port_type = capri_tm_get_port_type(port);
    num_iqs = tm_cfg_profile()->num_qs[port_type];

    switch(port_type) {
        case TM_PORT_TYPE_UPLINK:
            if (port == CAPRI_TM_PORT_NCSI) {
                // On the BMC port, only one pg is supported
                //num_iqs = 1;
                // On the BMC port, two PGs are supported
                num_iqs = CAPRI_TM_NUM_BMC_QUEUES;

                if ( (iq != QOS_QUEUE_DEFAULT) && (iq != QOS_SWM_CAM_NCSI_COS) ) {
                    disabled = true;
                }
                break;

            } else if (!is_active_uplink_port(port)) {
                disabled = true;
            }
            if (iq >= num_iqs) {
                disabled = true;
            }
            break;
        case TM_PORT_TYPE_P4EG:
        case TM_PORT_TYPE_P4IG:
            max_iqs = capri_tm_get_num_iqs_for_port_type(port_type);
            SDK_ASSERT(max_iqs > num_iqs);
            disabled_iq_start = CAPRI_TM_P4_UPLINK_IQ_OFFSET - (max_iqs - num_iqs) - 1;
            disabled_iq_end = CAPRI_TM_P4_UPLINK_IQ_OFFSET - 1;
            if ((iq >= disabled_iq_start) && (iq < disabled_iq_end)) {
                disabled = true;
            }
            break;
        case TM_PORT_TYPE_DMA:
            if (iq >= num_iqs) {
                disabled = true;
            }
            break;
        case NUM_TM_PORT_TYPES:
            disabled = true;
            break;
    }

    if (disabled) {
        SDK_TRACE_DEBUG("iq %u on port %u disabled",
                        iq, port);
    }

    return disabled;
}

static sdk_ret_t
capri_tm_program_pbc_buffers1 (capri_tm_buf_cfg_t *buf_cfg)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    uint32_t reserved_min;
    uint32_t headroom;
    uint32_t xon_threshold;
    tm_port_type_e port_type;

    stringstream data;
    data << hex << endl;
    // Program the buffers
//:: for p in range(0, TM_PORTS/3):
//::    pinfo = port_info[p]
    port_type = capri_tm_get_port_type(${pinfo["enum"]});
//::    for pg in range(port_info[p]["pgs"]):
    reserved_min = 0;
    headroom = 0;
    xon_threshold = 0;
    if (!iq_disabled(${pinfo["enum"]}, ${pg})) {
        if (tm_asic_profile()->port[port_type].uses_credits &&
            tm_asic_profile()->port[port_type].recirc_q != ${pg}) {
            reserved_min = buf_cfg->chunks_per_q[port_type];

            if (tm_is_high_perf_q(${pg})) {
                reserved_min *= 2;
            }
            reserved_min = reserved_min +
                cells_to_chunks(bytes_to_cells(tm_cfg_profile()->jumbo_mtu[port_type])) + 2;
            headroom = 0;
        } else {
            reserved_min = buf_cfg->chunks_per_q[port_type];
            headroom = cells_to_chunks(tm_asic_profile()->port[port_type].headroom_cells);
        }
    }

    if (headroom) {
        SDK_ASSERT(chunks_to_cells(reserved_min) >=
                   bytes_to_cells(tm_cfg_profile()->jumbo_mtu[port_type]));
        xon_threshold = chunks_to_cells(reserved_min) -
            bytes_to_cells(tm_cfg_profile()->jumbo_mtu[port_type]);
    }

    if (port_type == TM_PORT_TYPE_DMA) {
        // Based on asic config
        xon_threshold = 13;
    }

    pbc_csr.port_${p}.cfg_account_pg_${pg}.read();
    /* Update the PG parameters */
    pbc_csr.port_${p}.cfg_account_pg_${pg}.reserved_min(reserved_min);
    pbc_csr.port_${p}.cfg_account_pg_${pg}.headroom(headroom);
    pbc_csr.port_${p}.cfg_account_pg_${pg}.xon_threshold(xon_threshold);
    pbc_csr.port_${p}.cfg_account_pg_${pg}.low_limit(0);
    pbc_csr.port_${p}.cfg_account_pg_${pg}.alpha(0);

    if (tm_sw_init_enabled()) {
        ${trace_register("pbc_csr.port_" + str(p) + ".cfg_account_pg_" + str(pg))}
        pbc_csr.port_${p}.cfg_account_pg_${pg}.write();
    }
//::    #endfor
//:: #endfor
    SDK_TRACE_DEBUG("%s", data.str().c_str());
    return ret;
}

static sdk_ret_t
capri_tm_program_pbc_buffers2 (capri_tm_buf_cfg_t *buf_cfg)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    uint32_t reserved_min;
    uint32_t headroom;
    uint32_t xon_threshold;
    tm_port_type_e port_type;

    stringstream data;
    data << hex << endl;
    // Program the buffers
//:: for p in range(TM_PORTS/3, (2*TM_PORTS)/3):
//::    pinfo = port_info[p]
    port_type = capri_tm_get_port_type(${pinfo["enum"]});
//::    for pg in range(port_info[p]["pgs"]):
    reserved_min = 0;
    headroom = 0;
    xon_threshold = 0;
    if (!iq_disabled(${pinfo["enum"]}, ${pg})) {
        if (tm_asic_profile()->port[port_type].uses_credits &&
            tm_asic_profile()->port[port_type].recirc_q != ${pg}) {
            reserved_min = buf_cfg->chunks_per_q[port_type];

            if (tm_is_high_perf_q(${pg})) {
                reserved_min *= 2;
            }
            reserved_min = reserved_min +
                cells_to_chunks(bytes_to_cells(tm_cfg_profile()->jumbo_mtu[port_type])) + 2;
            headroom = 0;
        } else {
            reserved_min = buf_cfg->chunks_per_q[port_type];
            headroom = cells_to_chunks(tm_asic_profile()->port[port_type].headroom_cells);
        }
    }

    if (headroom) {
        SDK_ASSERT(chunks_to_cells(reserved_min) >=
                   bytes_to_cells(tm_cfg_profile()->jumbo_mtu[port_type]));
        xon_threshold = chunks_to_cells(reserved_min) -
            bytes_to_cells(tm_cfg_profile()->jumbo_mtu[port_type]);
    }

    if (port_type == TM_PORT_TYPE_DMA) {
        // Based on asic config
        xon_threshold = 13;
    }

    pbc_csr.port_${p}.cfg_account_pg_${pg}.read();
    /* Update the PG parameters */
    pbc_csr.port_${p}.cfg_account_pg_${pg}.reserved_min(reserved_min);
    pbc_csr.port_${p}.cfg_account_pg_${pg}.headroom(headroom);
    pbc_csr.port_${p}.cfg_account_pg_${pg}.xon_threshold(xon_threshold);
    pbc_csr.port_${p}.cfg_account_pg_${pg}.low_limit(0);
    pbc_csr.port_${p}.cfg_account_pg_${pg}.alpha(0);

    if (tm_sw_init_enabled()) {
        ${trace_register("pbc_csr.port_" + str(p) + ".cfg_account_pg_" + str(pg))}
        pbc_csr.port_${p}.cfg_account_pg_${pg}.write();
    }
//::    #endfor
//:: #endfor
    SDK_TRACE_DEBUG("%s", data.str().c_str());
    return ret;
}

static sdk_ret_t
capri_tm_program_pbc_buffers3 (capri_tm_buf_cfg_t *buf_cfg)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    uint32_t reserved_min;
    uint32_t headroom;
    uint32_t xon_threshold;
    tm_port_type_e port_type;

    stringstream data;
    data << hex << endl;
    // Program the buffers
//:: for p in range((2*TM_PORTS)/3, TM_PORTS):
//::    pinfo = port_info[p]
    port_type = capri_tm_get_port_type(${pinfo["enum"]});
//::    for pg in range(port_info[p]["pgs"]):
    reserved_min = 0;
    headroom = 0;
    xon_threshold = 0;
    if (!iq_disabled(${pinfo["enum"]}, ${pg})) {
        if (tm_asic_profile()->port[port_type].uses_credits &&
            tm_asic_profile()->port[port_type].recirc_q != ${pg}) {
            reserved_min = buf_cfg->chunks_per_q[port_type];

            if (tm_is_high_perf_q(${pg})) {
                reserved_min *= 2;
            }
            reserved_min = reserved_min +
                cells_to_chunks(bytes_to_cells(tm_cfg_profile()->jumbo_mtu[port_type])) + 2;
            headroom = 0;
        } else {
            reserved_min = buf_cfg->chunks_per_q[port_type];
            headroom = cells_to_chunks(tm_asic_profile()->port[port_type].headroom_cells);
        }
    }

    if (headroom) {
        SDK_ASSERT(chunks_to_cells(reserved_min) >=
                   bytes_to_cells(tm_cfg_profile()->jumbo_mtu[port_type]));
        xon_threshold = chunks_to_cells(reserved_min) -
            bytes_to_cells(tm_cfg_profile()->jumbo_mtu[port_type]);
    }

    if (port_type == TM_PORT_TYPE_DMA) {
        // Based on asic config
        xon_threshold = 13;
    }

    pbc_csr.port_${p}.cfg_account_pg_${pg}.read();
    /* Update the PG parameters */
    pbc_csr.port_${p}.cfg_account_pg_${pg}.reserved_min(reserved_min);
    pbc_csr.port_${p}.cfg_account_pg_${pg}.headroom(headroom);
    pbc_csr.port_${p}.cfg_account_pg_${pg}.xon_threshold(xon_threshold);
    pbc_csr.port_${p}.cfg_account_pg_${pg}.low_limit(0);
    pbc_csr.port_${p}.cfg_account_pg_${pg}.alpha(0);

    if (tm_sw_init_enabled()) {
        ${trace_register("pbc_csr.port_" + str(p) + ".cfg_account_pg_" + str(pg))}
        pbc_csr.port_${p}.cfg_account_pg_${pg}.write();
    }
//::    #endfor
//:: #endfor
    SDK_TRACE_DEBUG("%s", data.str().c_str());
    return ret;
}

static sdk_ret_t
capri_tm_program_p4_credits (capri_tm_buf_cfg_t *buf_cfg)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    tm_port_type_e port_type;
    uint32_t credit_enable;
    uint32_t credits;
    uint32_t qs_to_flush;
    uint32_t recirc_q_val;
    cpp_int max_growth;
    cap_pbc_max_growth_map_t max_growth_decoder;
    max_growth_decoder.init();

    stringstream data;
    data << hex << endl;

    // Program the buffers
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["supports_credits"]:
    port_type = capri_tm_get_port_type(${pinfo["enum"]});
    credit_enable = 0;
    qs_to_flush = 0;
    max_growth = 0;
    recirc_q_val = 1<<tm_asic_profile()->port[port_type].recirc_q;
//::        for pg in range(port_info[p]["pgs"]):
    credits = 0;
    if (!iq_disabled(${pinfo["enum"]}, ${pg})) {
        if (tm_asic_profile()->port[port_type].uses_credits &&
            (tm_asic_profile()->port[port_type].recirc_q != ${pg})) {

            credits = chunks_to_cells(buf_cfg->chunks_per_q[port_type]);
            if (tm_is_high_perf_q(${pg})) {
                credits = chunks_to_cells(2 * buf_cfg->chunks_per_q[port_type]);
            }

            credit_enable |= 1<<${pg};

            cpp_helper.set_slc(max_growth, 1, ${pg} * 5, ((${pg}+1)*5)-1);

            // Program credits
            // pbc_csr.port_${p}.dhs_oq_flow_control.entry[${pg}].read();
            pbc_csr.port_${p}.dhs_oq_flow_control.entry[${pg}].entry(credits);
            if (tm_sw_init_enabled()) {

                ${trace_register("pbc_csr.port_" + str(p) + ".dhs_oq_flow_control.entry[" + str(pg) +"]")}
                pbc_csr.port_${p}.dhs_oq_flow_control.entry[${pg}].write();
            }
        }
    } else {
        qs_to_flush |= 1<<${pg};
    }
//::        #endfor
    // Program the credit_enable
    if (credit_enable) {
        pbc_csr.port_${p}.cfg_account_credit_return.read();
        pbc_csr.port_${p}.cfg_oq_queue.read();
        pbc_csr.cfg_credits_max_growth_${p}.read();

        pbc_csr.port_${p}.cfg_account_credit_return.enable(credit_enable);
        pbc_csr.port_${p}.cfg_oq_queue.recirc(recirc_q_val);
        pbc_csr.port_${p}.cfg_oq_queue.flush(qs_to_flush);
        pbc_csr.cfg_credits_max_growth_${p}.cells(max_growth);

        max_growth_decoder.all(pbc_csr.cfg_credits_max_growth_${p}.cells());
        max_growth_decoder.set_name("cap0.pb.pbc.cfg_credits_max_growth_${p}.decoder");
        if (tm_sw_init_enabled()) {
            max_growth_decoder.show();

            ${trace_register("pbc_csr.port_" + str(p) + ".cfg_account_credit_return")}
            ${trace_register("pbc_csr.port_" + str(p) + ".cfg_oq_queue")}
            ${trace_register("pbc_csr.cfg_credits_max_growth_" + str(p))}

            pbc_csr.port_${p}.cfg_account_credit_return.write();
            pbc_csr.port_${p}.cfg_oq_queue.write();
            pbc_csr.cfg_credits_max_growth_${p}.write();
        }
    }
//::    #endif
//:: #endfor
    SDK_TRACE_DEBUG("%s", data.str().c_str());

    return ret;
}

static sdk_ret_t
capri_tm_program_hbm_buffers (capri_tm_buf_cfg_t *buf_cfg)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    cap_pbchbm_csr_t &hbm_csr = pbc_csr.hbm;
    uint32_t num_hbm_contexts_per_port;
    uint32_t context;
    uint32_t num_contexts;
    uint32_t base_offset;
    cpp_int port_payload_base_val;
    cpp_int port_payload_size_val;
    cpp_int port_payload_occupancy_val;
    cpp_int port_control_base_val;
    cpp_int port_control_size_val;

    cpp_int payload_base_val[NUM_TM_HBM_FIFO_TYPES];
    cpp_int payload_size_val[NUM_TM_HBM_FIFO_TYPES];
    cpp_int control_base_val[NUM_TM_HBM_FIFO_TYPES];
    cpp_int control_size_val[NUM_TM_HBM_FIFO_TYPES];
    cpp_int eth_xoff_val;
    cpp_int eth_xon_val;
    uint64_t payload_offset;
    uint64_t payload_size;
    uint64_t payload_occupancy;
    uint64_t control_offset;
    uint64_t control_size;
    uint64_t xoff_threshold;
    uint64_t xon_threshold;

    uint32_t fifo_type;

    tm_port_type_e port_type;

    // On active uplink ports and the DMA port, setup the HBM queues
    num_hbm_contexts_per_port = tm_cfg_profile()->num_qs[TM_PORT_TYPE_UPLINK];

    stringstream data;
    data << hex << endl;

//:: fifo_types = {"uplink": "TM_HBM_FIFO_TYPE_UPLINK" ,
//::               "dma" : "TM_HBM_FIFO_TYPE_TXDMA" }
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["has_hbm"]:
    // ${pinfo["enum"]}
//::        fifo_type = fifo_types[pinfo["type"]]
//::        reg_name = hbm_fifo_info[fifo_type]["reg_name"]
//::        if pinfo["type"] == "uplink":
    if (is_active_uplink_port(${pinfo["enum"]})) {
        // If we are an active port, then setup the HBM fifo contexts
        num_contexts = num_hbm_contexts_per_port;
    } else {
        num_contexts = 0;
    }
    base_offset = ${p} * num_contexts;
//::        elif pinfo["type"] == "dma":
    num_contexts = capri_tm_max_hbm_contexts_for_fifo(TM_HBM_FIFO_TYPE_TXDMA);
    base_offset = 0;
//::        #endif

    port_type = capri_tm_get_port_type(${pinfo["enum"]});
    fifo_type = ${fifo_type};
    port_payload_base_val = 0;
    port_payload_size_val = 0;
    port_payload_occupancy_val = 0;
    port_control_base_val = 0;
    port_control_size_val = 0;

    for (unsigned q = 0; q < num_contexts; q++) {
        context = base_offset + q;

        capri_tm_buf_hbm_cfg_t *hbm_cfg = &buf_cfg->hbm_fifo[fifo_type][context];
        if (hbm_cfg->valid) {
            payload_offset = hbm_cfg->payload_offset;
            payload_size = hbm_cfg->payload_chunks;
            // payload occupancy is in units of 1024 bytes
            // program it to drop when 1 jumbo-mtu worth of bytes still free
            payload_occupancy =
                (hbm_chunks_to_bytes(payload_size) - tm_cfg_profile()->jumbo_mtu[port_type]) >> 10;

            if (fifo_type == TM_HBM_FIFO_TYPE_UPLINK) {
                // xoff_threshold is in units of 512 bytes
                // program it to drop when 1000*64 bytes worth of bytes still free
                xoff_threshold =
                    (hbm_chunks_to_bytes(payload_size) -
                     CAPRI_TM_DEFAULT_RELATIVE_XOFF_THRESHOLD_BYTES) >> 9;

                // xon_threshold is in units of 512 bytes
                // program it to drop when 2000*64 bytes worth of bytes still free
                xon_threshold =
                    (hbm_chunks_to_bytes(payload_size) -
                     CAPRI_TM_DEFAULT_RELATIVE_XON_THRESHOLD_BYTES) >> 9;
            } else {
                xoff_threshold = 0;
                xon_threshold = 0;
            }

            control_offset = hbm_cfg->control_offset;
            control_size = hbm_cfg->control_chunks;
        } else {
            payload_offset = 0;
            payload_size = 0;
            payload_occupancy = 0;
            xoff_threshold = 0;
            xon_threshold = 0;
            control_offset = 0;
            control_size = 0;
        }

        // Per port registers
        // 27 bits per hbm_q
        cpp_helper.set_slc(port_payload_base_val, payload_offset,
                            q * 27, ((q + 1) * 27) - 1);
        // 23 bits per q
        cpp_helper.set_slc(port_payload_size_val, payload_size ? payload_size - 1 : 0,
                            q * 23, ((q + 1) * 23) - 1);
        // 19 bits per q
        cpp_helper.set_slc(port_payload_occupancy_val, payload_occupancy ? payload_occupancy - 1 : 0,
                            q * 19, ((q + 1) * 19) - 1);
        // 27 bits per q
        cpp_helper.set_slc(port_control_base_val, control_offset,
                            q * 27, ((q + 1) * 27) - 1);
        // 23 bits per q
        cpp_helper.set_slc(port_control_size_val, control_size ? control_size - 1 : 0,
                            q * 23, ((q + 1) * 23) - 1);

        // Global registers

        // 27 bits per hbm_q
        cpp_helper.set_slc(payload_base_val[fifo_type], payload_offset,
                            context * 27, ((context + 1) * 27) - 1);
        // 23 bits per context
        cpp_helper.set_slc(payload_size_val[fifo_type], payload_size ? payload_size - 1 : 0,
                            context * 23, ((context + 1) * 23) - 1);
        // 27 bits per context
        cpp_helper.set_slc(control_base_val[fifo_type], control_offset,
                            context * 27, ((context + 1) * 27) - 1);
        // 23 bits per context
        cpp_helper.set_slc(control_size_val[fifo_type], control_size ? control_size - 1 : 0,
                            context * 23, ((context + 1) * 23) - 1);

        if (fifo_type == TM_HBM_FIFO_TYPE_UPLINK) {
            // 20 bits per context
            cpp_helper.set_slc(eth_xoff_val, xoff_threshold,
                               context * 20, ((context + 1) * 20) - 1);
            // 20 bits per context
            cpp_helper.set_slc(eth_xon_val, xon_threshold,
                               context * 20, ((context + 1) * 20) - 1);
        }
    }

    hbm_csr.hbm_port_${p}.cfg_hbm_${reg_name}_payload.base(port_payload_base_val);
    hbm_csr.hbm_port_${p}.cfg_hbm_${reg_name}_payload.mem_sz(port_payload_size_val);
    hbm_csr.hbm_port_${p}.cfg_hbm_${reg_name}_payload_occupancy.threshold(port_payload_occupancy_val);

//::        if pinfo["type"] == "uplink":
    hbm_csr.hbm_port_${p}.cfg_hbm_${reg_name}_ctrl.base(port_control_base_val);
    hbm_csr.hbm_port_${p}.cfg_hbm_${reg_name}_ctrl.mem_sz(port_control_size_val);
//::        #endif

    hbm_csr.hbm_port_${p}.cfg_hbm_context.read();
    hbm_csr.hbm_port_${p}.cfg_hbm_context.enable((1ull<<num_contexts)-1);

    // enable no_drop by default in PB
    // hbm_csr.hbm_port_${p}.cfg_hbm_context.no_drop((1ull << num_contexts) - 1);

    // TODO use tm_sw_init_enabled below
    hbm_csr.hbm_port_${p}.cfg_hbm_context.write();

    hbm_csr.hbm_port_${p}.cfg_hbm_context.base(base_offset);
    if (tm_sw_init_enabled()) {

        ${trace_register("pbc_csr.hbm.hbm_port_" + str(p) + ".cfg_hbm_" + reg_name + "_payload")}
        hbm_csr.hbm_port_${p}.cfg_hbm_${reg_name}_payload.write();

        ${trace_register("pbc_csr.hbm.hbm_port_" + str(p) + ".cfg_hbm_" + reg_name + "_payload_occupancy")}
        hbm_csr.hbm_port_${p}.cfg_hbm_${reg_name}_payload_occupancy.write();

//::        if pinfo["type"] == "uplink":
        ${trace_register("pbc_csr.hbm.hbm_port_" + str(p) + ".cfg_hbm_" + reg_name + "_ctrl")}
        hbm_csr.hbm_port_${p}.cfg_hbm_${reg_name}_ctrl.write();
//::        #endif

        ${trace_register("pbc_csr.hbm.hbm_port_" + str(p) + ".cfg_hbm_context")}
        hbm_csr.hbm_port_${p}.cfg_hbm_context.write();
    }
//::    #endif
//:: #endfor

//:: for fifo_type in fifo_types.values():
//::    reg_name = hbm_fifo_info[fifo_type]["reg_name"]

    hbm_csr.cfg_hbm_${reg_name}_payload.base(payload_base_val[${fifo_type}]);
    hbm_csr.cfg_hbm_${reg_name}_payload.mem_sz(payload_size_val[${fifo_type}]);
    hbm_csr.cfg_hbm_${reg_name}_ctrl.base(control_base_val[${fifo_type}]);
    hbm_csr.cfg_hbm_${reg_name}_ctrl.mem_sz(control_size_val[${fifo_type}]);

    // Write all the registers
    {
        cap_pbc_hbm_${reg_name}_ctl_t hbm_ctl_decoder;

        hbm_ctl_decoder.init();
        hbm_ctl_decoder.all(hbm_csr.cfg_hbm_${reg_name}_payload.all());
        hbm_ctl_decoder.set_name("cap0.pb.pbc.hbm.cfg_hbm_${reg_name}_payload.decoder");
//        hbm_ctl_decoder.show();

        hbm_ctl_decoder.init();
        hbm_ctl_decoder.all(hbm_csr.cfg_hbm_${reg_name}_ctrl.all());
        hbm_ctl_decoder.set_name("cap0.pb.pbc.hbm.cfg_hbm_${reg_name}_ctrl.decoder");
//        hbm_ctl_decoder.show();

    }

    if (tm_sw_init_enabled()) {
        ${trace_register("pbc_csr.hbm.cfg_hbm_" + reg_name + "_payload")}
        ${trace_register("pbc_csr.hbm.cfg_hbm_" + reg_name + "_ctrl")}

        hbm_csr.cfg_hbm_${reg_name}_payload.write();
        hbm_csr.cfg_hbm_${reg_name}_ctrl.write();
    }
//:: #endfor

    pbc_csr.hbm.cfg_hbm_threshold.read();
    pbc_csr.hbm.cfg_hbm_threshold.xoff(eth_xoff_val);
    pbc_csr.hbm.cfg_hbm_threshold.xon(eth_xon_val);
    if (tm_sw_init_enabled()) {
        ${trace_register("pbc_csr.hbm.cfg_hbm_threshold")};
        pbc_csr.hbm.cfg_hbm_threshold.write();
    }

    SDK_TRACE_DEBUG("%s", data.str().c_str());

    return ret;
}

static sdk_ret_t
capri_tm_program_pbc_buffers (capri_tm_buf_cfg_t *buf_cfg)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;

    ret = capri_tm_program_pbc_buffers1(buf_cfg);
    if (ret != SDK_RET_OK) {
        return ret;
    }
    ret = capri_tm_program_pbc_buffers2(buf_cfg);
    if (ret != SDK_RET_OK) {
        return ret;
    }
    return capri_tm_program_pbc_buffers3(buf_cfg);
}

static sdk_ret_t
capri_tm_program_buffers (capri_tm_buf_cfg_t *buf_cfg)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;

    ret = capri_tm_program_pbc_buffers(buf_cfg);
    if (ret != sdk::SDK_RET_OK) {
        SDK_TRACE_ERR("Error programming pbc buffers ret %d",
                      ret);
        return ret;
    }

    ret = capri_tm_program_p4_credits(buf_cfg);
    if (ret != sdk::SDK_RET_OK) {
        SDK_TRACE_ERR("Error programming hbm buffers ret %d",
                      ret);
        return ret;
    }
    return ret;
}

static sdk_ret_t
capri_tm_port_program_defaults (void)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    cpp_int tc_to_pg_val;
    cpp_int xoff2oq_map_val;
    tm_port_type_e port_type;
    uint32_t mtu_cells;
    uint32_t nbits;
    uint32_t oq;

    // For every port, program the tc_to_pg mapping
    // and mtu

    stringstream data;
    data << hex << endl;

//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
    // ${pinfo["enum"]}
    port_type = capri_tm_get_port_type(${pinfo["enum"]});
    tc_to_pg_val = 0;

    pbc_csr.port_${p}.cfg_account_mtu_table.read();
    pbc_csr.port_${p}.cfg_account_tc_to_pg.read();
    pbc_csr.port_${p}.cfg_account_control.read();

    pbc_csr.port_${p}.cfg_account_control.use_sp_as_wm(1);

    mtu_cells = bytes_to_cells(tm_cfg_profile()->jumbo_mtu[port_type]);
//::    nbits = int(math.log(pinfo["pgs"], 2))
//::    for pg in range(pinfo["pgs"]):
    cpp_helper.set_slc(tc_to_pg_val, ${pg}, ${pg} * ${nbits}, ((${pg}+1) * ${nbits}) - 1);
    pbc_csr.port_${p}.cfg_account_mtu_table.pg${pg}(mtu_cells);
//::    #endfor
    pbc_csr.port_${p}.cfg_account_tc_to_pg.table(tc_to_pg_val);

    if (tm_sw_init_enabled()) {
        cap_pbc_pg${pinfo["pgs"]}_map_t pg_map_decoder;
        pg_map_decoder.init();
        pg_map_decoder.all(pbc_csr.port_${p}.cfg_account_tc_to_pg.table());
        pg_map_decoder.set_name("cap0.pb.pbc.port_${p}.cfg_account_tc_to_pg.decoder");
        pg_map_decoder.show();

        ${trace_register("pbc_csr.port_" + str(p) + ".cfg_account_mtu_table")}
        ${trace_register("pbc_csr.port_" + str(p) + ".cfg_account_tc_to_pg")}
        ${trace_register("pbc_csr.port_" + str(p) + ".cfg_account_control")}

        pbc_csr.port_${p}.cfg_account_control.write();
        pbc_csr.port_${p}.cfg_account_mtu_table.write();
        pbc_csr.port_${p}.cfg_account_tc_to_pg.write();
    }
//:: #endfor

    // On dma port, set the xoff to oq for flow control in RxDMA
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink" or pinfo["type"] == "dma":
    // ${pinfo["enum"]}
    port_type = capri_tm_get_port_type(${pinfo["enum"]});
    xoff2oq_map_val = 0;
    if (port_type == TM_PORT_TYPE_UPLINK) {
        nbits = 3;
    } else {
        nbits = 5;
    }
    for (oq = 0; oq < capri_tm_get_num_oqs_for_port_type(port_type); oq++) {
        cpp_helper.set_slc(xoff2oq_map_val, oq, oq*nbits, ((oq+1)*nbits)-1);
    }

    pbc_csr.port_${p}.cfg_oq_xoff2oq.read();
    pbc_csr.port_${p}.cfg_oq_xoff2oq.map(xoff2oq_map_val);
    if (tm_sw_init_enabled()) {
        ${trace_register("pbc_csr.port_" + str(p) + ".cfg_oq_xoff2oq")}

        pbc_csr.port_${p}.cfg_oq_xoff2oq.write();
    }
//::    #endif
//:: #endfor

    // On uplink ports, disable xoff on all oqs
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
    // ${pinfo["enum"]}
    pbc_csr.port_${p}.cfg_mac_xoff.read();
    pbc_csr.port_${p}.cfg_mac_xoff.enable(0);
    if (tm_sw_init_enabled()) {
        ${trace_register("pbc_csr.port_" + str(p) + ".cfg_mac_xoff")}
        pbc_csr.port_${p}.cfg_mac_xoff.write();
    }
//::    #endif
//:: #endfor

    // On uplink ports, set the number of header bytes to remove
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
    // ${pinfo["enum"]}
    port_type = capri_tm_get_port_type(${pinfo["enum"]});
    pbc_csr.port_${p}.cfg_oq.read();
//::    if pinfo["type"] == "uplink":
    pbc_csr.port_${p}.cfg_oq.num_hdr_bytes(
        CAPRI_GLOBAL_INTRINSIC_HDR_SZ + CAPRI_P4_INTRINSIC_HDR_SZ);
    // Tell MAC to stomp CRC on error
    pbc_csr.port_${p}.cfg_oq.hw_error_to_pbus(1);
//::    #endif

    if (tm_sw_init_enabled()) {
        pbc_csr.port_${p}.cfg_oq.enable(1);
        pbc_csr.port_${p}.cfg_oq.rewrite_enable(1);
//::    if pinfo["supports_credits"]:
        pbc_csr.port_${p}.cfg_oq.flow_control_enable_credits(
            tm_asic_profile()->port[port_type].uses_credits ? 1 : 0);
//::    #endif
//::    if pinfo["enum"] == "CAPRI_TM_PORT_INGRESS":
        pbc_csr.port_${p}.cfg_oq.packing_msb(
            capri_tm_get_max_cell_chunks_for_island(0) >
            capri_tm_get_max_cell_chunks_for_island(1) ? 1 : 0);
//::    #endif
//::    if pinfo["type"] == "dma" or pinfo["type"] == "uplink":
        pbc_csr.port_${p}.cfg_oq.flow_control_enable_xoff(1);
//::    #endif
    }
    ${trace_register("pbc_csr.port_" + str(p) + ".cfg_oq")}
    pbc_csr.port_${p}.cfg_oq.write();
//:: #endfor

    SDK_TRACE_DEBUG("%s", data.str().c_str());
    return sdk::SDK_RET_OK;
}

static
void cap_pb_cfg_sched_node(int chip_id, int inst_id, int level,
                           int oport, int queue_node, int quota)
{
    cap_pbc_csr_t & pbc_csr =
                    CAP_BLK_REG_MODEL_ACCESS(cap_pbc_csr_t, chip_id, inst_id);

    if(level < 1 || level > 3) {
        SDK_TRACE_ERR("Invalid level: %d", level);
        return;
    }

    int max_queues = 32;
    if(level == 1) {
        max_queues = 32;
    } else if(level == 2) {
        max_queues = 16;
    } else {
        max_queues = 4;
    }

    SDK_TRACE_DEBUG("level: %d, oport: %d, queue_node: %d, quota: %d",
                    level, oport, queue_node, quota);

    pbc_csr.cfg_sched.enable_wrr(1);
    pbc_csr.cfg_sched.dhs_selection( (level-1)*2 );
    pbc_csr.cfg_sched.write();

    pbc_csr.cfg_dhs_mem.address(oport*max_queues + queue_node);
    pbc_csr.cfg_dhs_mem.write();

    pbc_csr.dhs_sched.entry[0].command(1);   //1: overwrite quota and credits
    pbc_csr.dhs_sched.entry[0].current_credit(quota);
    pbc_csr.dhs_sched.entry[0].quota(quota);
    pbc_csr.dhs_sched.entry[0].write();
}

pb_sched_port_cfg_t pb_sched_port_cfg[CAPRI_TM_MAX_PORTS];

static bool
cap_pb_sched_node_set (int port,
                       int node_type,
                       int node,
                       int queue)
{
    bool set = pb_sched_port_cfg[port].node_cfg[node_type].input_cfg[node].
                                    inputs_bitmap->is_index_allocated(queue);
    if (set == true) {
        SDK_TRACE_DEBUG("port: %d, node_type; %d, node: %d, q: %d",
                        port, node_type, node, queue);
    }

    return set;
}

sdk_ret_t
cap_pb_sched_node_alloc (int port,
                         tm_queue_node_type_t node_type,
                         uint32_t *index)
{
    indexer::status status = indexer::status::SUCCESS;
    indexer *node_bitmap = pb_sched_port_cfg[port].
                            node_cfg[node_type].node_bitmap;

    if (NULL == node_bitmap) {
        SDK_TRACE_ERR("node_bitmap indexer NULL. "
                      "port: %u, node_type: %u, index: %u",
                      port, node_type, *index);
        return SDK_RET_ERR;
    }

    if (*index == 0xFFFFFFFF) {
        status = node_bitmap->alloc(index, true, 1);
    } else {
        status = node_bitmap->alloc_withid(*index, 1);
    }

    if (status != indexer::status::SUCCESS) {
        SDK_TRACE_ERR("Indexer allocation failed. "
                      "port: %u, node_type: %u, index: %u",
                      port, node_type, *index);
        return SDK_RET_ERR;
    }

    return SDK_RET_OK;
}

sdk_ret_t
cap_pb_sched_inputs_bitmap_free (int port,
                                 tm_queue_node_type_t node_type,
                                 int node_index,
                                 int input_index)
{
    indexer::status status = indexer::status::SUCCESS;
    indexer *inputs_bitmap = pb_sched_port_cfg[port].node_cfg[node_type].
                                    input_cfg[node_index].inputs_bitmap;
    if (NULL == inputs_bitmap) {
        SDK_TRACE_ERR("inputs_bitmap indexer NULL. "
                      "port: %u, node_type: %u, node_index: %u",
                      "input_index: %u",
                      port, node_type, node_index, input_index);
        return SDK_RET_ERR;
    }

    status = inputs_bitmap->free(input_index);
    if (status != indexer::status::SUCCESS) {
        SDK_TRACE_ERR("Indexer free failed. "
                      "port: %u, node_type: %u, node_index: %u",
                      "input_index: %u",
                      port, node_type, node_index, input_index);
        return SDK_RET_ERR;
    }

    return SDK_RET_OK;
}

sdk_ret_t
cap_pb_sched_inputs_bitmap_alloc (int port,
                                  tm_queue_node_type_t node_type,
                                  int node_index,
                                  uint32_t *input_index,
                                  pb_sched_node_input_info_t *input_info)
{
    indexer::status status = indexer::status::SUCCESS;
    pb_sched_node_input_cfg_t *input_cfg = &pb_sched_port_cfg[port].
                                node_cfg[node_type].input_cfg[node_index];

    indexer *inputs_bitmap = input_cfg->inputs_bitmap;
    if (NULL == inputs_bitmap) {
        SDK_TRACE_ERR("inputs_bitmap indexer NULL. "
                      "port: %u, node_type: %u, node_index: %u",
                      "input_index: %u",
                      port, node_type, node_index, *input_index);
        return SDK_RET_ERR;
    }

    if (*input_index == 0xFFFFFFFF) {
        status = inputs_bitmap->alloc(input_index, true, 1);
    } else {
        status = inputs_bitmap->alloc_withid(*input_index, 1);
    }

    if (status != indexer::status::SUCCESS) {
        SDK_TRACE_ERR("Indexer alloc failed. "
                      "port: %u, node_type: %u, node_index: %u",
                      "input_index: %u",
                      port, node_type, node_index, *input_index);
        return SDK_RET_ERR;
    }

    input_cfg->num_inputs += 1;
    input_cfg->total_weights += input_info->weight;

    memcpy(&input_cfg->input_info[*input_index],
           input_info,
           sizeof(pb_sched_node_input_info_t));

    return SDK_RET_OK;
}

bool
cap_pb_sched_find_and_remove_index (int port,
                                    tm_queue_node_type_t node_type,
                                    int input_index,
                                    uint32_t *node_index,
                                    bool remove)
{
    pb_sched_node_cfg_t *node_cfg =
                        &pb_sched_port_cfg[port].node_cfg[node_type];

    for (uint32_t node = 0; node < CAPRI_TM_MAX_SCHED_NODES; ++node) {
        pb_sched_node_input_cfg_t *input_cfg =
                                    &node_cfg->input_cfg[node];
        indexer *inputs_bitmap = input_cfg->inputs_bitmap;
        if (inputs_bitmap->is_index_allocated(input_index) == true) {
            input_cfg->num_inputs -= 1;
            input_cfg->total_weights -=
                            input_cfg->input_info[input_index].weight;

            if (remove == true) {
                inputs_bitmap->free(input_index);
            }

            *node_index = node;
            return true;
        }
    }

    return false;
}

sdk_ret_t
cap_pb_sched_node_pgm (int chip_id, int inst_id, int port,
                       pb_sched_node_cfg_t *node_cfg,
                       tm_queue_node_type_t node_type,
                       uint32_t node)
{
    pb_sched_node_input_cfg_t *input_cfg = &node_cfg->input_cfg[node];

    for (uint32_t input = 0; input < CAPRI_TM_MAX_SCHED_NODE_INPUTS;
                                                    ++input) {
        if (input_cfg->inputs_bitmap->is_index_allocated(input) == false) {
            continue;
        }

        pb_sched_node_input_info_t *input_info =
                                   &input_cfg->input_info[input];

        input_info->dwrr_ratio = (input_info->weight * 100.0) /
                                            input_cfg->total_weights;

        if (input_info->is_strict == true) {
            SDK_TRACE_DEBUG("bypass_timer: %u, input_info->sp_rate_mbps: %u",
                            input_info->priority_bypass_timer,
                            input_info->sp_rate_mbps);

            if (input_info->priority_bypass_timer != 0) {
                input_info->cfg_quota = 10 + (CAPRI_TM_SCHED_TIMER % 1000);
            } else {
                input_info->cfg_quota = ((input_info->sp_rate_mbps *
                            (unsigned long long) 64 * CAPRI_TM_SCHED_TIMER)/
                            (CAPRI_TM_CLK_PERIOD * CAPRI_TM_BUS_WIDTH));
            }

            SDK_TRACE_DEBUG("cfg_quota: %u", input_info->cfg_quota);
        } else {
            input_info->cfg_quota = input_info->dwrr_ratio * CAPRI_TM_DWRR_UNIT
                                        * input_cfg->total_weights;
        }

        cap_pb_cfg_sched_node(chip_id, inst_id, (uint32_t)node_type + 1,
                              port, input, input_info->cfg_quota);
    }

    return SDK_RET_OK;
}

sdk_ret_t
cap_pb_sched_l1_update (tm_port_t port,
                        uint32_t  node,
                        uint32_t  input,
                        bool      is_strict,
                        bool      reset)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    cpp_int node_val;
    cpp_int strict_val;
    uint32_t val = 1;

    if (reset == true) {
        val = 0;
    }

    switch (port) {
//::
//:: for p in range(TM_PORTS):
//::
    case ${p}:
        if (is_strict == true) {
            pbc_csr.port_${p}.cfg_oq_arb_l1_strict.read();

            strict_val = pbc_csr.port_${p}.cfg_oq_arb_l1_strict.priority();
            cpp_helper.set_slc(strict_val, val, input, input);

            pbc_csr.port_${p}.cfg_oq_arb_l1_strict.priority(strict_val);
            pbc_csr.port_${p}.cfg_oq_arb_l1_strict.write();
        }
        switch (node) {
//::
//::     for node in range(16):
//::
        case ${node}:
            pbc_csr.port_${p}.cfg_oq_arb_l1_selection.read();
            node_val = pbc_csr.port_${p}.cfg_oq_arb_l1_selection.node_${node}();

            cpp_helper.set_slc(node_val, val, input, input);

            pbc_csr.port_${p}.cfg_oq_arb_l1_selection.node_${node}(node_val);
            pbc_csr.port_${p}.cfg_oq_arb_l1_selection.write();
            break;
//::
//::     #endfor
//::
        }
        break;

//::
//:: #endfor
//::
    }

    return SDK_RET_OK;
}

sdk_ret_t
cap_pb_sched_l2_update (tm_port_t port,
                        uint32_t  node,
                        uint32_t  input,
                        bool      is_strict,
                        bool      reset)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    cpp_int node_val;
    cpp_int strict_val;
    uint32_t val = 1;

    if (reset == true) {
        val = 0;
    }

    switch (port) {
//::
//:: for p in range(TM_PORTS):
//::
    case ${p}:
        if (is_strict == true) {
            pbc_csr.port_${p}.cfg_oq_arb_l2_strict.read();

            strict_val = pbc_csr.port_${p}.cfg_oq_arb_l2_strict.priority();
            cpp_helper.set_slc(strict_val, val, input, input);

            pbc_csr.port_${p}.cfg_oq_arb_l2_strict.priority(strict_val);
            pbc_csr.port_${p}.cfg_oq_arb_l2_strict.write();
        }

        switch (node) {
//::
//::     for node in range(4):
//::
        case ${node}:
            pbc_csr.port_${p}.cfg_oq_arb_l2_selection.read();
            node_val = pbc_csr.port_${p}.cfg_oq_arb_l2_selection.node_${node}();

            cpp_helper.set_slc(node_val, val, input, input);

            pbc_csr.port_${p}.cfg_oq_arb_l2_selection.node_${node}(node_val);
            pbc_csr.port_${p}.cfg_oq_arb_l2_selection.write();
            break;

//::
//::     #endfor
//::
        }
        break;

//::
//:: #endfor
//::
    }

    return SDK_RET_OK;
}

sdk_ret_t
cap_pb_sched_l3_update (tm_port_t port,
                        uint32_t  l2_strict_node,
                        bool      is_strict,
                        uint64_t  priority_bypass_timer)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;

    switch (port) {
    case 9:
        pbc_csr.port_9.cfg_oq_arb_l3_strict.read();

        if(is_strict == true) {
              pbc_csr.port_9.cfg_oq_arb_l3_strict.priority(
                          pbc_csr.port_9.cfg_oq_arb_l3_strict.priority().
                                    convert_to<int>() | 1 << l2_strict_node);
        }

        pbc_csr.port_9.cfg_oq_arb_l3_strict.write();
        break;

    case 10:
        pbc_csr.port_10.cfg_oq_arb_l3_strict.read();

        if(is_strict == true) {
            pbc_csr.port_10.cfg_oq_arb_l3_strict.priority(
                        pbc_csr.port_10.cfg_oq_arb_l3_strict.priority().
                                    convert_to<int>() | 1 << l2_strict_node);
        }

        if(priority_bypass_timer != 0) {
            pbc_csr.port_10.cfg_oq_arb_l3_strict.priority_bypass_timer(
                pbc_csr.port_10.cfg_oq_arb_l3_strict.priority_bypass_timer().
                                    convert_to<int>() | 1 << l2_strict_node);
        }

        pbc_csr.port_10.cfg_oq_arb_l3_strict.write();
        break;

    case 11:
        pbc_csr.port_11.cfg_oq_arb_l3_strict.read();

        if(is_strict == true) {
            pbc_csr.port_11.cfg_oq_arb_l3_strict.priority(
                        pbc_csr.port_11.cfg_oq_arb_l3_strict.priority().
                                    convert_to<int>() | 1 << l2_strict_node);
        }

        if(priority_bypass_timer != 0) {
            pbc_csr.port_11.cfg_oq_arb_l3_strict.priority_bypass_timer(
                pbc_csr.port_11.cfg_oq_arb_l3_strict.priority_bypass_timer().
                                    convert_to<int>() | 1 << l2_strict_node);
        }

        pbc_csr.port_11.cfg_oq_arb_l3_strict.write();
        break;

    default:
        break;
    }

    //read to flush writes
    pbc_csr.cfg_island_control.read();

    return SDK_RET_OK;
}

static uint32_t
cap_pb_sched_get_num_inputs (tm_port_t port,
                             tm_queue_node_type_t node_type,
                             uint32_t node)
{
    return pb_sched_port_cfg[port].node_cfg[node_type].
                                input_cfg[node].num_inputs;
}

sdk_ret_t
cap_pb_sched_spq_pgm (uint32_t chip_id, uint32_t inst_id,
                      tm_port_t port,
                      tm_q_t oq,
                      pb_sched_node_input_info_t *input_info)
{
    uint32_t l1_node = 0;
    uint32_t l2_node = 0;
    static uint32_t l2_strict_node = 0xFFFFFFFF;
    bool remove = true;
    bool is_strict = input_info->is_strict;
    sdk_ret_t ret = SDK_RET_OK;

    /**
     * remove the inputs from LEVEL_1 and LEVEL_2 nodes
     * and reprogram the nodes
     */

    // remove the oq from the LEVEL_1 node
    cap_pb_sched_find_and_remove_index(port,
                                       TM_QUEUE_NODE_TYPE_LEVEL_1,
                                       oq,
                                       &l1_node,
                                       true);
    // program LEVEL_1 node cfg
    cap_pb_sched_node_pgm(
                chip_id, inst_id, port,
                &pb_sched_port_cfg[port].node_cfg[TM_QUEUE_NODE_TYPE_LEVEL_1],
                TM_QUEUE_NODE_TYPE_LEVEL_1, l1_node);

    cap_pb_sched_l1_update(port, l1_node, oq, false, true);

    remove = cap_pb_sched_get_num_inputs(
                    port, TM_QUEUE_NODE_TYPE_LEVEL_1, l1_node) == 0;

    // remove the LEVEL_1 node from the LEVEL_2 node
    cap_pb_sched_find_and_remove_index(port,
                                       TM_QUEUE_NODE_TYPE_LEVEL_2,
                                       l1_node,
                                       &l2_node,
                                       remove);
    // program LEVEL_2 node cfg
    cap_pb_sched_node_pgm(
                chip_id, inst_id, port,
                &pb_sched_port_cfg[port].node_cfg[TM_QUEUE_NODE_TYPE_LEVEL_2],
                TM_QUEUE_NODE_TYPE_LEVEL_2, l2_node);

    cap_pb_sched_l2_update(port, l2_node, l1_node, false, remove);

    /**
     * allocate inputs for LEVEL_1 and LEVEL_2 nodes
     * and reprogram the nodes
     */

    // allocate LEVEL_1 node
    l1_node = 0xFFFFFFFF;

    ret = cap_pb_sched_node_alloc(port, TM_QUEUE_NODE_TYPE_LEVEL_1, &l1_node);
    if (ret == SDK_RET_ERR) {
        return ret;
    }

    // set the oq for LEVEL_1 node
    cap_pb_sched_inputs_bitmap_alloc(port,
                                     TM_QUEUE_NODE_TYPE_LEVEL_1,
                                     l1_node,
                                     (uint32_t*)&oq,
                                     input_info);
    // program LEVEL_1 node cfg
    cap_pb_sched_node_pgm(
            chip_id, inst_id, port,
            &pb_sched_port_cfg[port].node_cfg[TM_QUEUE_NODE_TYPE_LEVEL_1],
            TM_QUEUE_NODE_TYPE_LEVEL_1, l1_node);

    cap_pb_sched_l1_update(port, l1_node, oq, is_strict, false);

    // remove the newly allocated L1_NODE from the older L2_NODE
    cap_pb_sched_l2_update(port, l2_node, l1_node, false, true);

    // allocate LEVEL_2 node
    if (l2_strict_node == 0xFFFFFFFF) {
        ret = cap_pb_sched_node_alloc(port, TM_QUEUE_NODE_TYPE_LEVEL_2,
                                      &l2_strict_node);
        if (ret == SDK_RET_ERR) {
            return ret;
        }
    }

    // set the input for LEVEL_2 node
    cap_pb_sched_inputs_bitmap_alloc(port,
                                     TM_QUEUE_NODE_TYPE_LEVEL_2,
                                     l2_strict_node,
                                     &l1_node,
                                     input_info);
    // program LEVEL_2 node cfg
    cap_pb_sched_node_pgm(
                chip_id, inst_id, port,
                &pb_sched_port_cfg[port].node_cfg[TM_QUEUE_NODE_TYPE_LEVEL_2],
                TM_QUEUE_NODE_TYPE_LEVEL_2, l2_strict_node);

    cap_pb_sched_l2_update(port, l2_strict_node, l1_node, is_strict, false);

    cap_pb_sched_l3_update(port, l2_strict_node, is_strict,
                           input_info->priority_bypass_timer);
    return SDK_RET_OK;
}

static sdk_ret_t
cap_pb_sched_node_cfg_init (int chip_id, int inst_id, int port,
                            pb_sched_node_cfg_t *node_cfg,
                            tm_queue_node_type_t node_type,
                            uint32_t num_nodes)
{
    uint32_t level = 0;
    node_cfg->node_type = node_type;
    node_cfg->num_nodes = num_nodes;
    node_cfg->node_bitmap = sdk::lib::indexer::factory(
                                        CAPRI_TM_MAX_SCHED_NODES);
    if (NULL == node_cfg->node_bitmap) {
        return SDK_RET_ERR;
    }

    for (uint32_t node = 0; node < num_nodes; ++node) {
        pb_sched_node_input_cfg_t *input_cfg = &node_cfg->input_cfg[node];
        input_cfg->inputs_bitmap = sdk::lib::indexer::factory(
                                    CAPRI_TM_MAX_SCHED_NODE_INPUTS);
        if (NULL == input_cfg->inputs_bitmap) {
            return SDK_RET_ERR;
        }

        switch (node_type) {
        case TM_QUEUE_NODE_TYPE_LEVEL_1:
            if (node == 0) {
                cap_pb_sched_node_alloc(port, node_type, &node);
                input_cfg->num_inputs    = 32;
                input_cfg->total_weights = 32;
                level = 1;
            }
            break;

        case TM_QUEUE_NODE_TYPE_LEVEL_2:
            if (node == 0) {
                cap_pb_sched_node_alloc(port, node_type, &node);
                input_cfg->num_inputs    = 16;
                input_cfg->total_weights = 16;
                level = 2;
            }
            break;

        case TM_QUEUE_NODE_TYPE_LEVEL_3:
        default:
            if (node == 0) {
                cap_pb_sched_node_alloc(port, node_type, &node);
                input_cfg->num_inputs    = 4;
                input_cfg->total_weights = 4;
                level = 3;
            }
            break;
        }   // switch (node_type)

        for (uint32_t input = 0; input < input_cfg->num_inputs;
                                                ++input) {
            input_cfg->inputs_bitmap->alloc_withid(input, 1);
            pb_sched_node_input_info_t *input_info =
                                       &input_cfg->input_info[input];
            input_info->weight = 1;
            input_info->dwrr_ratio = (input_info->weight * 100.0) /
                                        input_cfg->total_weights;
            input_info->cfg_quota = input_info->dwrr_ratio * CAPRI_TM_DWRR_UNIT
                                    * input_cfg->total_weights;
            cap_pb_cfg_sched_node(
                chip_id, inst_id, level, port, input, input_info->cfg_quota);
        }
    } // for each node

    return SDK_RET_OK;
}

static sdk_ret_t
cap_pb_sched_cfg_init (int chip_id, int inst_id)
{
    sdk_ret_t sdk_ret = SDK_RET_OK;
    cap_pbc_csr_t & pbc_csr =
                CAP_BLK_REG_MODEL_ACCESS(cap_pbc_csr_t, chip_id, inst_id);

    for (int port = 0; port < CAPRI_TM_MAX_PORTS; ++port) {
        for (int level = 0; level < TM_QUEUE_NODE_TYPE_LEVEL_MAX; ++level) {
            pb_sched_node_cfg_t *node_cfg = &pb_sched_port_cfg[port].node_cfg[level];
            switch (level) {
            case 0:
                sdk_ret = cap_pb_sched_node_cfg_init(chip_id, inst_id,
                              port, node_cfg, TM_QUEUE_NODE_TYPE_LEVEL_1, 16);
                if (sdk_ret != SDK_RET_OK) {
                    return sdk_ret;
                }
                break;

            case 1:
                sdk_ret = cap_pb_sched_node_cfg_init(chip_id, inst_id,
                              port, node_cfg, TM_QUEUE_NODE_TYPE_LEVEL_2, 4);
                if (sdk_ret != SDK_RET_OK) {
                    return sdk_ret;
                }
                break;

            case 2:
            default:
                sdk_ret = cap_pb_sched_node_cfg_init(chip_id, inst_id,
                              port, node_cfg, TM_QUEUE_NODE_TYPE_LEVEL_3, 1);
                if (sdk_ret != SDK_RET_OK) {
                    return sdk_ret;
                }
                break;
            }
        }
    }

//::
//:: for p in range(TM_PORTS):
//::
    pbc_csr.port_${p}.cfg_oq_arb_l1_selection.all(0);
    pbc_csr.port_${p}.cfg_oq_arb_l1_selection.write();

    for (int q_idx = 0; q_idx < 32; ++q_idx) {
//::
//::     for node in range(16):
//::
        if (cap_pb_sched_node_set(${p}, 0, ${node}, q_idx)) {
            pbc_csr.port_${p}.cfg_oq_arb_l1_selection.node_${node}(
                pbc_csr.port_${p}.cfg_oq_arb_l1_selection.node_${node}().
                                        convert_to<int>() | 1 << q_idx);
        }
//::
//::     #endfor
//::
    }

    pbc_csr.port_${p}.cfg_oq_arb_l1_strict.all(0);

    if (0) {
        pbc_csr.port_${p}.cfg_oq_arb_l1_strict.priority(0);
    }

    pbc_csr.port_${p}.cfg_oq_arb_l1_selection.write();
    pbc_csr.port_${p}.cfg_oq_arb_l1_strict.write();

//::
//:: #endfor
//:: for p in range(TM_PORTS):
//::
    pbc_csr.port_${p}.cfg_oq_arb_l2_selection.all(0);

    for (int l1_node_idx = 0; l1_node_idx < 16; ++l1_node_idx) {
//::
//::     for node in range(4):
//::
        if (cap_pb_sched_node_set(${p}, 1, ${node}, l1_node_idx)) {
            pbc_csr.port_${p}.cfg_oq_arb_l2_selection.node_${node}(
                pbc_csr.port_${p}.cfg_oq_arb_l2_selection.node_${node}().
                                        convert_to<int>() | 1 << l1_node_idx);
        }

//::
//::     #endfor
//::
        pbc_csr.port_${p}.cfg_oq_arb_l2_strict.all(0);

        if (0) {
            pbc_csr.port_${p}.cfg_oq_arb_l2_strict.priority(
                    pbc_csr.port_${p}.cfg_oq_arb_l2_strict.priority().
                    convert_to<int>() | 1 << l1_node_idx);
        }

        pbc_csr.port_${p}.cfg_oq_arb_l2_selection.write();
        pbc_csr.port_${p}.cfg_oq_arb_l2_strict.write();
    }

//::
//:: #endfor
//::
    pbc_csr.port_9.cfg_oq_arb_l3_strict.all(0);

    for(int l2_node_idx=0; l2_node_idx<4; l2_node_idx++) {
        if (0) {
        // if (cap_pb_sched_node_set(9, 2, 0, l2_node_idx)) {
            pbc_csr.port_9.cfg_oq_arb_l3_strict.priority(pbc_csr.port_9.cfg_oq_arb_l3_strict.priority().convert_to<int>() | 1 << l2_node_idx);
        }
    }

    pbc_csr.port_9.cfg_oq_arb_l3_strict.write();

    pbc_csr.port_10.cfg_oq_arb_l3_strict.all(0);

    for(int l2_node_idx=0; l2_node_idx<4; l2_node_idx++) {
        if (0) {
        // if (cap_pb_sched_node_set(10, 2, 0, l2_node_idx)) {
            pbc_csr.port_10.cfg_oq_arb_l3_strict.priority(pbc_csr.port_10.cfg_oq_arb_l3_strict.priority().convert_to<int>() | 1 << l2_node_idx);
        }
        if (0) {
        // if (cap_pb_sched_node_set(10, 2, 0, l2_node_idx)) {
            pbc_csr.port_10.cfg_oq_arb_l3_strict.priority_bypass_timer(pbc_csr.port_10.cfg_oq_arb_l3_strict.priority_bypass_timer().convert_to<int>() | 1 << l2_node_idx);
        }
    }

    pbc_csr.port_10.cfg_oq_arb_l3_strict.write();

    pbc_csr.port_11.cfg_oq_arb_l3_strict.all(0);

    for(int l2_node_idx=0; l2_node_idx<4; l2_node_idx++) {
        if (0) {
        // if (cap_pb_sched_node_set(11, 2, 0, l2_node_idx)) {
            pbc_csr.port_11.cfg_oq_arb_l3_strict.priority(pbc_csr.port_11.cfg_oq_arb_l3_strict.priority().convert_to<int>() | 1 << l2_node_idx);
        }
        if (0) {
        // if (cap_pb_sched_node_set(11, 2, 0, l2_node_idx)) {
            pbc_csr.port_11.cfg_oq_arb_l3_strict.priority_bypass_timer(pbc_csr.port_11.cfg_oq_arb_l3_strict.priority_bypass_timer().convert_to<int>() | 1 << l2_node_idx);
        }
    }

    pbc_csr.port_11.cfg_oq_arb_l3_strict.write();

    // read to flush writes
    pbc_csr.cfg_island_control.read();

    return sdk_ret;
}

sdk_ret_t
cap_pb_cfg_sched(int chip_id, int inst_id, int is_random)
{
    cap_pbc_csr_t & pbc_csr =
                CAP_BLK_REG_MODEL_ACCESS(cap_pbc_csr_t, chip_id, inst_id);

    unsigned int clk_period = 833;
    unsigned int bus_width  = 512;

    unsigned int l1_sched_dwrr_unit;
    unsigned int l1_node[12][32];
    unsigned int l1_is_strict[12][32];
    unsigned int l1_priority_bypass_timer[12][32];
    unsigned int l1_wt_rate[12][32];
    float l1_dwrr_ratio[12][32];
    unsigned int l1_sp_rate_mbps[12][32];

    unsigned int l1_per_node_tot_wt[12][16];
    unsigned int l1_per_node_tot_dwrr_inputs[12][16];
    unsigned int l2_node[12][16];
    unsigned int l2_is_strict[12][16];
    unsigned int l2_priority_bypass_timer[12][16];
    unsigned int l2_wt_rate[12][16];
    float l2_dwrr_ratio[12][16];
    unsigned int l2_sp_rate_mbps[12][16];

    unsigned int l2_per_node_tot_wt[12][4];
    unsigned int l2_per_node_tot_dwrr_inputs[12][4];

    unsigned int l3_node[12][4];
    unsigned int l3_is_strict[12][4];
    unsigned int l3_priority_bypass_timer[12][4];
    unsigned int l3_wt_rate[12][4];
    float l3_dwrr_ratio[12][4];
    unsigned int l3_sp_rate_mbps[12][4];

    unsigned int l3_per_node_tot_wt[12][1];
    unsigned int l3_per_node_tot_dwrr_inputs[12][1];
    int cfg_quota;

    l1_sched_dwrr_unit = 10000;

    unsigned long long sched_timer = 5000;
    pbc_csr.cfg_sched.timer(sched_timer);
    pbc_csr.cfg_sched.write();

    // Configuration for L1 scheduler
    for(int p_idx=0; p_idx<12; p_idx++) {
        for(int node_idx=0; node_idx<16; node_idx++) {
            l1_per_node_tot_wt[p_idx][node_idx]          = 0;
            l1_per_node_tot_dwrr_inputs[p_idx][node_idx] = 0;
        }

        for(int q_idx=0; q_idx<32; q_idx++) {
            if(is_random) {
            } else {
                l1_node[p_idx][q_idx]                   = 0;
                l1_is_strict[p_idx][q_idx]              = 0;
                l1_priority_bypass_timer[p_idx][q_idx]  = 0;
                l1_wt_rate[p_idx][q_idx]                = 1;
                l1_sp_rate_mbps[p_idx][q_idx]           = 0;
            }

            if(l1_is_strict[p_idx][q_idx] == 0) {
                l1_per_node_tot_wt[p_idx][l1_node[p_idx][q_idx]] +=
                                                    l1_wt_rate[p_idx][q_idx];
                l1_per_node_tot_dwrr_inputs[p_idx][l1_node[p_idx][q_idx]]
                                    += (l1_wt_rate[p_idx][q_idx] == 0) ? 0 : 1;
            }
        }

        for(int q_idx=0; q_idx<32; q_idx++) {
            if(l1_is_strict[p_idx][q_idx] == 0 &&
                                        l1_wt_rate[p_idx][q_idx] != 0) {
                l1_dwrr_ratio[p_idx][q_idx] = (l1_wt_rate[p_idx][q_idx] * 100.0)/
                            (l1_per_node_tot_wt[p_idx][l1_node[p_idx][q_idx]]);
            } else {
                l1_dwrr_ratio[p_idx][q_idx] = 0;
            }

            if(l1_is_strict[p_idx][q_idx] == 0) {
                l1_sp_rate_mbps[p_idx][q_idx] = 0;
            }

            if(l1_dwrr_ratio[p_idx][q_idx] != 0) {
                cfg_quota = (l1_dwrr_ratio[p_idx][q_idx] * l1_sched_dwrr_unit *
                    l1_per_node_tot_dwrr_inputs[p_idx][l1_node[p_idx][q_idx]]);

                cap_pb_cfg_sched_node(
                                    chip_id, inst_id, 1, p_idx, q_idx, cfg_quota);
            } else if(l1_is_strict[p_idx][q_idx] != 0) {
                if(l1_priority_bypass_timer[p_idx][q_idx] != 0) {
                    cfg_quota = 10 + ( sched_timer % 1000 );
                } else {
                    cfg_quota = ((l1_sp_rate_mbps[p_idx][q_idx] *
                                (unsigned long long) 64 * sched_timer)/
                                (clk_period*bus_width));
                }

                cap_pb_cfg_sched_node(
                                chip_id, inst_id, 1, p_idx, q_idx, cfg_quota);
            }
        }
    } //for port

    //Configuration for L2 scheduler
    for(int p_idx=0; p_idx<12; p_idx++) {
        for(int node_idx=0; node_idx<4; node_idx++) {
            l2_per_node_tot_wt[p_idx][node_idx]          = 0;
            l2_per_node_tot_dwrr_inputs[p_idx][node_idx] = 0;
        }

        for(int node_idx=0; node_idx<16; node_idx++) {
            if(is_random) {
            } else {
                l2_node[p_idx][node_idx]                  = 0;
                l2_is_strict[p_idx][node_idx]             = 0;
                l2_priority_bypass_timer[p_idx][node_idx] = 0;
                l2_wt_rate[p_idx][node_idx]               = 1;
                l2_sp_rate_mbps[p_idx][node_idx]          = 0;
            }

            if(l2_is_strict[p_idx][node_idx] == 0) {
                l2_per_node_tot_wt[p_idx][l2_node[p_idx][node_idx]] +=
                                            l2_wt_rate[p_idx][node_idx];
                l2_per_node_tot_dwrr_inputs[p_idx][l2_node[p_idx][node_idx]] +=
                                (l2_wt_rate[p_idx][node_idx] == 0) ? 0 :
                                l1_per_node_tot_dwrr_inputs[p_idx][node_idx];
            }
        }

        for(int node_idx=0; node_idx<16; node_idx++) {
            if(l2_is_strict[p_idx][node_idx] == 0 &&
                           l2_wt_rate[p_idx][node_idx] != 0) {
                l2_dwrr_ratio[p_idx][node_idx] =
                        (l2_wt_rate[p_idx][node_idx] * 100.0)/
                        (l2_per_node_tot_wt[p_idx][l2_node[p_idx][node_idx]]);
            } else {
                l2_dwrr_ratio[p_idx][node_idx] = 0;
            }

            if(l2_is_strict[p_idx][node_idx] == 0) {
                l2_sp_rate_mbps[p_idx][node_idx] = 0;
            }

            if(l2_dwrr_ratio[p_idx][node_idx] != 0) {
                cfg_quota  = (l2_dwrr_ratio[p_idx][node_idx] *
                              l1_sched_dwrr_unit *
                              l2_per_node_tot_dwrr_inputs
                                            [p_idx][l2_node[p_idx][node_idx]]);

                cap_pb_cfg_sched_node(
                            chip_id, inst_id, 2, p_idx, node_idx, cfg_quota);
            } else if(l2_is_strict[p_idx][node_idx] != 0) {
                if(l2_priority_bypass_timer[p_idx][node_idx] != 0) {
                    cfg_quota = 10 + ( sched_timer % 1000 );
                } else {
                    cfg_quota = ((l2_sp_rate_mbps[p_idx][node_idx] *
                                 (unsigned long long) 64 * sched_timer) /
                                 (clk_period*bus_width));
                }

                cap_pb_cfg_sched_node(
                            chip_id, inst_id, 2, p_idx, node_idx, cfg_quota);
            }
        }
    } //for port

    //Configuration for L3 scheduler
    for(int p_idx=9; p_idx<12; p_idx++) {
        for(int node_idx=0; node_idx<1; node_idx++) {
            l3_per_node_tot_wt[p_idx][node_idx]          = 0;
            l3_per_node_tot_dwrr_inputs[p_idx][node_idx] = 0;
        }

        for(int node_idx=0; node_idx<4; node_idx++) {
            if(is_random) {
            } else {
                l3_node[p_idx][node_idx]                  = 0;
                l3_is_strict[p_idx][node_idx]             = 0;
                l3_priority_bypass_timer[p_idx][node_idx] = 0;
                l3_wt_rate[p_idx][node_idx]               = 1;
                l3_sp_rate_mbps[p_idx][node_idx]          = 0;
            }

            if(l3_is_strict[p_idx][node_idx] == 0) {
                l3_per_node_tot_wt[p_idx][l3_node[p_idx][node_idx]] +=
                                                l3_wt_rate[p_idx][node_idx];

                l3_per_node_tot_dwrr_inputs[p_idx][l3_node[p_idx][node_idx]] +=
                                    (l3_wt_rate[p_idx][node_idx] == 0) ? 0 :
                                    l2_per_node_tot_dwrr_inputs[p_idx][node_idx];
            }
        }

        for(int node_idx=0; node_idx<4; node_idx++) {
            if(l3_is_strict[p_idx][node_idx] == 0 &&
                                            l3_wt_rate[p_idx][node_idx] != 0) {
                l3_dwrr_ratio[p_idx][node_idx] =
                        (l3_wt_rate[p_idx][node_idx] * 100.0) /
                        (l3_per_node_tot_wt[p_idx][l3_node[p_idx][node_idx]]);
            } else {
                l3_dwrr_ratio[p_idx][node_idx] = 0;
            }

            if(l3_is_strict[p_idx][node_idx] == 0) {
                l3_sp_rate_mbps[p_idx][node_idx] = 0;
            }

            if(l3_dwrr_ratio[p_idx][node_idx] != 0) {
                cfg_quota  = (l3_dwrr_ratio[p_idx][node_idx] *
                              l1_sched_dwrr_unit *
                              l3_per_node_tot_dwrr_inputs
                                        [p_idx][l3_node[p_idx][node_idx]]);

                cap_pb_cfg_sched_node(
                            chip_id, inst_id, 3, p_idx, node_idx, cfg_quota);
            } else if(l3_is_strict[p_idx][node_idx] != 0) {
                if(l3_priority_bypass_timer[p_idx][node_idx] != 0) {
                    cfg_quota = 10 + ( sched_timer % 1000 );
                } else {
                    cfg_quota = ((l3_sp_rate_mbps[p_idx][node_idx] *
                                64 * sched_timer) / (clk_period*bus_width));
                }
                cap_pb_cfg_sched_node(
                            chip_id, inst_id, 3, p_idx, node_idx, cfg_quota);
            }
        }
    } //for port

//::
//:: for p in range(TM_PORTS):
//::
    pbc_csr.port_${p}.cfg_oq_arb_l1_selection.all(0);

    for (int q_idx = 0; q_idx < 32; ++q_idx) {
//::
//::     for node in range(16):
//::
        if (l1_node[${p}][q_idx] == ${node}) {
            pbc_csr.port_${p}.cfg_oq_arb_l1_selection.node_${node}(
                pbc_csr.port_${p}.cfg_oq_arb_l1_selection.node_${node}().
                                        convert_to<int>() | 1 << q_idx);
        }

//::
//::     #endfor
//::
        pbc_csr.port_${p}.cfg_oq_arb_l1_strict.all(0);

        if(l1_is_strict[${p}][q_idx] == 1) {
            pbc_csr.port_${p}.cfg_oq_arb_l1_strict.priority(
                    pbc_csr.port_${p}.cfg_oq_arb_l1_strict.priority().
                    convert_to<int>() | 1 << q_idx);
        }

        pbc_csr.port_${p}.cfg_oq_arb_l1_selection.write();
        pbc_csr.port_${p}.cfg_oq_arb_l1_strict.write();
    }

//::
//:: #endfor
//::

//::
//:: for p in range(TM_PORTS):
//::
    pbc_csr.port_${p}.cfg_oq_arb_l2_selection.all(0);

    for (int l1_node_idx = 0; l1_node_idx < 16; ++l1_node_idx) {
//::
//::     for node in range(4):
//::
        if (l2_node[${p}][l1_node_idx] == ${node}) {
            pbc_csr.port_${p}.cfg_oq_arb_l2_selection.node_${node}(
                pbc_csr.port_${p}.cfg_oq_arb_l2_selection.node_${node}().
                                        convert_to<int>() | 1 << l1_node_idx);
        }

//::
//::     #endfor
//::
        pbc_csr.port_${p}.cfg_oq_arb_l2_strict.all(0);

        if(l2_is_strict[${p}][l1_node_idx] == 1) {
            pbc_csr.port_${p}.cfg_oq_arb_l2_strict.priority(
                    pbc_csr.port_${p}.cfg_oq_arb_l2_strict.priority().
                    convert_to<int>() | 1 << l1_node_idx);
        }

        pbc_csr.port_${p}.cfg_oq_arb_l2_selection.write();
        pbc_csr.port_${p}.cfg_oq_arb_l2_strict.write();
    }

//::
//:: #endfor
//::
    // pbc_csr.port_9.cfg_oq_arb_l3_selection.all(0);
    // for(int l2_node_idx=0; l2_node_idx<4; l2_node_idx++) {
    //   if(l3_node[9][l2_node_idx] == 0) {
    //     pbc_csr.port_9.cfg_oq_arb_l3_selection.node_0(pbc_csr.port_9.cfg_oq_arb_l3_selection.node_0().convert_to<int>() | 1 << l2_node_idx);
    //   }
    // }
    // pbc_csr.port_9.cfg_oq_arb_l3_selection.write();

    pbc_csr.port_9.cfg_oq_arb_l3_strict.all(0);

    for(int l2_node_idx=0; l2_node_idx<4; l2_node_idx++) {
        if(l3_is_strict[9][l2_node_idx] == 1) {
            pbc_csr.port_9.cfg_oq_arb_l3_strict.priority(pbc_csr.port_9.cfg_oq_arb_l3_strict.priority().convert_to<int>() | 1 << l2_node_idx);
        }
    }

    pbc_csr.port_9.cfg_oq_arb_l3_strict.write();

    // pbc_csr.port_10.cfg_oq_arb_l3_selection.all(0);
    // for(int l2_node_idx=0; l2_node_idx<4; l2_node_idx++) {
    //   if(l3_node[10][l2_node_idx] == 0) {
    //     pbc_csr.port_10.cfg_oq_arb_l3_selection.node_0(pbc_csr.port_10.cfg_oq_arb_l3_selection.node_0().convert_to<int>() | 1 << l2_node_idx);
    //   }
    // }
    // pbc_csr.port_10.cfg_oq_arb_l3_selection.write();

    pbc_csr.port_10.cfg_oq_arb_l3_strict.all(0);

    for(int l2_node_idx=0; l2_node_idx<4; l2_node_idx++) {
        if(l3_is_strict[10][l2_node_idx] == 1) {
            pbc_csr.port_10.cfg_oq_arb_l3_strict.priority(pbc_csr.port_10.cfg_oq_arb_l3_strict.priority().convert_to<int>() | 1 << l2_node_idx);
        }
        if(l3_priority_bypass_timer [10][l2_node_idx] == 1) {
            pbc_csr.port_10.cfg_oq_arb_l3_strict.priority_bypass_timer(pbc_csr.port_10.cfg_oq_arb_l3_strict.priority_bypass_timer().convert_to<int>() | 1 << l2_node_idx);
        }
    }

    pbc_csr.port_10.cfg_oq_arb_l3_strict.write();

    // pbc_csr.port_11.cfg_oq_arb_l3_selection.all(0);
    // for(int l2_node_idx=0; l2_node_idx<4; l2_node_idx++) {
    //   if(l3_node[11][l2_node_idx] == 0) {
    //     pbc_csr.port_11.cfg_oq_arb_l3_selection.node_0(pbc_csr.port_11.cfg_oq_arb_l3_selection.node_0().convert_to<int>() | 1 << l2_node_idx);
    //   }
    // }
    // pbc_csr.port_11.cfg_oq_arb_l3_selection.write();

    pbc_csr.port_11.cfg_oq_arb_l3_strict.all(0);

    for(int l2_node_idx=0; l2_node_idx<4; l2_node_idx++) {
        if(l3_is_strict[11][l2_node_idx] == 1) {
            pbc_csr.port_11.cfg_oq_arb_l3_strict.priority(pbc_csr.port_11.cfg_oq_arb_l3_strict.priority().convert_to<int>() | 1 << l2_node_idx);
        }
        if(l3_priority_bypass_timer [11][l2_node_idx] == 1) {
            pbc_csr.port_11.cfg_oq_arb_l3_strict.priority_bypass_timer(pbc_csr.port_11.cfg_oq_arb_l3_strict.priority_bypass_timer().convert_to<int>() | 1 << l2_node_idx);
        }
    }

    pbc_csr.port_11.cfg_oq_arb_l3_strict.write();

    // read to flush writes
    pbc_csr.cfg_island_control.read();

    return SDK_RET_OK;
}

static sdk_ret_t
capri_tm_init_pbc (capri_tm_buf_cfg_t *buf_cfg)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;

    ret = capri_tm_alloc_pbc_buffers(buf_cfg);
    if (ret != sdk::SDK_RET_OK) {
        SDK_TRACE_ERR("Error allocating buffer configs %d", ret);
        return ret;
    }

    ret = capri_tm_port_program_defaults();
    if (ret != sdk::SDK_RET_OK) {
        SDK_TRACE_ERR("Error programming port defaults %d", ret);
        return ret;
    }

    ret = cap_pb_sched_cfg_init(0, 0);
    if (ret != sdk::SDK_RET_OK) {
        SDK_TRACE_ERR("Error programming scheduler defaults %d", ret);
        return ret;
    }

#if 0
    ret = cap_pb_cfg_sched(0, 0, 0);
    if (ret != sdk::SDK_RET_OK) {
        SDK_TRACE_ERR("Error programming scheduler defaults %d", ret);
        return ret;
    }
#endif

    ret = capri_tm_program_buffers(buf_cfg);
    if (ret != sdk::SDK_RET_OK) {
        SDK_TRACE_ERR("Error allocating buffer configs %d", ret);
        return ret;
    }

    return sdk::SDK_RET_OK;
}

static sdk_ret_t
capri_tm_init_hbm_q_map (void)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    cap_pbchbm_csr_t &hbm_csr = pbc_csr.hbm;
    tm_port_type_e port_type;
    uint32_t p4_oq;
    cpp_int oq_map_val;
    cpp_int hbm_tc_to_q_val;
    cap_pbc_oq_map_t oq_map_decoder;
    oq_map_decoder.init();

    // Map traffic to the contexts
    // On uplink by default, map everything to context 0
    // On DMA port, map each iq to each context
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["has_hbm"] or pinfo["enum"] == "CAPRI_TM_PORT_NCSI":
    // ${pinfo["enum"]}
    hbm_tc_to_q_val = 0;
    port_type = capri_tm_get_port_type(${pinfo["enum"]});
//::        if pinfo["type"] == "dma":
    for (unsigned tc = 0; tc < tm_cfg_profile()->num_qs[port_type]; tc++) {
        cpp_helper.set_slc(hbm_tc_to_q_val, tc, tc*4, ((tc+1)*4)-1);
    }
//::        #endif
    hbm_csr.hbm_port_${p}.cfg_hbm_tc_to_q.read();
    hbm_csr.hbm_port_${p}.cfg_hbm_tc_to_q.table(hbm_tc_to_q_val);

    if (tm_sw_init_enabled()) {
        cap_pbc_pg${pinfo["pgs"]}_map_t pg_map_decoder;
        pg_map_decoder.init();
        pg_map_decoder.all(hbm_csr.hbm_port_${p}.cfg_hbm_tc_to_q.table());
        pg_map_decoder.set_name("cap0.pb.pbc.hbm.hbm_port_${p}.cfg_hbm_tc_to_q.decoder");
        pg_map_decoder.show();

        stringstream data;
        data << hex << endl;
        ${trace_register("pbc_csr.hbm.hbm_port_" + str(p) + ".cfg_hbm_tc_to_q")}
        SDK_TRACE_DEBUG("%s", data.str().c_str());

        hbm_csr.hbm_port_${p}.cfg_hbm_tc_to_q.write();
    }
//::    #endif
//:: #endfor

    // Configure the parsers
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
    // ${pinfo["enum"]}
    oq_map_val = 0;
    p4_oq = CAPRI_TM_P4_UPLINK_IQ_OFFSET;
    port_type = capri_tm_get_port_type(${pinfo["enum"]});

    hbm_csr.hbm_port_${p}.cfg_hbm_parser.read();
    hbm_csr.hbm_port_${p}.cfg_hbm_parser.use_dot1q(1);
    hbm_csr.hbm_port_${p}.cfg_hbm_parser.use_ip(0);
    hbm_csr.hbm_port_${p}.cfg_hbm_parser.default_cos(0);
    hbm_csr.hbm_port_${p}.cfg_hbm_parser.dscp_map(0);

    for (unsigned tc = 0; tc < capri_tm_get_num_iqs_for_port_type(port_type); tc++) {
        cpp_helper.set_slc(oq_map_val, p4_oq, tc * 5, ((tc+1)*5)-1);
    }

    pbc_csr.cfg_parser${p}.default_cos(0);
    pbc_csr.cfg_parser${p}.oq_map(oq_map_val);

    oq_map_decoder.all(pbc_csr.cfg_parser${p}.oq_map());
    oq_map_decoder.set_name("cap0.pb.pbc.cfg_parser${p}.decoder");

    if (tm_sw_init_enabled()) {
        stringstream data;
        data << hex << endl;
        ${trace_register("pbc_csr.hbm.hbm_port_" + str(p) + ".cfg_hbm_parser")}
        ${trace_register("pbc_csr.cfg_parser" + str(p))}
        SDK_TRACE_DEBUG("%s", data.str().c_str());

        hbm_csr.hbm_port_${p}.cfg_hbm_parser.write();
        pbc_csr.cfg_parser${p}.write();
    }
//::    #endif
//:: #endfor

    return ret;
}

static sdk_ret_t
capri_tm_init_hbm (capri_tm_buf_cfg_t *buf_cfg)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    cap_pbchbm_csr_t &hbm_csr = pbc_csr.hbm;

    if (capri_tm_hbm_overflow_enabled() == true) {
        ret = capri_tm_alloc_hbm_buffers(buf_cfg);
        if (ret != sdk::SDK_RET_OK) {
            SDK_TRACE_ERR("Error allocating hbm buffers ret %d",
                          ret);
            return ret;
        }

        // Program the HBM buffers
        ret = capri_tm_program_hbm_buffers(buf_cfg);
        if (ret != sdk::SDK_RET_OK) {
            SDK_TRACE_ERR("Error programming hbm buffers ret %d",
                          ret);
            return ret;
        }
    }

    ret = capri_tm_init_hbm_q_map();
    if (ret != sdk::SDK_RET_OK) {
        SDK_TRACE_ERR("Error programming hbm q mapping ret %d",
                      ret);
        return ret;
    }

    uint32_t rate_limiter;
    stringstream data;
    data << hex << endl;
    // On configure rate-limiter from HBM
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["has_hbm"]:
    // ${pinfo["enum"]}
    if (capri_tm_port_is_uplink_port(${pinfo["enum"]})) {
        rate_limiter = (tm_cfg_profile()->num_active_uplink_ports * 2) - 1;
    } else {
        rate_limiter = 3;
    }

    hbm_csr.hbm_port_${p}.cfg_hbm.read();
    hbm_csr.hbm_port_${p}.cfg_hbm.rate_limiter(rate_limiter);

    hbm_csr.hbm_port_${p}.cfg_hbm_read_fifo.read();
    hbm_csr.hbm_port_${p}.cfg_hbm_read_fifo.max_cells(0x78);
    hbm_csr.hbm_port_${p}.cfg_hbm_read_fifo.max_flits(0x78);
    hbm_csr.hbm_port_${p}.cfg_hbm_read_fifo.max_packets(0x28);

    if (tm_sw_init_enabled()) {
        ${trace_register("pbc_csr.hbm.hbm_port_" + str(p) + ".cfg_hbm")}
        hbm_csr.hbm_port_${p}.cfg_hbm.write();
        //:: # ${trace_register("pbc_csr.hbm.hbm_port_" + str(p) + ".cfg_hbm_read_fifo")}
        // TODO: this is not written in cap_pb_api.cc
        // hbm_csr.hbm_port_${p}.cfg_hbm_read_fifo.write();
    }

//::    #endif
//:: #endfor

    hbm_csr.cfg_hbm_wb.read();
    hbm_csr.cfg_hbm_rb.read();
    hbm_csr.cfg_hbm_cut_thru.read();

    hbm_csr.cfg_hbm_rb.enable_wrr(0);

    if (tm_sw_init_enabled()) {
        // TODO: this is not written in cap_pb_api.cc
        //:: # ${trace_register("pbc_csr.hbm.cfg_hbm_wb")}
        // hbm_csr.cfg_hbm_wb.write();
        ${trace_register("pbc_csr.hbm.cfg_hbm_rb")}
        hbm_csr.cfg_hbm_rb.write();
        //:: # ${trace_register("pbc_csr.hbm.cfg_hbm_cut_thru")}
        // hbm_csr.cfg_hbm_cut_thru.write();
    }

    // AXI Base Address
    pbc_csr.cfg_axi.read();
    pbc_csr.cfg_axi.base_addr(g_capri_state_pd->mempartition()->base());
    ${trace_register("pbc_csr.cfg_axi")}
    pbc_csr.cfg_axi.write();

    // AXI Base for buffer FIFOs
    pbc_csr.hbm.cfg_hbm_axi_base.read();
    pbc_csr.hbm.cfg_hbm_axi_base.addr(tm_cfg_profile()->hbm_fifo_base);
    ${trace_register("pbc_csr.hbm.cfg_hbm_axi_base")}
    pbc_csr.hbm.cfg_hbm_axi_base.write();

    SDK_TRACE_DEBUG("%s", data.str().c_str());
    return sdk::SDK_RET_OK;
}

static sdk_ret_t
capri_tm_init_ports (void)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;
    capri_tm_buf_cfg_t buf_cfg = {0};

    ret = capri_tm_init_pbc(&buf_cfg);
    if (ret != sdk::SDK_RET_OK) {
        SDK_TRACE_ERR("Error initing pbc %d", ret);
        return ret;
    }

    ret = capri_tm_init_hbm(&buf_cfg);
    if (ret != sdk::SDK_RET_OK) {
        SDK_TRACE_ERR("Error initing hbm %d", ret);
        return ret;
    }
    tm_ctx()->buf_cfg = buf_cfg;
    return ret;
}

static sdk_ret_t
capri_tm_global_init (void)
{
    // Init the FC mgr and RC
    //
    // There are only 2 combinations valid with min_cell, max_row as either
    // 0, 4095 or 4096, 2559 . Choose one of them based on the island which
    // needs more cells
    uint32_t min_cells[] = { 0, 4096};
    uint32_t max_row[] = {4095, 2559};
    uint32_t sched_timer;
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    cap_pbchbm_csr_t &hbm_csr = pbc_csr.hbm;

//:: for fifo_type, finfo in hbm_fifo_info.items():
//::    reg_name = finfo["reg_name"]
    hbm_csr.cfg_hbm_${reg_name}_ctrl_init.head_start(1);
    hbm_csr.cfg_hbm_${reg_name}_ctrl_init.tail_start(1);
    if (tm_sw_init_enabled()) {
        stringstream data;
        data << hex << endl;
        ${trace_register("pbc_csr.hbm.cfg_hbm_" + reg_name + "_ctrl_init")}
        SDK_TRACE_DEBUG("%s", data.str().c_str());
        hbm_csr.cfg_hbm_${reg_name}_ctrl_init.write();
    }
//:: #endfor

//:: for fifo_type, finfo in hbm_fifo_info.items():
//::    reg_name = finfo["reg_name"]
    hbm_csr.cfg_hbm_${reg_name}_ctrl_init.head_start(0);
    hbm_csr.cfg_hbm_${reg_name}_ctrl_init.tail_start(0);
    if (tm_sw_init_enabled()) {
        stringstream data;
        data << hex << endl;
        ${trace_register("pbc_csr.hbm.cfg_hbm_" + reg_name + "_ctrl_init")}
        SDK_TRACE_DEBUG("%s", data.str().c_str());
        hbm_csr.cfg_hbm_${reg_name}_ctrl_init.write();
    }
//:: #endfor


#if 0
    pbc_csr.cfg_fc_mgr_0.read();
    pbc_csr.cfg_fc_mgr_1.read();
    pbc_csr.cfg_island_control.read();
    pbc_csr.cfg_rc.read();
    pbc_csr.cfg_tail_drop.read();
#endif

    pbc_csr.cfg_fc_mgr_0.init_start(1);
    pbc_csr.cfg_fc_mgr_0.init_reset(0);
    pbc_csr.cfg_fc_mgr_1.init_start(1);
    pbc_csr.cfg_fc_mgr_1.init_reset(0);
    if (capri_tm_get_max_cell_chunks_for_island(0) >
        capri_tm_get_max_cell_chunks_for_island(1)) {
        pbc_csr.cfg_fc_mgr_0.max_row(max_row[0]);
        pbc_csr.cfg_fc_mgr_0.min_cell(min_cells[0]);
        pbc_csr.cfg_fc_mgr_1.max_row(max_row[1]);
        pbc_csr.cfg_fc_mgr_1.min_cell(min_cells[1]);
        pbc_csr.cfg_island_control.map(0);
    } else {
        pbc_csr.cfg_fc_mgr_0.max_row(max_row[1]);
        pbc_csr.cfg_fc_mgr_0.min_cell(min_cells[1]);
        pbc_csr.cfg_fc_mgr_1.max_row(max_row[0]);
        pbc_csr.cfg_fc_mgr_1.min_cell(min_cells[0]);
        pbc_csr.cfg_island_control.map(1);
    }

    pbc_csr.cfg_rc.init_start(1);
    pbc_csr.cfg_rc.init_reset(0);

    pbc_csr.cfg_tail_drop.cpu_threshold(tm_asic_profile()->cpu_copy_tail_drop_threshold);
    pbc_csr.cfg_tail_drop.span_threshold(tm_asic_profile()->span_tail_drop_threshold);

    sched_timer = CAPRI_TM_CLOCK_SPEED_MHZ * CAPRI_TM_SCHEDULER_RATE_REFRESH_INTERVAL_US;
    pbc_csr.cfg_sched.read();
    pbc_csr.cfg_sched.timer(sched_timer);

    // Write all the registers
    if (tm_sw_init_enabled()) {
        stringstream data;
        data << hex << endl;
        ${trace_register("pbc_csr.cfg_tail_drop")}
        ${trace_register("pbc_csr.cfg_fc_mgr_0")}
        ${trace_register("pbc_csr.cfg_fc_mgr_1")}
        ${trace_register("pbc_csr.cfg_island_control")}
        ${trace_register("pbc_csr.cfg_rc")}
        ${trace_register("pbc_csr.cfg_sched")}
        SDK_TRACE_DEBUG("%s", data.str().c_str());

        pbc_csr.cfg_tail_drop.write();
        pbc_csr.cfg_fc_mgr_0.write();
        pbc_csr.cfg_fc_mgr_1.write();
        pbc_csr.cfg_island_control.write();
        pbc_csr.cfg_rc.write();
        pbc_csr.cfg_sched.write();
        SDK_TRACE_DEBUG("TM global init done");
    }
    return sdk::SDK_RET_OK;
}

static sdk_ret_t
capri_tm_init_enable_ports (void)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    tm_port_t port;
    tm_port_type_e port_type;
    uint32_t enable;
    uint32_t rate_limiter;
    uint32_t cut_thru;
    uint32_t recirc_q;
    bool set_rate_limiter;
    bool set_cut_thru;
    bool drop_on_error;

//::
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::
    // ${pinfo["enum"]}
    port = ${pinfo["enum"]};
    port_type = capri_tm_get_port_type(port);
    enable = 0;
    rate_limiter = (tm_cfg_profile()->num_active_uplink_ports * 2) - 1;
    cut_thru = 0;
    recirc_q = 0;
    set_rate_limiter = false;
    set_cut_thru = false;

    // Uplink 0: IQ is blocked though P4IG OQ is free and hence Tx pause is
    //           being sent out.
    // Uplink 1: OQ is blocked due to Rx pause.
    // Though Rx and Tx path queues are different, if PB is dropping the error
    // packets, somehow block on Tx path is affecting the Rx.
    // Hence keep drop_on_error=0x0.
    drop_on_error = false;

    if (is_active_port(${pinfo["enum"]})) {
        enable = 1;
    }
    switch(port_type) {
        case TM_PORT_TYPE_UPLINK:
            if (port != CAPRI_TM_PORT_NCSI) {
                set_rate_limiter = true;
            }
            break;
        case TM_PORT_TYPE_P4IG:
        case TM_PORT_TYPE_P4EG:
            recirc_q = tm_asic_profile()->port[port_type].recirc_q;
            set_cut_thru = true;
            cut_thru = 0;
            break;
        case TM_PORT_TYPE_DMA:
            set_cut_thru = true;
            cut_thru = 0x1f;
            break;
        case NUM_TM_PORT_TYPES:
            break;
    }
    pbc_csr.port_${p}.cfg_write_control.read();
    pbc_csr.port_${p}.cfg_write_control.enable(enable);

    // PB freeing cells from cache when toggling cfg_write_control.enable
    // can mess up the accounting. Avoid freeing cells by setting
    // release_cells=0x0
    // pbc_csr.port_${p}.cfg_write_control.release_cells(0);

    if (set_rate_limiter) {
        pbc_csr.port_${p}.cfg_write_control.rate_limiter(rate_limiter);
    }
    if (set_cut_thru) {
        pbc_csr.port_${p}.cfg_write_control.cut_thru(cut_thru);
    }
    if (drop_on_error) {
        pbc_csr.port_${p}.cfg_write_control.drop_on_error(1);
    } else {
        pbc_csr.port_${p}.cfg_write_control.drop_on_error(0);
    }
//::
//::    if pinfo["type"] == "p4":
//::
    pbc_csr.port_${p}.cfg_write_control.recirc_enable(1);
    pbc_csr.port_${p}.cfg_write_control.recirc_oq(recirc_q);
//::
//::    #endif
//::
    if (tm_sw_init_enabled()) {
        stringstream data;
        data << hex << endl;
        ${trace_register("pbc_csr.port_" + str(p) + ".cfg_write_control")}
        SDK_TRACE_DEBUG("%s", data.str().c_str());

        pbc_csr.port_${p}.cfg_write_control.write();
    }
    // Enable port flush and write control
    capri_tm_enable_disable_uplink_port(port, true);

//::
//:: #endfor
//::
    return ret;
}

static sdk_ret_t
capri_tm_init_qos_profile (capri_tm_cfg_profile_t *tm_cfg_profile,
                           sdk::lib::catalog *catalog,
                           sdk::lib::qos_profile_t *qos_profile)
{
    uint32_t interpipe_mtu;
    uint32_t jumbo_mtu     = qos_profile->jumbo_mtu;
    uint32_t num_uplink_qs = qos_profile->num_uplink_qs;
    uint32_t num_p4ig_qs   = qos_profile->num_p4ig_qs;
    uint32_t num_p4eg_qs   = qos_profile->num_p4eg_qs;
    uint32_t num_dma_qs    = qos_profile->num_dma_qs;
    uint32_t num_p4_high_perf_qs = qos_profile->num_p4_high_perf_qs;

    if (num_uplink_qs == 0) {
        SDK_TRACE_ERR("Invalid qos profile");
        return SDK_RET_ERR;
    }
    tm_cfg_profile->sw_init_enabled = true;
    tm_cfg_profile->sw_cfg_write_enabled = true;

    tm_cfg_profile->hbm_fifo_base =
        g_capri_state_pd->mempartition()->start_addr(MEM_REGION_QOS_FIFO_NAME);
    tm_cfg_profile->hbm_fifo_size =
        g_capri_state_pd->mempartition()->size(MEM_REGION_QOS_FIFO_NAME);
    tm_cfg_profile->num_active_uplink_ports = catalog->num_fp_ports();

    if (tm_cfg_profile->num_active_uplink_ports <= 1) {
        tm_cfg_profile->num_active_uplink_ports = 1;
        SDK_TRACE_INFO("num_uplink_ports %u is not valid. resetting it to %u",
                       catalog->num_fp_ports(),
                       tm_cfg_profile->num_active_uplink_ports);
    } else {
        // Do not count the BMC port
        tm_cfg_profile->num_active_uplink_ports -= 1;
    }

    tm_cfg_profile->jumbo_mtu[TM_PORT_TYPE_UPLINK] = jumbo_mtu;

    interpipe_mtu = jumbo_mtu + CAPRI_TM_MAX_INTERPIPE_HDR_SZ;
    tm_cfg_profile->jumbo_mtu[TM_PORT_TYPE_P4IG] = interpipe_mtu;
    tm_cfg_profile->jumbo_mtu[TM_PORT_TYPE_P4EG] = interpipe_mtu;
    tm_cfg_profile->jumbo_mtu[TM_PORT_TYPE_DMA] = interpipe_mtu;

    tm_cfg_profile->num_qs[TM_PORT_TYPE_UPLINK] = num_uplink_qs;
    tm_cfg_profile->num_qs[TM_PORT_TYPE_P4IG]   = num_p4ig_qs;
    tm_cfg_profile->num_qs[TM_PORT_TYPE_P4EG]   = num_p4eg_qs;
    tm_cfg_profile->num_qs[TM_PORT_TYPE_DMA]    = num_dma_qs;

    tm_cfg_profile->num_p4_high_perf_qs = num_p4_high_perf_qs;
    if (tm_cfg_profile->num_p4_high_perf_qs) {
        tm_cfg_profile->p4_high_perf_qs =
            (tm_q_t *)SDK_MALLOC(sdk::SDK_MEM_ALLOC_PD,
                                 tm_cfg_profile->num_p4_high_perf_qs * sizeof(tm_q_t));

        memcpy(tm_cfg_profile->p4_high_perf_qs, qos_profile->p4_high_perf_qs,
               tm_cfg_profile->num_p4_high_perf_qs * sizeof(tm_q_t));
    }

    if ((tm_cfg_profile->num_qs[TM_PORT_TYPE_UPLINK] *
         tm_cfg_profile->num_active_uplink_ports) > CAPRI_TM_MAX_HBM_ETH_CONTEXTS) {
        SDK_TRACE_INFO("num_uplink_ports %u  with %u qs cannot be supported"
                       " reducing the num of qs to %u",
                       tm_cfg_profile->num_active_uplink_ports,
                       tm_cfg_profile->num_qs[TM_PORT_TYPE_UPLINK],
                       CAPRI_TM_MAX_HBM_ETH_CONTEXTS/tm_cfg_profile->num_active_uplink_ports);
        tm_cfg_profile->num_qs[TM_PORT_TYPE_UPLINK] =
            CAPRI_TM_MAX_HBM_ETH_CONTEXTS/tm_cfg_profile->num_active_uplink_ports;
    }
    return sdk::SDK_RET_OK;
}

static sdk_ret_t
capri_tm_update_perf_run_config (void)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    cap_pbchbm_csr_t &hbm_csr = pbc_csr.hbm;
    stringstream data;
    data << hex << endl;
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
    // ${pinfo["enum"]}
    hbm_csr.hbm_port_${p}.cfg_hbm_parser.read();
    hbm_csr.hbm_port_${p}.cfg_hbm_parser.use_dot1q(0);
    hbm_csr.hbm_port_${p}.cfg_hbm_parser.use_ip(0);
    hbm_csr.hbm_port_${p}.cfg_hbm_parser.default_cos(0);
    hbm_csr.hbm_port_${p}.cfg_hbm_parser.dscp_map(0);
    ${trace_register("pbc_csr.hbm.hbm_port_" + str(p) + ".cfg_hbm_parser")}
    hbm_csr.hbm_port_${p}.cfg_hbm_parser.write();
//::    #endif
//:: #endfor
    SDK_TRACE_DEBUG("%s", data.str().c_str());
    return sdk::SDK_RET_OK;
}

sdk_ret_t
capri_tm_soft_init (sdk::lib::catalog* catalog,
                    sdk::lib::qos_profile_t *qos_profile)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;
    capri_tm_cfg_profile_t tm_cfg_profile_;
    capri_tm_cfg_profile_t *tm_cfg_profile = &tm_cfg_profile_;

    capri_tm_asic_profile_t asic_profile;

    populate_asic_profile(&asic_profile);

    pthread_mutex_init(&tm_mutex, NULL);

    ret = capri_tm_init_qos_profile(tm_cfg_profile, catalog,
                                    qos_profile);
    if (ret != SDK_RET_OK) {
        SDK_TRACE_ERR("Error initing qos profile. ret: %d", ret);
        return ret;
    }

    SDK_TRACE_DEBUG("cfg-profile sw_init_en %u sw_cfg_write_en %u "
                    "num_active_uplink_ports %u hbm_fifo_size %u hbm_fifo_base 0x%x",
                    tm_cfg_profile->sw_init_enabled,
                    tm_cfg_profile->sw_cfg_write_enabled,
                    tm_cfg_profile->num_active_uplink_ports,
                    tm_cfg_profile->hbm_fifo_size,
                    tm_cfg_profile->hbm_fifo_base);

    for (unsigned port_type = 0; port_type < NUM_TM_PORT_TYPES; port_type++) {
        if (tm_cfg_profile->num_qs[port_type] >
            capri_tm_get_num_iqs_for_port_type((tm_port_type_e)port_type)) {
            SDK_TRACE_ERR("Error cfg-profile port_type %u num_qs %u "
                          "supported %u", (tm_port_type_e)port_type,
                          tm_cfg_profile->num_qs[port_type],
                          capri_tm_get_num_iqs_for_port_type((tm_port_type_e)port_type));
            return sdk::SDK_RET_INVALID_ARG;
        }
        SDK_TRACE_DEBUG("cfg-profile port_type %u num_qs %u jumbo_mtu %u ",
                        (tm_port_type_e)port_type,
                        tm_cfg_profile->num_qs[port_type],
                        tm_cfg_profile->jumbo_mtu[port_type]);
    }

    set_tm_ctx(tm_cfg_profile, &asic_profile);
    return ret;
}

sdk_ret_t
capri_tm_init (sdk::lib::catalog* catalog,
               sdk::lib::qos_profile_t *qos_profile)
{
    sdk_ret_t ret = sdk::SDK_RET_OK;
    capri_tm_cfg_profile_t tm_cfg_profile_;
    capri_tm_cfg_profile_t *tm_cfg_profile = &tm_cfg_profile_;

    capri_tm_asic_profile_t asic_profile;

    populate_asic_profile(&asic_profile);

    pthread_mutex_init(&tm_mutex, NULL);

    ret = capri_tm_init_qos_profile(tm_cfg_profile, catalog,
                                    qos_profile);
    if (ret != SDK_RET_OK) {
        SDK_TRACE_ERR("Error initing qos profile. ret: %d",
                      ret);
        return ret;
    }

    SDK_TRACE_DEBUG("cfg-profile sw_init_en %u sw_cfg_write_en %u "
                    "num_active_uplink_ports %u hbm_fifo_size %u hbm_fifo_base 0x%x",
                    tm_cfg_profile->sw_init_enabled,
                    tm_cfg_profile->sw_cfg_write_enabled,
                    tm_cfg_profile->num_active_uplink_ports,
                    tm_cfg_profile->hbm_fifo_size,
                    tm_cfg_profile->hbm_fifo_base);
    for (unsigned port_type = 0; port_type < NUM_TM_PORT_TYPES; port_type++) {
        if (tm_cfg_profile->num_qs[port_type] >
            capri_tm_get_num_iqs_for_port_type((tm_port_type_e)port_type)) {
            SDK_TRACE_ERR("Error cfg-profile port_type %u num_qs %u "
                          "supported %u",
                          (tm_port_type_e)port_type, tm_cfg_profile->num_qs[port_type],
                          capri_tm_get_num_iqs_for_port_type((tm_port_type_e)port_type));
            return sdk::SDK_RET_INVALID_ARG;
        }
        SDK_TRACE_DEBUG("cfg-profile port_type %u num_qs %u jumbo_mtu %u ",
                        (tm_port_type_e)port_type, tm_cfg_profile->num_qs[port_type],
                        tm_cfg_profile->jumbo_mtu[port_type]);
    }

    set_tm_ctx(tm_cfg_profile, &asic_profile);

    ret = capri_tm_global_init();
    if (ret != sdk::SDK_RET_OK) {
        SDK_TRACE_ERR("Error initing global config ret %d", ret);
        return ret;
    }
    if (tm_sw_init_enabled()) {
        // Poll for the completion of the inits
        cap_pb_init_done(0,0);
    }

    ret = capri_tm_init_ports();
    if (ret != sdk::SDK_RET_OK) {
        SDK_TRACE_ERR("Error initing ports ret %d", ret);
        return ret;
    }

    ret = capri_tm_init_enable_ports();
    if (ret != sdk::SDK_RET_OK) {
        SDK_TRACE_ERR("Error enabling ports ret %d", ret);
        return ret;
    }

    char *perf_run = getenv("PERF_RUN");
    if (perf_run) {
        SDK_TRACE_DEBUG("perf-run env %s", perf_run);
        if (!strcmp(perf_run, "true")) {
            capri_tm_update_perf_run_config();
        }
    }
    SDK_TRACE_DEBUG("Init completed");
    tm_ctx()->init_complete.store(true);

    return ret;
}

/* Programs the base address in HBM for the replication table */
sdk_ret_t
capri_tm_repl_table_base_addr_set (uint64_t addr)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    pbc_csr.cfg_rpl.read();
    pbc_csr.cfg_rpl.base(addr);
    pbc_csr.cfg_rpl.write();
    return sdk::SDK_RET_OK;
}

/* Programs the replication table token size */
sdk_ret_t
capri_tm_repl_table_token_size_set (uint32_t size_in_bits)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    pbc_csr.cfg_rpl.read();

    // "Size of token in nodes. 0: 32 bits, 1: 48 bits, 2: 64 bits"
    if (size_in_bits == 64) {
        pbc_csr.cfg_rpl.token_size(2);
    } else if (size_in_bits == 48) {
        pbc_csr.cfg_rpl.token_size(1);
    } else if (size_in_bits == 32) {
        pbc_csr.cfg_rpl.token_size(0);
    } else {
        return sdk::SDK_RET_INVALID_ARG;
    }

    pbc_csr.cfg_rpl.write();
    return sdk::SDK_RET_OK;
}

/* Get hw clock */
sdk_ret_t
capri_tm_get_clock_tick (uint64_t *tick)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    cap_pbchbm_csr_t &hbm_csr = pbc_csr.hbm;

    hbm_csr.sta_hbm_timestamp.read();
    *tick = (uint64_t)hbm_csr.sta_hbm_timestamp.value().convert_to<uint64_t>();
    return sdk::SDK_RET_OK;
}

#define CHECK_OVERFLOW_AND_UPDATE(c, p, n)       \
{                                                \
    c += (p > n) ? (UINT32_MAX - p) + n : n - p; \
    p = n;                                       \
}

sdk_ret_t
capri_tm_periodic_stats_update (void)
{
    uint32_t port_in, port_out;
    uint32_t fifo_type;
    uint32_t context;
    capri_tm_hbm_context_stats_t *cur_vals;
    capri_tm_hbm_context_stats_t *new_val;
    capri_tm_hbm_context_stats_t *prev_vals;

    capri_tm_hbm_context_stats_t new_vals[NUM_TM_HBM_FIFO_TYPES][CAPRI_TM_MAX_HBM_CONTEXTS] = {};
    cpp_int good_count_in;
    cpp_int errored_count_in;
    cpp_int watermark_in;
    cpp_int good_count_out;

    if (!tm_ctx() || !tm_ctx()->init_complete.load()) {
        return sdk::SDK_RET_OK;
    }

    // Take lock and update
    SDK_SPINLOCK_LOCK(&tm_ctx()->stats.slock);
    // Read from asic
    for (fifo_type = 0; fifo_type < NUM_TM_HBM_FIFO_TYPES; fifo_type++) {
        for (context = 0; context < capri_tm_max_hbm_contexts_for_fifo(fifo_type);
             context++) {
            if (fifo_type == TM_HBM_FIFO_TYPE_UPLINK) {
                port_in = 13;
                port_out = 12;
            } else {
                port_in = 15;
                port_out = 14;
            }
            new_val = &new_vals[fifo_type][context];
            cap_pb_read_hbm_ctx_stat(0, 0, port_in, context, good_count_in,
                                     errored_count_in);
            cap_pb_read_hbm_ctx_stat(0, 0, port_out, context, good_count_out,
                                     watermark_in);
            new_val->good_pkts_in = good_count_in.convert_to<uint32_t>();
            new_val->good_pkts_out = good_count_out.convert_to<uint32_t>();
            new_val->errored_pkts_in = errored_count_in.convert_to<uint32_t>();
            new_val->max_oflow_fifo_depth = watermark_in.convert_to<uint32_t>();
        }
    }
    for (fifo_type = 0; fifo_type < NUM_TM_HBM_FIFO_TYPES; fifo_type++) {
        for (context = 0; context < capri_tm_max_hbm_contexts_for_fifo(fifo_type);
             context++) {
            cur_vals = &tm_ctx()->stats.cur_vals[fifo_type][context];
            prev_vals = &tm_ctx()->stats.prev_vals[fifo_type][context];
            new_val = &new_vals[fifo_type][context];
            CHECK_OVERFLOW_AND_UPDATE(cur_vals->good_pkts_in,
                                      prev_vals->good_pkts_in,
                                      new_val->good_pkts_in);
            CHECK_OVERFLOW_AND_UPDATE(cur_vals->good_pkts_out,
                                      prev_vals->good_pkts_out,
                                      new_val->good_pkts_out);
            CHECK_OVERFLOW_AND_UPDATE(cur_vals->errored_pkts_in,
                                      prev_vals->errored_pkts_in,
                                      new_val->errored_pkts_in);
            cur_vals->max_oflow_fifo_depth = new_val->max_oflow_fifo_depth;
        }
    }
    SDK_SPINLOCK_UNLOCK(&tm_ctx()->stats.slock);
    return sdk::SDK_RET_OK;
}

static void
capri_tm_get_context_stats (tm_hbm_fifo_type_e fifo_type, uint32_t context,
                            capri_tm_hbm_context_stats_t *context_stats)
{
    if ((fifo_type >= NUM_TM_HBM_FIFO_TYPES) ||
        (context >= capri_tm_max_hbm_contexts_for_fifo(fifo_type)))  {
        *context_stats = {0};
        return;
    }
    SDK_SPINLOCK_LOCK(&tm_ctx()->stats.slock);
    *context_stats = tm_ctx()->stats.cur_vals[fifo_type][context];
    SDK_SPINLOCK_UNLOCK(&tm_ctx()->stats.slock);
}

static void
capri_tm_reset_context_stats (tm_hbm_fifo_type_e fifo_type, uint32_t context)
{
    if ((fifo_type >= NUM_TM_HBM_FIFO_TYPES) ||
        (context >= capri_tm_max_hbm_contexts_for_fifo(fifo_type)))  {
        return;
    }
    SDK_SPINLOCK_LOCK(&tm_ctx()->stats.slock);
    tm_ctx()->stats.cur_vals[fifo_type][context] =
                                    (const capri_tm_hbm_context_stats_t) {0};
    SDK_SPINLOCK_UNLOCK(&tm_ctx()->stats.slock);
}

sdk_ret_t
capri_tm_get_iq_stats(tm_port_t port, tm_q_t iq, tm_iq_stats_t *iq_stats)
{
    uint32_t num_hbm_contexts_per_port;
    uint32_t context;
    tm_port_type_e port_type;
    tm_hbm_fifo_type_e fifo_type;
    capri_tm_hbm_context_stats_t context_stats = {0};
    uint32_t cur_occupancy, peak_occupancy;

    if (!capri_tm_is_valid_port(port)) {
        SDK_TRACE_ERR("%u is not a valid TM port",
                      port);
        return sdk::SDK_RET_INVALID_ARG;
    }
    *iq_stats = (const tm_iq_stats_t) {0};

    // Read the registers to figure out the current stats

    if (port_supports_hbm_contexts(port)) {
        port_type = capri_tm_get_port_type(port);
        if (port_type == TM_PORT_TYPE_UPLINK) {
            num_hbm_contexts_per_port = tm_cfg_profile()->num_qs[TM_PORT_TYPE_UPLINK];
            context = (port * num_hbm_contexts_per_port) + iq;
        } else {
            context = iq;
        }
        fifo_type = capri_tm_get_fifo_type_for_port(port);

        // Get the context stats from shadow
        capri_tm_get_context_stats(fifo_type, context, &context_stats);

        iq_stats->oflow.good_pkts_in = context_stats.good_pkts_in;
        iq_stats->oflow.good_pkts_out = context_stats.good_pkts_out;
        iq_stats->oflow.errored_pkts_in = context_stats.errored_pkts_in;
        iq_stats->oflow.max_fifo_depth = CAPRI_TM_HBM_FIFO_ALLOC_SIZE *
                                            context_stats.max_oflow_fifo_depth;

        // Get the current occupancy
        iq_stats->oflow.fifo_depth = CAPRI_TM_HBM_FIFO_ALLOC_SIZE *
                                capri_tm_get_hbm_occupancy(fifo_type, context);
    }
    capri_tm_get_buffer_occupancy(port, iq, &cur_occupancy, &peak_occupancy);
    iq_stats->buffer_occupancy = CAPRI_TM_CELL_SIZE * cur_occupancy;
    iq_stats->peak_occupancy = CAPRI_TM_CELL_SIZE * peak_occupancy;
    iq_stats->port_monitor = capri_tm_get_port_mon_in(0, 0, port, iq);
    return sdk::SDK_RET_OK;
}

sdk_ret_t
capri_tm_reset_iq_stats(tm_port_t port, tm_q_t iq)
{
    uint32_t num_hbm_contexts_per_port;
    uint32_t context;
    tm_port_type_e port_type;
    tm_hbm_fifo_type_e fifo_type;

    if (!capri_tm_is_valid_port(port)) {
        SDK_TRACE_ERR("%u is not a valid TM port",
                      port);
        return sdk::SDK_RET_INVALID_ARG;
    }

    if (port_supports_hbm_contexts(port)) {
        port_type = capri_tm_get_port_type(port);
        if (port_type == TM_PORT_TYPE_UPLINK) {
            num_hbm_contexts_per_port = tm_cfg_profile()->num_qs[TM_PORT_TYPE_UPLINK];
            context = (port * num_hbm_contexts_per_port) + iq;
        } else {
            context = iq;
        }
        fifo_type = capri_tm_get_fifo_type_for_port(port);

        // Reset the context stats in shadow
        capri_tm_reset_context_stats(fifo_type, context);

    }
    return sdk::SDK_RET_OK;
}

sdk_ret_t
capri_tm_get_oq_stats(tm_port_t port, tm_q_t oq, tm_oq_stats_t *oq_stats)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;

    if (!capri_tm_is_valid_port(port)) {
        SDK_TRACE_ERR("%u is not a valid TM port",
                      port);
        return sdk::SDK_RET_INVALID_ARG;
    }

    pbc_csr.sta_oq[port].read();

    // 16 bits per oq
    oq_stats->queue_depth = cpp_helper.get_slc(pbc_csr.sta_oq[port].depth_value(),
                                              oq*16,
                                              (((oq+1)*16)-1)).convert_to<uint32_t>();
#if 0
    oq_stats->queue_depth = pack_bytes_unpack((uint8_t *)pbc_csr.sta_oq[port].depth_value(),
                                              oq*16, 16);
#endif
    oq_stats->port_monitor = capri_tm_get_port_mon_out(0, 0, port, oq);
    return sdk::SDK_RET_OK;
}

sdk_ret_t
capri_tm_debug_stats_get (tm_port_t port, tm_debug_stats_t *debug_stats,
                          bool reset)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;

    if (!capri_tm_is_valid_port(port)) {
        SDK_TRACE_ERR("%u is not a valid TM port",
                      port);
        return sdk::SDK_RET_INVALID_ARG;
    }

    if (debug_stats) {
        memset(debug_stats, 0, sizeof(tm_debug_stats_t));

        pbc_csr.cnt_flits[port].read();
        pbc_csr.sat_write_error[port].read();

        debug_stats->buffer_stats.sop_count_in = pbc_csr.cnt_flits[port].sop_in().convert_to<uint32_t>();
        debug_stats->buffer_stats.eop_count_in = pbc_csr.cnt_flits[port].eop_in().convert_to<uint32_t>();
        debug_stats->buffer_stats.sop_count_out = pbc_csr.cnt_flits[port].sop_out().convert_to<uint32_t>();
        debug_stats->buffer_stats.eop_count_out = pbc_csr.cnt_flits[port].eop_out().convert_to<uint32_t>();

        debug_stats->buffer_stats.drop_counts[sdk::qos::BUFFER_INTRINSIC_DROP] = pbc_csr.sat_write_error[port].intrinsic_drop().convert_to<uint32_t>();
        debug_stats->buffer_stats.drop_counts[sdk::qos::BUFFER_DISCARDED] = pbc_csr.sat_write_error[port].discarded().convert_to<uint32_t>();
        debug_stats->buffer_stats.drop_counts[sdk::qos::BUFFER_ADMITTED] = pbc_csr.sat_write_error[port].admitted().convert_to<uint32_t>();
        debug_stats->buffer_stats.drop_counts[sdk::qos::BUFFER_OUT_OF_CELLS_DROP] = pbc_csr.sat_write_error[port].out_of_cells().convert_to<uint32_t>();
        debug_stats->buffer_stats.drop_counts[sdk::qos::BUFFER_OUT_OF_CELLS_DROP_2] = pbc_csr.sat_write_error[port].out_of_cells1().convert_to<uint32_t>();
        debug_stats->buffer_stats.drop_counts[sdk::qos::BUFFER_OUT_OF_CREDIT_DROP] = pbc_csr.sat_write_error[port].out_of_credit().convert_to<uint32_t>();
        debug_stats->buffer_stats.drop_counts[sdk::qos::BUFFER_TRUNCATION_DROP] = pbc_csr.sat_write_error[port].truncation().convert_to<uint32_t>();
        debug_stats->buffer_stats.drop_counts[sdk::qos::BUFFER_PORT_DISABLED_DROP] = pbc_csr.sat_write_error[port].port_disabled().convert_to<uint32_t>();
        debug_stats->buffer_stats.drop_counts[sdk::qos::BUFFER_COPY_TO_CPU_TAIL_DROP] = pbc_csr.sat_write_error[port].tail_drop_cpu().convert_to<uint32_t>();
        debug_stats->buffer_stats.drop_counts[sdk::qos::BUFFER_SPAN_TAIL_DROP] = pbc_csr.sat_write_error[port].tail_drop_span().convert_to<uint32_t>();
        debug_stats->buffer_stats.drop_counts[sdk::qos::BUFFER_MIN_SIZE_VIOLATION_DROP] = pbc_csr.sat_write_error[port].min_size_viol().convert_to<uint32_t>();
        debug_stats->buffer_stats.drop_counts[sdk::qos::BUFFER_ENQUEUE_ERROR_DROP] = pbc_csr.sat_write_error[port].enqueue().convert_to<uint32_t>();
        debug_stats->buffer_stats.drop_counts[sdk::qos::BUFFER_INVALID_PORT_DROP] = pbc_csr.sat_write_error[port].port_range().convert_to<uint32_t>();
        debug_stats->buffer_stats.drop_counts[sdk::qos::BUFFER_INVALID_OUTPUT_QUEUE_DROP] = pbc_csr.sat_write_error[port].oq_range().convert_to<uint32_t>();
    }

    if (reset) {
        pbc_csr.cnt_flits[port].all(0);
        pbc_csr.sat_write_error[port].all(0);

        pbc_csr.cnt_flits[port].write();
        pbc_csr.sat_write_error[port].write();
    }

    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
        case ${pinfo["enum"]}:
            {
                if (debug_stats) {
                    pbc_csr.hbm.hbm_port_${p}.cnt_hbm.read();
                    pbc_csr.hbm.cnt_hbm${p}_emergency_stop.read();
                    pbc_csr.hbm.cnt_hbm${p}_write_ack_filling_up.read();
                    pbc_csr.hbm.cnt_hbm${p}_write_ack_full.read();
                    pbc_csr.hbm.cnt_hbm${p}_truncate.read();
                    pbc_csr.hbm.sat_hbm${p}_ctrl_full.read();

                    debug_stats->oflow_fifo_stats.sop_count_in = pbc_csr.hbm.hbm_port_${p}.cnt_hbm.flits_sop_in().convert_to<uint32_t>();
                    debug_stats->oflow_fifo_stats.eop_count_in = pbc_csr.hbm.hbm_port_${p}.cnt_hbm.flits_eop_in().convert_to<uint32_t>();
                    debug_stats->oflow_fifo_stats.sop_count_out = pbc_csr.hbm.hbm_port_${p}.cnt_hbm.flits_sop_out().convert_to<uint32_t>();
                    debug_stats->oflow_fifo_stats.eop_count_out = pbc_csr.hbm.hbm_port_${p}.cnt_hbm.flits_eop_out().convert_to<uint32_t>();

                    debug_stats->oflow_fifo_stats.drop_counts.occupancy_drop_count = pbc_csr.hbm.hbm_port_${p}.cnt_hbm.occupancy_drop().convert_to<uint32_t>();
                    debug_stats->oflow_fifo_stats.drop_counts.emergency_stop_drop_count = pbc_csr.hbm.cnt_hbm${p}_emergency_stop.drop().convert_to<uint32_t>();
                    debug_stats->oflow_fifo_stats.drop_counts.write_buffer_ack_fill_up_drop_count = pbc_csr.hbm.cnt_hbm${p}_write_ack_filling_up.drop().convert_to<uint32_t>();
                    debug_stats->oflow_fifo_stats.drop_counts.write_buffer_ack_full_drop_count = pbc_csr.hbm.cnt_hbm${p}_write_ack_full.drop().convert_to<uint32_t>();
                    debug_stats->oflow_fifo_stats.drop_counts.write_buffer_full_drop_count = pbc_csr.hbm.cnt_hbm${p}_truncate.drop().convert_to<uint32_t>();
                    debug_stats->oflow_fifo_stats.drop_counts.control_fifo_full_drop_count = pbc_csr.hbm.sat_hbm${p}_ctrl_full.drop().convert_to<uint32_t>();
                }

                if (reset) {
                    pbc_csr.hbm.hbm_port_${p}.cnt_hbm.all(0);
                    pbc_csr.hbm.cnt_hbm${p}_emergency_stop.all(0);
                    pbc_csr.hbm.cnt_hbm${p}_write_ack_filling_up.all(0);
                    pbc_csr.hbm.cnt_hbm${p}_write_ack_full.all(0);
                    pbc_csr.hbm.cnt_hbm${p}_truncate.all(0);
                    pbc_csr.hbm.sat_hbm${p}_ctrl_full.all(0);

                    pbc_csr.hbm.hbm_port_${p}.cnt_hbm.write();
                    pbc_csr.hbm.cnt_hbm${p}_emergency_stop.write();
                    pbc_csr.hbm.cnt_hbm${p}_write_ack_filling_up.write();
                    pbc_csr.hbm.cnt_hbm${p}_write_ack_full.write();
                    pbc_csr.hbm.cnt_hbm${p}_truncate.write();
                    pbc_csr.hbm.sat_hbm${p}_ctrl_full.write();
                }

                break;
            }
//::    #endif
//:: #endfor
        default:
            break;
    }

    return sdk::SDK_RET_OK;
}

uint32_t
capri_tm_get_port_occupancy (tm_port_t port, uint32_t iq)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    cpp_int port_payload_occupancy_val;
    uint32_t payload_occupancy = 0;

    switch(port) {
//:: for p in range(TM_PORTS):
//::    pinfo = port_info[p]
//::    if pinfo["type"] == "uplink":
        case ${pinfo["enum"]}:
            pbc_csr.hbm.hbm_port_${p}.cfg_hbm_eth_payload_occupancy.read();
            port_payload_occupancy_val = pbc_csr.hbm.hbm_port_${p}.cfg_hbm_eth_payload_occupancy.threshold();
            payload_occupancy = cpp_helper.get_slc(port_payload_occupancy_val, iq*19, ((iq+1)*19)-1).convert_to<uint32_t>();
            break;
//::    #endif
//:: #endfor
        default:
            break;
    }

    return (payload_occupancy << 10);
}

uint32_t
capri_tm_get_xon_threshold (uint32_t ctx)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    uint32_t xon_threshold = 0;
    cpp_int xon_val;

    pbc_csr.hbm.cfg_hbm_threshold.read();
    xon_val = pbc_csr.hbm.cfg_hbm_threshold.xon();
    xon_threshold = cpp_helper.get_slc(xon_val, ctx*20, ((ctx+1)*20)-1).convert_to<uint32_t>();

    return (xon_threshold << 9);
}

uint32_t
capri_tm_get_xoff_threshold (uint32_t ctx)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    uint32_t xoff_threshold = 0;
    cpp_int xoff_val;

    pbc_csr.hbm.cfg_hbm_threshold.read();
    xoff_val = pbc_csr.hbm.cfg_hbm_threshold.xoff();
    xoff_threshold = cpp_helper.get_slc(xoff_val, ctx*20, ((ctx+1)*20)-1).convert_to<uint32_t>();

    return (xoff_threshold << 9);
}

uint64_t
capri_tm_get_port_mon_out (int chip_id,
                           int inst_id,
                           tm_port_t tm_port,
                           tm_q_t tm_oq)
{
    cpp_int count;
    uint32_t cfg_port_0;
    uint32_t cfg_port_1;
    uint32_t cfg_port_2;
    uint32_t cfg_port_3;
    int port = 0;
    int cur_address = 0;
    cap_pbc_csr_t &pbc_csr =
                CAP_BLK_REG_MODEL_ACCESS(cap_pbc_csr_t, chip_id, inst_id);

    pbc_csr.cfg_port_mon_out.read();
    cfg_port_0 = pbc_csr.cfg_port_mon_out.port_0().convert_to<int>();
    cfg_port_1 = pbc_csr.cfg_port_mon_out.port_1().convert_to<int>();
    cfg_port_2 = pbc_csr.cfg_port_mon_out.port_2().convert_to<int>();
    cfg_port_3 = pbc_csr.cfg_port_mon_out.port_3().convert_to<int>();

    if (tm_port == cfg_port_0) {
        port = 0;
    } else if (tm_port == cfg_port_1) {
        port = 1;
    } else if (tm_port == cfg_port_2) {
        port = 2;
    } else if (tm_port == cfg_port_3) {
        port = 3;
    } else {
        // port monitor not configured for tm_port
        // SDK_TRACE_DEBUG("tm_port %d, oq %d not supported",
        //                 tm_port, tm_oq);
        return 0;
    }

    cur_address = (port * CAPRI_TM_MAX_QUEUES) + tm_oq;
    // SDK_TRACE_DEBUG("tm_port %d, oq %d cur_address %d",
    //                 tm_port, tm_oq, cur_address);
    cap_pb_read_port_mon_out(chip_id, inst_id, cur_address, count);
    return count.convert_to<uint64_t>();
}

uint64_t
capri_tm_get_port_mon_in (int chip_id,
                          int inst_id,
                          tm_port_t tm_port,
                          tm_q_t tm_iq)
{
    uint32_t eth_port_start = 0;
    int cur_address = 0;
    cpp_int count;
    cap_pbc_csr_t &pbc_csr =
                CAP_BLK_REG_MODEL_ACCESS(cap_pbc_csr_t, chip_id, inst_id);

    pbc_csr.cfg_port_mon_in.read();
    eth_port_start = pbc_csr.cfg_port_mon_in.eth().convert_to<uint32_t>();

    // port monitor order in HW - INGRESS, EGRESS, DMA, ETH
    switch (tm_port) {
        case CAPRI_TM_PORT_INGRESS:
            cur_address = 0 + tm_iq;
            break;

        case CAPRI_TM_PORT_EGRESS:
            cur_address = capri_tm_get_num_iqs_for_port(CAPRI_TM_PORT_INGRESS) +
                          tm_iq;
            break;

        case CAPRI_TM_PORT_DMA:
            cur_address = capri_tm_get_num_iqs_for_port(CAPRI_TM_PORT_INGRESS) +
                          capri_tm_get_num_iqs_for_port(CAPRI_TM_PORT_EGRESS)  +
                          tm_iq;
            break;

        default:
            // NCSI and UPLINKS
            // only 6 ETH ports can be monitored
            if (tm_port > eth_port_start + 5) {
                // SDK_TRACE_DEBUG("tm_port %d, iq %d not supported",
                //                 tm_port, tm_iq);
                return 0;
            }
            cur_address = capri_tm_get_num_iqs_for_port(CAPRI_TM_PORT_INGRESS) +
                          capri_tm_get_num_iqs_for_port(CAPRI_TM_PORT_EGRESS)  +
                          capri_tm_get_num_iqs_for_port(CAPRI_TM_PORT_DMA)     +
                          (capri_tm_get_num_iqs_for_port(TM_PORT_TYPE_UPLINK)
                                                              * tm_port) +
                          tm_iq;
            break;
    }
    // SDK_TRACE_DEBUG("tm_port %d, iq %d cur_address %d",
    //                 tm_port, tm_iq, cur_address);
    cap_pb_read_port_mon_in(chip_id, inst_id, cur_address, count);
    return count.convert_to<uint64_t>();
}

// set the span queue threshold
sdk_ret_t
capri_tm_set_span_threshold (uint32_t span_threshold)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;
    pbc_csr.cfg_tail_drop.read();
    pbc_csr.cfg_tail_drop.span_threshold(span_threshold);
    pbc_csr.cfg_tail_drop.write();
    return SDK_RET_OK;
}

// set the reserved min for uplink ports
sdk_ret_t
capri_tm_set_reserved_min (uint32_t reserved_min)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;

    pbc_csr.port_0.cfg_account_pg_0.read();
    pbc_csr.port_0.cfg_account_pg_0.reserved_min(reserved_min);
    pbc_csr.port_0.cfg_account_pg_0.write();
    pbc_csr.port_1.cfg_account_pg_0.read();
    pbc_csr.port_1.cfg_account_pg_0.reserved_min(reserved_min);
    pbc_csr.port_1.cfg_account_pg_0.write();
    return SDK_RET_OK;
}

/// \brief      Get current credits for queue on tm port
/// \param[in]  tm_port PB port
/// \param[in]  oq      PB output queue
/// \param[out] val    Current credits value
/// \return     #SDK_RET_OK on success, failure status code on error
sdk_ret_t
capri_tm_get_current_credits (tm_port_t tm_port,
                              tm_q_t oq,
                              uint32_t *val)
{
    cap_top_csr_t &cap0 = g_capri_state_pd->cap_top();
    cap_pbc_csr_t &pbc_csr = cap0.pb.pbc;

    if (tm_port == CAPRI_TM_PORT_EGRESS) {
        *val = pbc_csr.port_10.dhs_oq_flow_control.entry[oq].entry().convert_to<uint32_t>();
    } else if (tm_port == CAPRI_TM_PORT_INGRESS) {
        *val = pbc_csr.port_11.dhs_oq_flow_control.entry[oq].entry().convert_to<uint32_t>();
    } else {
        return SDK_RET_ERR;
    }
    return SDK_RET_OK;
}

} // namespace capri
} // namespace platform
} // namespace sdk
